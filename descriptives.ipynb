{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "######################################################################\n",
      "# AI EXPOSURE AND ENROLLMENT ANALYSIS - 4-DIGIT CIP\n",
      "######################################################################\n",
      "\n",
      "======================================================================\n",
      "LOADING FELTEN AIOE DATA\n",
      "======================================================================\n",
      "\n",
      "Loaded 774 occupations\n",
      "AIOE range: -2.67 to 1.53\n",
      "\n",
      "======================================================================\n",
      "LOADING FOD TO 4-DIGIT CIP CROSSWALK\n",
      "======================================================================\n",
      "\n",
      "Mapped 191 FOD codes to 4-digit CIP codes\n",
      "\n",
      "Sample mappings:\n",
      "  FOD 1100 → CIP4 0100\n",
      "  FOD 1101 → CIP4 0106\n",
      "  FOD 1102 → CIP4 0100\n",
      "  FOD 1103 → CIP4 0109\n",
      "  FOD 1104 → CIP4 0110\n",
      "  FOD 1105 → CIP4 0111\n",
      "  FOD 1106 → CIP4 0112\n",
      "  FOD 1199 → CIP4 0108\n",
      "  FOD 1301 → CIP4 0301\n",
      "  FOD 1302 → CIP4 0305\n",
      "  FOD 1303 → CIP4 0302\n",
      "  FOD 1401 → CIP4 0400\n",
      "  FOD 1501 → CIP4 0501\n",
      "  FOD 1901 → CIP4 0901\n",
      "  FOD 1902 → CIP4 0904\n",
      "  FOD 1903 → CIP4 0907\n",
      "  FOD 1904 → CIP4 0909\n",
      "  FOD 2001 → CIP4 1003\n",
      "  FOD 2100 → CIP4 1101\n",
      "  FOD 2101 → CIP4 1102\n",
      "\n",
      "✓ Computer Science: FOD 2102 → CIP4 1100\n",
      "\n",
      "======================================================================\n",
      "PROCESSING ACS DATA\n",
      "======================================================================\n",
      "\n",
      "======================================================================\n",
      "LOADING ACS PUMS DATA\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "AI Exposure and College Enrollment Analysis - 4-DIGIT CIP VERSION\n",
    "==================================================================\n",
    "Updated for:\n",
    "- 4-digit CIP codes (436 programs vs 49 at 2-digit level)\n",
    "- 2019-2025 enrollment data (combined from both files)\n",
    "- More granular analysis (e.g., Computer Science vs Information Systems)\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from typing import Dict\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# =============================================================================\n",
    "# STEP 1: LOAD FELTEN AIOE DATA\n",
    "# =============================================================================\n",
    "\n",
    "def load_felten_data(filepath: str) -> pd.DataFrame:\n",
    "    \"\"\"Load Felten et al. (2021) AIOE scores.\"\"\"\n",
    "    print(\"=\"*70)\n",
    "    print(\"LOADING FELTEN AIOE DATA\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    felten = pd.read_excel(filepath, sheet_name='Appendix A')\n",
    "    felten['soc_clean'] = felten['SOC Code'].str.replace('-', '').str.replace('.', '')\n",
    "    \n",
    "    print(f\"\\nLoaded {len(felten)} occupations\")\n",
    "    print(f\"AIOE range: {felten['AIOE'].min():.2f} to {felten['AIOE'].max():.2f}\")\n",
    "    \n",
    "    return felten\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# STEP 2: LOAD FOD TO 4-DIGIT CIP CROSSWALK\n",
    "# =============================================================================\n",
    "\n",
    "def load_fod_cip4_crosswalk(filepath: str) -> Dict[int, str]:\n",
    "    \"\"\"\n",
    "    Load FOD to 4-digit CIP mapping from crosswalk file.\n",
    "    \n",
    "    The crosswalk has detailed 6-digit CIP codes (like 11.0701).\n",
    "    We extract 4-digit CIP:\n",
    "    - Family (2 digits): 11 = Computer Science\n",
    "    - Group (next 2 digits): 07 = Computer Science \n",
    "    - Combined: 1107 = Computer Science (4-digit)\n",
    "    \n",
    "    Examples:\n",
    "    - 11.0000 → 1100 (Computer Science, General)\n",
    "    - 11.0701 → 1107 (Computer Science)\n",
    "    - 52.0201 → 5202 (Business Administration)\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    Dict mapping FOD code (int) to 4-digit CIP string (e.g., '1107')\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"LOADING FOD TO 4-DIGIT CIP CROSSWALK\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    # Read from \"CIP code by HHES code\" sheet\n",
    "    df = pd.read_excel(filepath, sheet_name='CIP code by HHES code', skiprows=1)\n",
    "    \n",
    "    # Extract FOD and CIP columns\n",
    "    crosswalk = df[['HHES Code', 'CIP \\nCode']].copy()\n",
    "    crosswalk.columns = ['FOD', 'CIP']\n",
    "    crosswalk = crosswalk.dropna(subset=['FOD', 'CIP'])\n",
    "    \n",
    "    # Convert FOD to integer\n",
    "    crosswalk['FOD'] = crosswalk['FOD'].astype(int)\n",
    "    \n",
    "    # Extract 4-digit CIP from 6-digit CIP code\n",
    "    # CIP format: XX.XXXX where first 2 are family, next 2 are group\n",
    "    # E.g., 11.0701 → 1107\n",
    "    def extract_cip4(cip_6digit):\n",
    "        try:\n",
    "            cip_float = float(cip_6digit)\n",
    "            # Get integer part (family, 2 digits)\n",
    "            family = int(cip_float)  # e.g., 11\n",
    "            # Get first 2 decimal digits (group)\n",
    "            decimal_part = cip_float - family  # e.g., 0.0701\n",
    "            # Extract first 2 decimal digits\n",
    "            group = int(round(decimal_part * 10000)) // 100  # e.g., 07\n",
    "            # Combine to 4-digit code\n",
    "            cip4 = f\"{family:02d}{group:02d}\"  # e.g., \"1107\"\n",
    "            return cip4\n",
    "        except:\n",
    "            return None\n",
    "    \n",
    "    crosswalk['CIP4'] = crosswalk['CIP'].apply(extract_cip4)\n",
    "    crosswalk = crosswalk.dropna(subset=['CIP4'])\n",
    "    \n",
    "    # For each FOD, use the modal (most common) 4-digit CIP\n",
    "    # (some FOD codes map to multiple detailed CIPs within same 4-digit group)\n",
    "    fod_to_cip4 = crosswalk.groupby('FOD')['CIP4'].agg(lambda x: x.mode()[0] if len(x.mode()) > 0 else x.iloc[0]).to_dict()\n",
    "    \n",
    "    print(f\"\\nMapped {len(fod_to_cip4)} FOD codes to 4-digit CIP codes\")\n",
    "    \n",
    "    # Show sample mappings\n",
    "    print(\"\\nSample mappings:\")\n",
    "    for fod in sorted(fod_to_cip4.keys())[:20]:\n",
    "        print(f\"  FOD {fod} → CIP4 {fod_to_cip4[fod]}\")\n",
    "    \n",
    "    # Check Computer Science specifically (FOD 2102)\n",
    "    if 2102 in fod_to_cip4:\n",
    "        print(f\"\\n✓ Computer Science: FOD 2102 → CIP4 {fod_to_cip4[2102]}\")\n",
    "    \n",
    "    return fod_to_cip4\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# STEP 3: LOAD AND PROCESS ACS PUMS DATA\n",
    "# =============================================================================\n",
    "\n",
    "def load_and_filter_acs(\n",
    "    filepath: str,\n",
    "    age_min: int = 22,\n",
    "    age_max: int = 35\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Load and filter IPUMS ACS PUMS data.\n",
    "    \n",
    "    Your ACS columns: DEGFIELDD, OCCSOC, PERWT, AGE, EDUC, YEAR\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"LOADING ACS PUMS DATA\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    acs = pd.read_csv(filepath)\n",
    "    \n",
    "    print(f\"\\nInitial sample: {len(acs):,} observations\")\n",
    "    \n",
    "    # Filter\n",
    "    acs_filtered = acs[\n",
    "        (acs['AGE'] >= age_min) & \n",
    "        (acs['AGE'] <= age_max) &\n",
    "        (acs['OCCSOC'].notna()) &\n",
    "        (acs['DEGFIELDD'].notna())\n",
    "    ].copy()\n",
    "    \n",
    "    print(f\"Filtered sample: {len(acs_filtered):,} observations\")\n",
    "    print(f\"  - Age {age_min}-{age_max}\")\n",
    "    print(f\"  - Valid occupation (OCCSOC) and field of degree (DEGFIELDD)\")\n",
    "    \n",
    "    # Clean SOC codes\n",
    "    acs_filtered['soc_clean'] = acs_filtered['OCCSOC'].astype(str).str.replace('-', '').str.replace('.', '')\n",
    "    \n",
    "    print(f\"\\nUnique DEGFIELDD codes: {acs_filtered['DEGFIELDD'].nunique()}\")\n",
    "    print(f\"Unique OCCSOC codes: {acs_filtered['OCCSOC'].nunique()}\")\n",
    "    \n",
    "    return acs_filtered\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# STEP 4: MAP FOD TO 4-DIGIT CIP AND MERGE WITH EXPOSURE\n",
    "# =============================================================================\n",
    "\n",
    "def process_acs_with_exposure(\n",
    "    acs: pd.DataFrame,\n",
    "    felten: pd.DataFrame,\n",
    "    fod_to_cip4: Dict[int, str]\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Map ACS FOD codes to 4-digit CIP, merge with AI exposure scores.\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"MAPPING FOD TO 4-DIGIT CIP AND MERGING AI EXPOSURE\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    # Map FOD to CIP4\n",
    "    acs['CIP4'] = acs['DEGFIELDD'].map(fod_to_cip4)\n",
    "    \n",
    "    # Report mapping success\n",
    "    n_mapped = acs['CIP4'].notna().sum()\n",
    "    pct_mapped = 100 * n_mapped / len(acs)\n",
    "    print(f\"\\nMapped {n_mapped:,}/{len(acs):,} observations to CIP4 ({pct_mapped:.1f}%)\")\n",
    "    \n",
    "    # Check unmapped FODs\n",
    "    if acs['CIP4'].isna().any():\n",
    "        unmapped_fods = acs[acs['CIP4'].isna()]['DEGFIELDD'].value_counts().head(10)\n",
    "        print(\"\\nTop 10 unmapped FOD codes:\")\n",
    "        print(unmapped_fods)\n",
    "    \n",
    "    # Filter to successfully mapped\n",
    "    acs_mapped = acs[acs['CIP4'].notna()].copy()\n",
    "    \n",
    "    # Merge with Felten AIOE scores on SOC code\n",
    "    acs_with_exposure = acs_mapped.merge(\n",
    "        felten[['soc_clean', 'AIOE']],\n",
    "        on='soc_clean',\n",
    "        how='left'\n",
    "    )\n",
    "    \n",
    "    # Report merge success\n",
    "    n_matched = acs_with_exposure['AIOE'].notna().sum()\n",
    "    pct_matched = 100 * n_matched / len(acs_with_exposure)\n",
    "    print(f\"\\nMatched {n_matched:,}/{len(acs_with_exposure):,} observations to AI exposure ({pct_matched:.1f}%)\")\n",
    "    \n",
    "    # Handle missing AIOE scores (impute with mean)\n",
    "    mean_aioe = acs_with_exposure['AIOE'].mean()\n",
    "    n_missing = acs_with_exposure['AIOE'].isna().sum()\n",
    "    if n_missing > 0:\n",
    "        print(f\"\\n⚠ Imputing {n_missing} missing AIOE values with mean ({mean_aioe:.4f})\")\n",
    "        acs_with_exposure['AIOE'].fillna(mean_aioe, inplace=True)\n",
    "    \n",
    "    print(f\"\\nFinal sample: {len(acs_with_exposure):,} observations\")\n",
    "    print(f\"Unique 4-digit CIP codes: {acs_with_exposure['CIP4'].nunique()}\")\n",
    "    \n",
    "    return acs_with_exposure\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# STEP 5: CALCULATE 4-DIGIT CIP-LEVEL AI EXPOSURE\n",
    "# =============================================================================\n",
    "\n",
    "def calculate_cip4_exposure(\n",
    "    acs: pd.DataFrame,\n",
    "    weight_var: str = 'PERWT'\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Calculate weighted average AI exposure by 4-digit CIP code.\n",
    "    \n",
    "    For each CIP4: AI_exposure = Σ [P(occupation|CIP4) × AIOE(occupation)]\n",
    "    where P(occupation|CIP4) is weighted by person weights.\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"CALCULATING 4-DIGIT CIP-LEVEL AI EXPOSURE SCORES\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    # Calculate weighted average by CIP4\n",
    "    cip_exposure = acs.groupby('CIP4').apply(\n",
    "        lambda x: pd.Series({\n",
    "            'ai_exposure_score': np.average(x['AIOE'], weights=x[weight_var]),\n",
    "            'n_obs': len(x),\n",
    "            'n_weighted': x[weight_var].sum(),\n",
    "            'min_exposure': x['AIOE'].min(),\n",
    "            'max_exposure': x['AIOE'].max(),\n",
    "            'std_exposure': np.sqrt(np.average((x['AIOE'] - np.average(x['AIOE'], weights=x[weight_var]))**2, \n",
    "                                                weights=x[weight_var]))\n",
    "        })\n",
    "    ).reset_index()\n",
    "    \n",
    "    print(f\"\\nCalculated AI exposure for {len(cip_exposure)} 4-digit CIP codes\")\n",
    "    print(\"\\nAI Exposure Score Distribution:\")\n",
    "    print(cip_exposure['ai_exposure_score'].describe())\n",
    "    \n",
    "    # Show top and bottom CIPs\n",
    "    print(\"\\n\\nTop 20 most AI-exposed majors (4-digit CIP):\")\n",
    "    top20 = cip_exposure.nlargest(20, 'ai_exposure_score')[['CIP4', 'ai_exposure_score', 'n_obs']]\n",
    "    print(top20)\n",
    "    \n",
    "    print(\"\\n\\nBottom 20 least AI-exposed majors (4-digit CIP):\")\n",
    "    bottom20 = cip_exposure.nsmallest(20, 'ai_exposure_score')[['CIP4', 'ai_exposure_score', 'n_obs']]\n",
    "    print(bottom20)\n",
    "    \n",
    "    return cip_exposure\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# STEP 6: LOAD AND COMBINE ENROLLMENT DATA (2019-2025)\n",
    "# =============================================================================\n",
    "\n",
    "def load_and_combine_enrollment_data(\n",
    "    filepath_2024: str, \n",
    "    filepath_2025: str\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Load and combine enrollment data from two sources with proper header handling.\n",
    "    \n",
    "    2024 file: Major Field (4-year, Undergrad) sheet, years 2019-2024\n",
    "    2025 file: CIP Group Enrollment sheet, years 2020-2025 (filter to Undergraduate 4-year)\n",
    "    \n",
    "    Returns combined dataset with 4-digit CIP codes (2019-2025).\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"LOADING AND COMBINING ENROLLMENT DATA (2019-2025)\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    # ===== LOAD 2024 FILE =====\n",
    "    print(\"\\nLoading 2019-2024 data from CTEESpring2024-Appendix.xlsx...\")\n",
    "    df_2024 = pd.read_excel(\n",
    "        filepath_2024, \n",
    "        sheet_name='Major Field (4-year, Undergrad)',\n",
    "        header=2  # Row 2 has the actual column headers\n",
    "    )\n",
    "    print(f\"  Loaded {len(df_2024)} rows\")\n",
    "    \n",
    "    # Rename columns for clarity\n",
    "    df_2024 = df_2024.rename(columns={\n",
    "        'Major Field Family (2-digit CIP)': 'CIP2',\n",
    "        'Major Field Family (2-digit) Title': 'CIP2_title',\n",
    "        'Major Field Group (4-digit CIP)': 'CIP4',\n",
    "        'Major Field Group (4-digit) Title': 'CIP4_title'\n",
    "    })\n",
    "    \n",
    "    # Get enrollment columns (years 2019-2024)\n",
    "    years_2024 = [2019, 2020, 2021, 2022, 2023, 2024]\n",
    "    enrollment_cols = [col for col in df_2024.columns if 'Enrollment' in str(col) and '% Change' not in str(col)]\n",
    "    print(f\"  Found {len(enrollment_cols)} enrollment columns for years 2019-2024\")\n",
    "    \n",
    "    # Reshape to long format\n",
    "    data_2024 = []\n",
    "    for idx, row in df_2024.iterrows():\n",
    "        cip4 = row['CIP4']\n",
    "        if pd.isna(cip4) or cip4 == 'Total':\n",
    "            continue\n",
    "        for year, col in zip(years_2024, enrollment_cols):\n",
    "            enrollment = row[col]\n",
    "            if pd.notna(enrollment) and enrollment != '*':\n",
    "                data_2024.append({\n",
    "                    'CIP4': str(cip4).zfill(4) if str(cip4).isdigit() else cip4,\n",
    "                    'year': year,\n",
    "                    'enrollment': float(enrollment)\n",
    "                })\n",
    "    \n",
    "    df_2024_long = pd.DataFrame(data_2024)\n",
    "    print(f\"  Reshaped to {len(df_2024_long)} observations\")\n",
    "    \n",
    "    # ===== LOAD 2025 FILE =====\n",
    "    print(\"\\nLoading 2020-2025 data from CTEESpring2025-DataAppendix.xlsx...\")\n",
    "    df_2025 = pd.read_excel(\n",
    "        filepath_2025,\n",
    "        sheet_name='CIP Group Enrollment',\n",
    "        header=2  # Row 2 has the actual column headers\n",
    "    )\n",
    "    print(f\"  Loaded {len(df_2025)} rows\")\n",
    "    \n",
    "    # Filter to Undergraduate 4-year only\n",
    "    df_2025 = df_2025[df_2025['Award Level and Institution Type'] == 'Undergraduate 4-year'].copy()\n",
    "    print(f\"  Filtered to {len(df_2025)} Undergraduate 4-year rows\")\n",
    "    \n",
    "    # Rename columns\n",
    "    df_2025 = df_2025.rename(columns={\n",
    "        'Major Field Family \\n(2-digit CIP)': 'CIP2',\n",
    "        'Major Field Family \\n(2-digit CIP) Title': 'CIP2_title',\n",
    "        'Major Field Group \\n(4-digit CIP)': 'CIP4',\n",
    "        'Major Field Group \\n(4-digit CIP) Title': 'CIP4_title'\n",
    "    })\n",
    "    \n",
    "    # Get enrollment columns (years 2020-2025)\n",
    "    # The enrollment columns alternate: Enrollment, % Change, Enrollment, % Change...\n",
    "    # Columns 5, 6, 8, 10, 12, 14 correspond to years 2020-2025\n",
    "    years_2025 = [2020, 2021, 2022, 2023, 2024, 2025]\n",
    "    enrollment_col_indices = [5, 6, 8, 10, 12, 14]\n",
    "    \n",
    "    # Reshape to long format\n",
    "    data_2025 = []\n",
    "    for idx, row in df_2025.iterrows():\n",
    "        cip4 = row['CIP4']\n",
    "        if pd.isna(cip4) or cip4 == 'Total':\n",
    "            continue\n",
    "        for year, col_idx in zip(years_2025, enrollment_col_indices):\n",
    "            enrollment = row.iloc[col_idx]\n",
    "            if pd.notna(enrollment) and enrollment != '*':\n",
    "                data_2025.append({\n",
    "                    'CIP4': str(cip4).zfill(4) if str(cip4).isdigit() else cip4,\n",
    "                    'year': year,\n",
    "                    'enrollment': float(enrollment)\n",
    "                })\n",
    "    \n",
    "    df_2025_long = pd.DataFrame(data_2025)\n",
    "    print(f\"  Reshaped to {len(df_2025_long)} observations\")\n",
    "    \n",
    "    # ===== COMBINE DATASETS =====\n",
    "    print(\"\\nCombining datasets...\")\n",
    "    \n",
    "    # For overlapping years (2020-2024), use 2025 file data (more recent)\n",
    "    df_2024_unique = df_2024_long[df_2024_long['year'] == 2019].copy()\n",
    "    \n",
    "    enrollment = pd.concat([df_2024_unique, df_2025_long], axis=0, ignore_index=True)\n",
    "    enrollment = enrollment.sort_values(['CIP4', 'year']).reset_index(drop=True)\n",
    "    \n",
    "    print(f\"\\n✓ Combined dataset: {len(enrollment)} observations\")\n",
    "    print(f\"  Years: {sorted(enrollment['year'].unique())}\")\n",
    "    print(f\"  Unique 4-digit CIP codes: {enrollment['CIP4'].nunique()}\")\n",
    "    \n",
    "    # Summary stats\n",
    "    print(\"\\nTotal enrollment by year:\")\n",
    "    yearly_enrollment = enrollment.groupby('year')['enrollment'].sum()\n",
    "    for year, total in yearly_enrollment.items():\n",
    "        print(f\"  {year}: {total:,.0f}\")\n",
    "    \n",
    "    return enrollment\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# STEP 7: MERGE AND FINALIZE\n",
    "# =============================================================================\n",
    "\n",
    "def merge_enrollment_exposure(\n",
    "    enrollment: pd.DataFrame,\n",
    "    cip_exposure: pd.DataFrame\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Merge enrollment data with AI exposure scores.\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"MERGING ENROLLMENT WITH AI EXPOSURE\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    # Merge on 4-digit CIP code\n",
    "    df_final = enrollment.merge(\n",
    "        cip_exposure[['CIP4', 'ai_exposure_score', 'n_obs']],\n",
    "        on='CIP4',\n",
    "        how='left'\n",
    "    )\n",
    "    \n",
    "    # Report merge success\n",
    "    n_matched = df_final['ai_exposure_score'].notna().sum()\n",
    "    pct_matched = 100 * n_matched / len(df_final)\n",
    "    print(f\"\\nMatched {n_matched}/{len(df_final)} enrollment records ({pct_matched:.1f}%)\")\n",
    "    \n",
    "    # Create treatment variables\n",
    "    median_exposure = df_final['ai_exposure_score'].median()\n",
    "    df_final['high_ai_exposure'] = (\n",
    "        df_final['ai_exposure_score'] > median_exposure\n",
    "    ).astype(int)\n",
    "    \n",
    "    # Standardized exposure\n",
    "    df_final['ai_exposure_std'] = (\n",
    "        (df_final['ai_exposure_score'] - df_final['ai_exposure_score'].mean()) /\n",
    "        df_final['ai_exposure_score'].std()\n",
    "    )\n",
    "    \n",
    "    # Terciles\n",
    "    df_final['ai_exposure_tercile'] = pd.qcut(\n",
    "        df_final['ai_exposure_score'],\n",
    "        q=3,\n",
    "        labels=['Low', 'Medium', 'High'],\n",
    "        duplicates='drop'\n",
    "    )\n",
    "    \n",
    "    # Create log enrollment\n",
    "    df_final['log_enrollment'] = np.log(df_final['enrollment'] + 1)\n",
    "    \n",
    "    print(\"\\n\\nFinal dataset:\")\n",
    "    print(df_final.head(20))\n",
    "    print(f\"\\nShape: {df_final.shape}\")\n",
    "    \n",
    "    return df_final\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# STEP 8: VISUALIZATION\n",
    "# =============================================================================\n",
    "\n",
    "def create_descriptive_plots(df: pd.DataFrame, output_path: str = 'enrollment_trends_4digit.png'):\n",
    "    \"\"\"\n",
    "    Create descriptive visualizations for 4-digit CIP analysis.\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"CREATING VISUALIZATIONS\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "    \n",
    "    # 1. Enrollment trends by AI exposure group\n",
    "    ax1 = axes[0, 0]\n",
    "    trend_data = df.groupby(['year', 'high_ai_exposure'])['enrollment'].sum().reset_index()\n",
    "    for group in [0, 1]:\n",
    "        data = trend_data[trend_data['high_ai_exposure'] == group]\n",
    "        label = 'High AI Exposure' if group else 'Low AI Exposure'\n",
    "        ax1.plot(data['year'], data['enrollment'], marker='o', label=label, linewidth=2)\n",
    "    ax1.set_xlabel('Year', fontsize=12)\n",
    "    ax1.set_ylabel('Total Enrollment', fontsize=12)\n",
    "    ax1.set_title('Enrollment Trends by AI Exposure (4-digit CIP)', fontsize=14, fontweight='bold')\n",
    "    ax1.legend()\n",
    "    ax1.grid(alpha=0.3)\n",
    "    ax1.axvline(2022.5, color='red', linestyle='--', alpha=0.5, label='ChatGPT Launch')\n",
    "    \n",
    "    # 2. Distribution of AI exposure\n",
    "    ax2 = axes[0, 1]\n",
    "    cip_scores = df.groupby('CIP4')['ai_exposure_score'].first()\n",
    "    ax2.hist(cip_scores, bins=50, edgecolor='black', alpha=0.7, color='steelblue')\n",
    "    ax2.axvline(cip_scores.median(), color='red', linestyle='--', linewidth=2, label='Median')\n",
    "    ax2.set_xlabel('AI Exposure Score', fontsize=12)\n",
    "    ax2.set_ylabel('Number of 4-digit CIP Codes', fontsize=12)\n",
    "    ax2.set_title('Distribution of AI Exposure Across Majors', fontsize=14, fontweight='bold')\n",
    "    ax2.legend()\n",
    "    ax2.grid(alpha=0.3)\n",
    "    \n",
    "    # 3. Scatter: enrollment growth vs exposure\n",
    "    ax3 = axes[1, 0]\n",
    "    first_year = df['year'].min()\n",
    "    last_year = df['year'].max()\n",
    "    \n",
    "    growth_data = []\n",
    "    for cip in df['CIP4'].unique():\n",
    "        cip_data = df[df['CIP4'] == cip]\n",
    "        enroll_first = cip_data[cip_data['year'] == first_year]['enrollment'].values\n",
    "        enroll_last = cip_data[cip_data['year'] == last_year]['enrollment'].values\n",
    "        if len(enroll_first) > 0 and len(enroll_last) > 0 and enroll_first[0] > 0:\n",
    "            growth = (enroll_last[0] - enroll_first[0]) / enroll_first[0] * 100\n",
    "            exposure = cip_data['ai_exposure_score'].iloc[0] if len(cip_data) > 0 else None\n",
    "            if exposure is not None and pd.notna(exposure):\n",
    "                growth_data.append({'CIP4': cip, 'growth_rate': growth, 'ai_exposure': exposure})\n",
    "    \n",
    "    growth_df = pd.DataFrame(growth_data)\n",
    "    if len(growth_df) > 0:\n",
    "        ax3.scatter(growth_df['ai_exposure'], growth_df['growth_rate'], alpha=0.6, s=30)\n",
    "        ax3.set_xlabel('AI Exposure Score', fontsize=12)\n",
    "        ax3.set_ylabel(f'Enrollment Growth Rate ({first_year}-{last_year}, %)', fontsize=12)\n",
    "        ax3.set_title('Growth Rate vs AI Exposure', fontsize=14, fontweight='bold')\n",
    "        ax3.axhline(0, color='black', linestyle='--', linewidth=1, alpha=0.5)\n",
    "        ax3.grid(alpha=0.3)\n",
    "        \n",
    "        # Add correlation\n",
    "        corr = growth_df[['ai_exposure', 'growth_rate']].corr().iloc[0, 1]\n",
    "        ax3.text(0.05, 0.95, f'Correlation: {corr:.3f}', \n",
    "                transform=ax3.transAxes, verticalalignment='top',\n",
    "                bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))\n",
    "    \n",
    "    # 4. Enrollment by tercile over time\n",
    "    ax4 = axes[1, 1]\n",
    "    tercile_data = df.groupby(['year', 'ai_exposure_tercile'])['enrollment'].sum().reset_index()\n",
    "    for tercile in ['Low', 'Medium', 'High']:\n",
    "        data = tercile_data[tercile_data['ai_exposure_tercile'] == tercile]\n",
    "        if len(data) > 0:\n",
    "            ax4.plot(data['year'], data['enrollment'], marker='o', label=f'{tercile} Exposure', linewidth=2)\n",
    "    ax4.set_xlabel('Year', fontsize=12)\n",
    "    ax4.set_ylabel('Total Enrollment', fontsize=12)\n",
    "    ax4.set_title('Enrollment by AI Exposure Tercile', fontsize=14, fontweight='bold')\n",
    "    ax4.legend()\n",
    "    ax4.grid(alpha=0.3)\n",
    "    ax4.axvline(2022.5, color='red', linestyle='--', alpha=0.5)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(output_path, dpi=300, bbox_inches='tight')\n",
    "    print(f\"\\n✓ Saved plots to {output_path}\")\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# MAIN EXECUTION\n",
    "# =============================================================================\n",
    "\n",
    "def main():\n",
    "    \"\"\"\n",
    "    Main execution function.\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"\\n\" + \"#\"*70)\n",
    "    print(\"# AI EXPOSURE AND ENROLLMENT ANALYSIS - 4-DIGIT CIP\")\n",
    "    print(\"#\"*70 + \"\\n\")\n",
    "    \n",
    "    # FILE PATHS\n",
    "    FELTEN_PATH = '/Users/jeffreyohl/Dropbox/CollegeMajorData/FeltenEtAl/AIOE_DataAppendix.xlsx'\n",
    "    CROSSWALK_PATH = '/Users/jeffreyohl/Dropbox/CollegeMajorData/Crosswalks/crosswalk_handout.xlsx'\n",
    "    ACS_PATH = '/Users/jeffreyohl/Dropbox/CollegeMajorData/IPUMS/usa_00008.csv'\n",
    "    ENROLLMENT_PATH_2025 = '/Users/jeffreyohl/Dropbox/CollegeMajorData/National Student Clearinghouse Data/CTEESpring2025-DataAppendix.xlsx'\n",
    "    ENROLLMENT_PATH_2024 = '/Users/jeffreyohl/Dropbox/CollegeMajorData/National Student Clearinghouse Data/CTEESpring2024-Appendix.xlsx'\n",
    "    OUTPUT_DIR = '/Users/jeffreyohl/Dropbox/CollegeMajorData/output'\n",
    "    \n",
    "    try:\n",
    "        # Step 1: Load Felten data\n",
    "        felten = load_felten_data(FELTEN_PATH)\n",
    "        \n",
    "        # Step 2: Load FOD to 4-digit CIP crosswalk\n",
    "        fod_to_cip4 = load_fod_cip4_crosswalk(CROSSWALK_PATH)\n",
    "        \n",
    "        # Step 3-5: Process ACS and calculate exposure scores\n",
    "        print(\"\\n\" + \"=\"*70)\n",
    "        print(\"PROCESSING ACS DATA\")\n",
    "        print(\"=\"*70)\n",
    "        acs = load_and_filter_acs(ACS_PATH)\n",
    "        acs_with_exposure = process_acs_with_exposure(acs, felten, fod_to_cip4)\n",
    "        cip_exposure = calculate_cip4_exposure(acs_with_exposure)\n",
    "        \n",
    "        # Save exposure scores\n",
    "        cip_exposure.to_csv(f'{OUTPUT_DIR}/cip4_ai_exposure_scores.csv', index=False)\n",
    "        print(f\"\\n✓ Saved exposure scores to {OUTPUT_DIR}/cip4_ai_exposure_scores.csv\")\n",
    "        \n",
    "        # Step 6: Load and combine enrollment data (2019-2025)\n",
    "        enrollment = load_and_combine_enrollment_data(ENROLLMENT_PATH_2024, ENROLLMENT_PATH_2025)\n",
    "        \n",
    "        # Step 7: Merge enrollment with exposure\n",
    "        df_final = merge_enrollment_exposure(enrollment, cip_exposure)\n",
    "        \n",
    "        # Save final dataset\n",
    "        df_final.to_csv(f'{OUTPUT_DIR}/enrollment_with_ai_exposure_4digit.csv', index=False)\n",
    "        print(f\"\\n✓ Saved final dataset to {OUTPUT_DIR}/enrollment_with_ai_exposure_4digit.csv\")\n",
    "        \n",
    "        # Step 8: Create visualizations\n",
    "        create_descriptive_plots(df_final, f'{OUTPUT_DIR}/enrollment_trends_4digit.png')\n",
    "        \n",
    "        print(\"\\n\" + \"#\"*70)\n",
    "        print(\"# DATA PREPARATION COMPLETE (4-DIGIT CIP)\")\n",
    "        print(\"#\"*70)\n",
    "        print(\"\\nNext steps:\")\n",
    "        print(\"1. Review cip4_ai_exposure_scores.csv to validate exposure scores\")\n",
    "        print(\"2. Check enrollment_with_ai_exposure_4digit.csv for data quality\")\n",
    "        print(\"3. Run econometric_analysis.py for DiD and event study\")\n",
    "        print(\"\\n4-digit CIP analysis provides:\")\n",
    "        print(\"  - Computer Science (1107) vs Information Systems (1104)\")\n",
    "        print(\"  - Business Administration (5202) vs Finance (5208) vs Accounting (5203)\")  \n",
    "        print(\"  - More granular treatment effects and heterogeneity analysis\")\n",
    "        \n",
    "    except FileNotFoundError as e:\n",
    "        print(f\"\\n❌ Error: File not found - {e}\")\n",
    "        print(\"\\nPlease check that all data files exist at the specified paths:\")\n",
    "        print(f\"  - Felten: {FELTEN_PATH}\")\n",
    "        print(f\"  - Crosswalk: {CROSSWALK_PATH}\")\n",
    "        print(f\"  - ACS: {ACS_PATH}\")\n",
    "        print(f\"  - Enrollment 2024: {ENROLLMENT_PATH_2024}\")\n",
    "        print(f\"  - Enrollment 2025: {ENROLLMENT_PATH_2025}\")\n",
    "    except Exception as e:\n",
    "        print(f\"\\n❌ Error occurred: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run main analysis\n",
    "main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
