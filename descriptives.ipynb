{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "######################################################################\n",
      "# AI EXPOSURE AND ENROLLMENT ANALYSIS - 4-DIGIT CIP\n",
      "######################################################################\n",
      "\n",
      "======================================================================\n",
      "LOADING FELTEN AIOE DATA\n",
      "======================================================================\n",
      "\n",
      "Loaded 774 occupations\n",
      "AIOE range: -2.67 to 1.53\n",
      "\n",
      "======================================================================\n",
      "LOADING FOD TO 4-DIGIT CIP CROSSWALK\n",
      "======================================================================\n",
      "\n",
      "Mapped 191 FOD codes to 4-digit CIP codes\n",
      "\n",
      "Sample mappings:\n",
      "  FOD 1100 → CIP4 0100\n",
      "  FOD 1101 → CIP4 0106\n",
      "  FOD 1102 → CIP4 0100\n",
      "  FOD 1103 → CIP4 0109\n",
      "  FOD 1104 → CIP4 0110\n",
      "  FOD 1105 → CIP4 0111\n",
      "  FOD 1106 → CIP4 0112\n",
      "  FOD 1199 → CIP4 0108\n",
      "  FOD 1301 → CIP4 0301\n",
      "  FOD 1302 → CIP4 0305\n",
      "  FOD 1303 → CIP4 0302\n",
      "  FOD 1401 → CIP4 0400\n",
      "  FOD 1501 → CIP4 0501\n",
      "  FOD 1901 → CIP4 0901\n",
      "  FOD 1902 → CIP4 0904\n",
      "  FOD 1903 → CIP4 0907\n",
      "  FOD 1904 → CIP4 0909\n",
      "  FOD 2001 → CIP4 1003\n",
      "  FOD 2100 → CIP4 1101\n",
      "  FOD 2101 → CIP4 1102\n",
      "\n",
      "✓ Computer Science: FOD 2102 → CIP4 1100\n",
      "\n",
      "======================================================================\n",
      "PROCESSING ACS DATA\n",
      "======================================================================\n",
      "\n",
      "======================================================================\n",
      "LOADING ACS PUMS DATA\n",
      "======================================================================\n",
      "\n",
      "Initial sample: 4,770,082 observations\n",
      "Filtered sample: 1,405,906 observations\n",
      "  - Age 22-35\n",
      "  - Valid occupation (OCCSOC) and field of degree (DEGFIELDD)\n",
      "\n",
      "Unique DEGFIELDD codes: 175\n",
      "Unique OCCSOC codes: 530\n",
      "\n",
      "======================================================================\n",
      "MAPPING FOD TO 4-DIGIT CIP AND MERGING AI EXPOSURE\n",
      "======================================================================\n",
      "\n",
      "Mapped 896,320/1,405,906 observations to CIP4 (63.8%)\n",
      "\n",
      "Top 10 unmapped FOD codes:\n",
      "DEGFIELDD\n",
      "0       497608\n",
      "5098      5853\n",
      "3611      2970\n",
      "4000      2238\n",
      "5008       856\n",
      "4009        34\n",
      "1107        27\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Matched 461,765/896,320 observations to AI exposure (51.5%)\n",
      "\n",
      "⚠ Imputing 434555 missing AIOE values with mean (0.6499)\n",
      "\n",
      "Final sample: 896,320 observations\n",
      "Unique 4-digit CIP codes: 114\n",
      "\n",
      "======================================================================\n",
      "CALCULATING 4-DIGIT CIP-LEVEL AI EXPOSURE SCORES\n",
      "======================================================================\n",
      "\n",
      "Calculated AI exposure for 114 4-digit CIP codes\n",
      "\n",
      "AI Exposure Score Distribution:\n",
      "count    114.000000\n",
      "mean       0.604038\n",
      "std        0.143527\n",
      "min        0.106418\n",
      "25%        0.550558\n",
      "50%        0.622390\n",
      "75%        0.677311\n",
      "max        1.071093\n",
      "Name: ai_exposure_score, dtype: float64\n",
      "\n",
      "\n",
      "Top 20 most AI-exposed majors (4-digit CIP):\n",
      "     CIP4  ai_exposure_score    n_obs\n",
      "105  5203           1.071093  26092.0\n",
      "107  5208           0.904944  21972.0\n",
      "30   1408           0.893621   8613.0\n",
      "80   4506           0.815386  17931.0\n",
      "69   4004           0.812050    531.0\n",
      "25   1311           0.808718    207.0\n",
      "93   5102           0.799797   5111.0\n",
      "15   0909           0.785925   5483.0\n",
      "10   0400           0.763493   6144.0\n",
      "111  5219           0.754308  22448.0\n",
      "60   2705           0.754267   1453.0\n",
      "59   2703           0.744304   1262.0\n",
      "109  5210           0.728584   3458.0\n",
      "104  5202           0.725977  43260.0\n",
      "13   0904           0.722950   7398.0\n",
      "94   5107           0.722852   3978.0\n",
      "29   1400           0.722367  61846.0\n",
      "41   2200           0.719326   1385.0\n",
      "82   4510           0.716958  20273.0\n",
      "76   4400           0.716954   3516.0\n",
      "\n",
      "\n",
      "Bottom 20 least AI-exposed majors (4-digit CIP):\n",
      "     CIP4  ai_exposure_score    n_obs\n",
      "84   4706           0.106418    307.0\n",
      "73   4102           0.127971    279.0\n",
      "21   1204           0.200252   1007.0\n",
      "3    0109           0.293108   3643.0\n",
      "52   2607           0.317896    907.0\n",
      "98   5116           0.320429  39347.0\n",
      "96   5109           0.329488   2526.0\n",
      "9    0305           0.331092    742.0\n",
      "101  5123           0.353892   6435.0\n",
      "64   3105           0.369885  20404.0\n",
      "5    0111           0.397873   1434.0\n",
      "87   5003           0.432913   1924.0\n",
      "95   5108           0.479110   1455.0\n",
      "54   2609           0.483783   3231.0\n",
      "0    0100           0.484601   2157.0\n",
      "89   5005           0.492623   5459.0\n",
      "75   4301           0.496753  21185.0\n",
      "8    0302           0.501062   2643.0\n",
      "1    0106           0.501707   2584.0\n",
      "108  5209           0.503084   5536.0\n",
      "\n",
      "✓ Saved exposure scores to /Users/jeffreyohl/Dropbox/CollegeMajorData/output/cip4_ai_exposure_scores.csv\n",
      "\n",
      "======================================================================\n",
      "LOADING AND COMBINING ENROLLMENT DATA (2019-2025)\n",
      "======================================================================\n",
      "\n",
      "Loading 2019-2024 data from CTEESpring2024-Appendix.xlsx...\n",
      "  Loaded 488 rows\n",
      "  Found 6 enrollment columns for years 2019-2024\n",
      "  Reshaped to 2001 observations\n",
      "\n",
      "Loading 2020-2025 data from CTEESpring2025-DataAppendix.xlsx...\n",
      "  Loaded 1410 rows\n",
      "  Filtered to 470 Undergraduate 4-year rows\n",
      "  Reshaped to 2097 observations\n",
      "\n",
      "Combining datasets...\n",
      "\n",
      "✓ Combined dataset: 2421 observations\n",
      "  Years: [np.int64(2019), np.int64(2020), np.int64(2021), np.int64(2022), np.int64(2023), np.int64(2024), np.int64(2025)]\n",
      "  Unique 4-digit CIP codes: 390\n",
      "\n",
      "Total enrollment by year:\n",
      "  2019: 8,881,017\n",
      "  2020: 8,836,845\n",
      "  2021: 8,690,353\n",
      "  2022: 8,581,948\n",
      "  2023: 8,456,944\n",
      "  2024: 8,669,730\n",
      "  2025: 8,877,394\n",
      "\n",
      "======================================================================\n",
      "MERGING ENROLLMENT WITH AI EXPOSURE\n",
      "======================================================================\n",
      "\n",
      "Matched 665/2421 enrollment records (27.5%)\n",
      "\n",
      "\n",
      "Final dataset:\n",
      "    CIP4  year    enrollment  ai_exposure_score   n_obs  high_ai_exposure  \\\n",
      "0   0100  2019   9519.068031           0.484601  2157.0                 0   \n",
      "1   0100  2020   9282.396944           0.484601  2157.0                 0   \n",
      "2   0100  2021   9147.125698           0.484601  2157.0                 0   \n",
      "3   0100  2022   8410.844989           0.484601  2157.0                 0   \n",
      "4   0100  2023   8616.469810           0.484601  2157.0                 0   \n",
      "5   0100  2024   8706.931635           0.484601  2157.0                 0   \n",
      "6   0100  2025   8644.549148           0.484601  2157.0                 0   \n",
      "7   0101  2019  18059.790261                NaN     NaN                 0   \n",
      "8   0101  2020  17627.500204                NaN     NaN                 0   \n",
      "9   0101  2021  16472.834741                NaN     NaN                 0   \n",
      "10  0101  2022  16076.321122                NaN     NaN                 0   \n",
      "11  0101  2023  14674.973222                NaN     NaN                 0   \n",
      "12  0101  2024  17441.527090                NaN     NaN                 0   \n",
      "13  0101  2025  17907.299601                NaN     NaN                 0   \n",
      "14  0102  2019   1259.195858                NaN     NaN                 0   \n",
      "15  0102  2020   1123.517786                NaN     NaN                 0   \n",
      "16  0102  2021   1006.194094                NaN     NaN                 0   \n",
      "17  0102  2022    936.594522                NaN     NaN                 0   \n",
      "18  0102  2023    926.160247                NaN     NaN                 0   \n",
      "19  0102  2024    928.274895                NaN     NaN                 0   \n",
      "\n",
      "    ai_exposure_std ai_exposure_tercile  log_enrollment  \n",
      "0         -0.824341                 Low        9.161157  \n",
      "1         -0.824341                 Low        9.135983  \n",
      "2         -0.824341                 Low        9.121304  \n",
      "3         -0.824341                 Low        9.037396  \n",
      "4         -0.824341                 Low        9.061547  \n",
      "5         -0.824341                 Low        9.071990  \n",
      "6         -0.824341                 Low        9.064800  \n",
      "7               NaN                 NaN        9.801499  \n",
      "8               NaN                 NaN        9.777272  \n",
      "9               NaN                 NaN        9.709529  \n",
      "10              NaN                 NaN        9.685165  \n",
      "11              NaN                 NaN        9.593967  \n",
      "12              NaN                 NaN        9.766667  \n",
      "13              NaN                 NaN        9.793020  \n",
      "14              NaN                 NaN        7.139022  \n",
      "15              NaN                 NaN        7.025110  \n",
      "16              NaN                 NaN        6.914924  \n",
      "17              NaN                 NaN        6.843318  \n",
      "18              NaN                 NaN        6.832126  \n",
      "19              NaN                 NaN        6.834405  \n",
      "\n",
      "Shape: (2421, 9)\n",
      "\n",
      "✓ Saved final dataset to /Users/jeffreyohl/Dropbox/CollegeMajorData/output/enrollment_with_ai_exposure_4digit.csv\n",
      "\n",
      "======================================================================\n",
      "CREATING VISUALIZATIONS\n",
      "======================================================================\n",
      "\n",
      "✓ Saved plots to /Users/jeffreyohl/Dropbox/CollegeMajorData/output/enrollment_trends_4digit.png\n",
      "\n",
      "######################################################################\n",
      "# DATA PREPARATION COMPLETE (4-DIGIT CIP)\n",
      "######################################################################\n",
      "\n",
      "Next steps:\n",
      "1. Review cip4_ai_exposure_scores.csv to validate exposure scores\n",
      "2. Check enrollment_with_ai_exposure_4digit.csv for data quality\n",
      "3. Run econometric_analysis.py for DiD and event study\n",
      "\n",
      "4-digit CIP analysis provides:\n",
      "  - Computer Science (1107) vs Information Systems (1104)\n",
      "  - Business Administration (5202) vs Finance (5208) vs Accounting (5203)\n",
      "  - More granular treatment effects and heterogeneity analysis\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "AI Exposure and College Enrollment Analysis - 4-DIGIT CIP VERSION\n",
    "==================================================================\n",
    "Updated for:\n",
    "- 4-digit CIP codes (436 programs vs 49 at 2-digit level)\n",
    "- 2019-2025 enrollment data (combined from both files)\n",
    "- More granular analysis (e.g., Computer Science vs Information Systems)\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from typing import Dict\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# =============================================================================\n",
    "# STEP 1: LOAD FELTEN AIOE DATA\n",
    "# =============================================================================\n",
    "\n",
    "def load_felten_data(filepath: str) -> pd.DataFrame:\n",
    "    \"\"\"Load Felten et al. (2021) AIOE scores.\"\"\"\n",
    "    print(\"=\"*70)\n",
    "    print(\"LOADING FELTEN AIOE DATA\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    felten = pd.read_excel(filepath, sheet_name='Appendix A')\n",
    "    felten['soc_clean'] = felten['SOC Code'].str.replace('-', '').str.replace('.', '')\n",
    "    \n",
    "    print(f\"\\nLoaded {len(felten)} occupations\")\n",
    "    print(f\"AIOE range: {felten['AIOE'].min():.2f} to {felten['AIOE'].max():.2f}\")\n",
    "    \n",
    "    return felten\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# STEP 2: LOAD FOD TO 4-DIGIT CIP CROSSWALK\n",
    "# =============================================================================\n",
    "\n",
    "def load_fod_cip4_crosswalk(filepath: str) -> Dict[int, str]:\n",
    "    \"\"\"\n",
    "    Load FOD to 4-digit CIP mapping from crosswalk file.\n",
    "    \n",
    "    The crosswalk has detailed 6-digit CIP codes (like 11.0701).\n",
    "    We extract 4-digit CIP:\n",
    "    - Family (2 digits): 11 = Computer Science\n",
    "    - Group (next 2 digits): 07 = Computer Science \n",
    "    - Combined: 1107 = Computer Science (4-digit)\n",
    "    \n",
    "    Examples:\n",
    "    - 11.0000 → 1100 (Computer Science, General)\n",
    "    - 11.0701 → 1107 (Computer Science)\n",
    "    - 52.0201 → 5202 (Business Administration)\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    Dict mapping FOD code (int) to 4-digit CIP string (e.g., '1107')\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"LOADING FOD TO 4-DIGIT CIP CROSSWALK\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    # Read from \"CIP code by HHES code\" sheet\n",
    "    df = pd.read_excel(filepath, sheet_name='CIP code by HHES code', skiprows=1)\n",
    "    \n",
    "    # Extract FOD and CIP columns\n",
    "    crosswalk = df[['HHES Code', 'CIP \\nCode']].copy()\n",
    "    crosswalk.columns = ['FOD', 'CIP']\n",
    "    crosswalk = crosswalk.dropna(subset=['FOD', 'CIP'])\n",
    "    \n",
    "    # Convert FOD to integer\n",
    "    crosswalk['FOD'] = crosswalk['FOD'].astype(int)\n",
    "    \n",
    "    # Extract 4-digit CIP from 6-digit CIP code\n",
    "    # CIP format: XX.XXXX where first 2 are family, next 2 are group\n",
    "    # E.g., 11.0701 → 1107\n",
    "    def extract_cip4(cip_6digit):\n",
    "        try:\n",
    "            cip_float = float(cip_6digit)\n",
    "            # Get integer part (family, 2 digits)\n",
    "            family = int(cip_float)  # e.g., 11\n",
    "            # Get first 2 decimal digits (group)\n",
    "            decimal_part = cip_float - family  # e.g., 0.0701\n",
    "            # Extract first 2 decimal digits\n",
    "            group = int(round(decimal_part * 10000)) // 100  # e.g., 07\n",
    "            # Combine to 4-digit code\n",
    "            cip4 = f\"{family:02d}{group:02d}\"  # e.g., \"1107\"\n",
    "            return cip4\n",
    "        except:\n",
    "            return None\n",
    "    \n",
    "    crosswalk['CIP4'] = crosswalk['CIP'].apply(extract_cip4)\n",
    "    crosswalk = crosswalk.dropna(subset=['CIP4'])\n",
    "    \n",
    "    # For each FOD, use the modal (most common) 4-digit CIP\n",
    "    # (some FOD codes map to multiple detailed CIPs within same 4-digit group)\n",
    "    fod_to_cip4 = crosswalk.groupby('FOD')['CIP4'].agg(lambda x: x.mode()[0] if len(x.mode()) > 0 else x.iloc[0]).to_dict()\n",
    "    \n",
    "    print(f\"\\nMapped {len(fod_to_cip4)} FOD codes to 4-digit CIP codes\")\n",
    "    \n",
    "    # Show sample mappings\n",
    "    print(\"\\nSample mappings:\")\n",
    "    for fod in sorted(fod_to_cip4.keys())[:20]:\n",
    "        print(f\"  FOD {fod} → CIP4 {fod_to_cip4[fod]}\")\n",
    "    \n",
    "    # Check Computer Science specifically (FOD 2102)\n",
    "    if 2102 in fod_to_cip4:\n",
    "        print(f\"\\n✓ Computer Science: FOD 2102 → CIP4 {fod_to_cip4[2102]}\")\n",
    "    \n",
    "    return fod_to_cip4\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# STEP 3: LOAD AND PROCESS ACS PUMS DATA\n",
    "# =============================================================================\n",
    "\n",
    "def load_and_filter_acs(\n",
    "    filepath: str,\n",
    "    age_min: int = 22,\n",
    "    age_max: int = 35\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Load and filter IPUMS ACS PUMS data.\n",
    "    \n",
    "    Your ACS columns: DEGFIELDD, OCCSOC, PERWT, AGE, EDUC, YEAR\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"LOADING ACS PUMS DATA\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    acs = pd.read_csv(filepath)\n",
    "    \n",
    "    print(f\"\\nInitial sample: {len(acs):,} observations\")\n",
    "    \n",
    "    # Filter\n",
    "    acs_filtered = acs[\n",
    "        (acs['AGE'] >= age_min) & \n",
    "        (acs['AGE'] <= age_max) &\n",
    "        (acs['OCCSOC'].notna()) &\n",
    "        (acs['DEGFIELDD'].notna())\n",
    "    ].copy()\n",
    "    \n",
    "    print(f\"Filtered sample: {len(acs_filtered):,} observations\")\n",
    "    print(f\"  - Age {age_min}-{age_max}\")\n",
    "    print(f\"  - Valid occupation (OCCSOC) and field of degree (DEGFIELDD)\")\n",
    "    \n",
    "    # Clean SOC codes\n",
    "    acs_filtered['soc_clean'] = acs_filtered['OCCSOC'].astype(str).str.replace('-', '').str.replace('.', '')\n",
    "    \n",
    "    print(f\"\\nUnique DEGFIELDD codes: {acs_filtered['DEGFIELDD'].nunique()}\")\n",
    "    print(f\"Unique OCCSOC codes: {acs_filtered['OCCSOC'].nunique()}\")\n",
    "    \n",
    "    return acs_filtered\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# STEP 4: MAP FOD TO 4-DIGIT CIP AND MERGE WITH EXPOSURE\n",
    "# =============================================================================\n",
    "\n",
    "def process_acs_with_exposure(\n",
    "    acs: pd.DataFrame,\n",
    "    felten: pd.DataFrame,\n",
    "    fod_to_cip4: Dict[int, str]\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Map ACS FOD codes to 4-digit CIP, merge with AI exposure scores.\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"MAPPING FOD TO 4-DIGIT CIP AND MERGING AI EXPOSURE\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    # Map FOD to CIP4\n",
    "    acs['CIP4'] = acs['DEGFIELDD'].map(fod_to_cip4)\n",
    "    \n",
    "    # Report mapping success\n",
    "    n_mapped = acs['CIP4'].notna().sum()\n",
    "    pct_mapped = 100 * n_mapped / len(acs)\n",
    "    print(f\"\\nMapped {n_mapped:,}/{len(acs):,} observations to CIP4 ({pct_mapped:.1f}%)\")\n",
    "    \n",
    "    # Check unmapped FODs\n",
    "    if acs['CIP4'].isna().any():\n",
    "        unmapped_fods = acs[acs['CIP4'].isna()]['DEGFIELDD'].value_counts().head(10)\n",
    "        print(\"\\nTop 10 unmapped FOD codes:\")\n",
    "        print(unmapped_fods)\n",
    "    \n",
    "    # Filter to successfully mapped\n",
    "    acs_mapped = acs[acs['CIP4'].notna()].copy()\n",
    "    \n",
    "    # Merge with Felten AIOE scores on SOC code\n",
    "    acs_with_exposure = acs_mapped.merge(\n",
    "        felten[['soc_clean', 'AIOE']],\n",
    "        on='soc_clean',\n",
    "        how='left'\n",
    "    )\n",
    "    \n",
    "    # Report merge success\n",
    "    n_matched = acs_with_exposure['AIOE'].notna().sum()\n",
    "    pct_matched = 100 * n_matched / len(acs_with_exposure)\n",
    "    print(f\"\\nMatched {n_matched:,}/{len(acs_with_exposure):,} observations to AI exposure ({pct_matched:.1f}%)\")\n",
    "    \n",
    "    # Handle missing AIOE scores (impute with mean)\n",
    "    mean_aioe = acs_with_exposure['AIOE'].mean()\n",
    "    n_missing = acs_with_exposure['AIOE'].isna().sum()\n",
    "    if n_missing > 0:\n",
    "        print(f\"\\n⚠ Imputing {n_missing} missing AIOE values with mean ({mean_aioe:.4f})\")\n",
    "        acs_with_exposure['AIOE'].fillna(mean_aioe, inplace=True)\n",
    "    \n",
    "    print(f\"\\nFinal sample: {len(acs_with_exposure):,} observations\")\n",
    "    print(f\"Unique 4-digit CIP codes: {acs_with_exposure['CIP4'].nunique()}\")\n",
    "    \n",
    "    return acs_with_exposure\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# STEP 5: CALCULATE 4-DIGIT CIP-LEVEL AI EXPOSURE\n",
    "# =============================================================================\n",
    "\n",
    "def calculate_cip4_exposure(\n",
    "    acs: pd.DataFrame,\n",
    "    weight_var: str = 'PERWT'\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Calculate weighted average AI exposure by 4-digit CIP code.\n",
    "    \n",
    "    For each CIP4: AI_exposure = Σ [P(occupation|CIP4) × AIOE(occupation)]\n",
    "    where P(occupation|CIP4) is weighted by person weights.\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"CALCULATING 4-DIGIT CIP-LEVEL AI EXPOSURE SCORES\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    # Calculate weighted average by CIP4\n",
    "    cip_exposure = acs.groupby('CIP4').apply(\n",
    "        lambda x: pd.Series({\n",
    "            'ai_exposure_score': np.average(x['AIOE'], weights=x[weight_var]),\n",
    "            'n_obs': len(x),\n",
    "            'n_weighted': x[weight_var].sum(),\n",
    "            'min_exposure': x['AIOE'].min(),\n",
    "            'max_exposure': x['AIOE'].max(),\n",
    "            'std_exposure': np.sqrt(np.average((x['AIOE'] - np.average(x['AIOE'], weights=x[weight_var]))**2, \n",
    "                                                weights=x[weight_var]))\n",
    "        })\n",
    "    ).reset_index()\n",
    "    \n",
    "    print(f\"\\nCalculated AI exposure for {len(cip_exposure)} 4-digit CIP codes\")\n",
    "    print(\"\\nAI Exposure Score Distribution:\")\n",
    "    print(cip_exposure['ai_exposure_score'].describe())\n",
    "    \n",
    "    # Show top and bottom CIPs\n",
    "    print(\"\\n\\nTop 20 most AI-exposed majors (4-digit CIP):\")\n",
    "    top20 = cip_exposure.nlargest(20, 'ai_exposure_score')[['CIP4', 'ai_exposure_score', 'n_obs']]\n",
    "    print(top20)\n",
    "    \n",
    "    print(\"\\n\\nBottom 20 least AI-exposed majors (4-digit CIP):\")\n",
    "    bottom20 = cip_exposure.nsmallest(20, 'ai_exposure_score')[['CIP4', 'ai_exposure_score', 'n_obs']]\n",
    "    print(bottom20)\n",
    "    \n",
    "    return cip_exposure\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# STEP 6: LOAD AND COMBINE ENROLLMENT DATA (2019-2025)\n",
    "# =============================================================================\n",
    "\n",
    "def load_and_combine_enrollment_data(\n",
    "    filepath_2024: str, \n",
    "    filepath_2025: str\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Load and combine enrollment data from two sources with proper header handling.\n",
    "    \n",
    "    2024 file: Major Field (4-year, Undergrad) sheet, years 2019-2024\n",
    "    2025 file: CIP Group Enrollment sheet, years 2020-2025 (filter to Undergraduate 4-year)\n",
    "    \n",
    "    Returns combined dataset with 4-digit CIP codes (2019-2025).\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"LOADING AND COMBINING ENROLLMENT DATA (2019-2025)\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    # ===== LOAD 2024 FILE =====\n",
    "    print(\"\\nLoading 2019-2024 data from CTEESpring2024-Appendix.xlsx...\")\n",
    "    df_2024 = pd.read_excel(\n",
    "        filepath_2024, \n",
    "        sheet_name='Major Field (4-year, Undergrad)',\n",
    "        header=2  # Row 2 has the actual column headers\n",
    "    )\n",
    "    print(f\"  Loaded {len(df_2024)} rows\")\n",
    "    \n",
    "    # Rename columns for clarity\n",
    "    df_2024 = df_2024.rename(columns={\n",
    "        'Major Field Family (2-digit CIP)': 'CIP2',\n",
    "        'Major Field Family (2-digit) Title': 'CIP2_title',\n",
    "        'Major Field Group (4-digit CIP)': 'CIP4',\n",
    "        'Major Field Group (4-digit) Title': 'CIP4_title'\n",
    "    })\n",
    "    \n",
    "    # Get enrollment columns (years 2019-2024)\n",
    "    years_2024 = [2019, 2020, 2021, 2022, 2023, 2024]\n",
    "    enrollment_cols = [col for col in df_2024.columns if 'Enrollment' in str(col) and '% Change' not in str(col)]\n",
    "    print(f\"  Found {len(enrollment_cols)} enrollment columns for years 2019-2024\")\n",
    "    \n",
    "    # Reshape to long format\n",
    "    data_2024 = []\n",
    "    for idx, row in df_2024.iterrows():\n",
    "        cip4 = row['CIP4']\n",
    "        if pd.isna(cip4) or cip4 == 'Total':\n",
    "            continue\n",
    "        for year, col in zip(years_2024, enrollment_cols):\n",
    "            enrollment = row[col]\n",
    "            if pd.notna(enrollment) and enrollment != '*':\n",
    "                data_2024.append({\n",
    "                    'CIP4': str(cip4)[:4] if pd.notna(cip4) and str(cip4) != 'Total' else None,\n",
    "                    'year': year,\n",
    "                    'enrollment': float(enrollment)\n",
    "                })\n",
    "    \n",
    "    df_2024_long = pd.DataFrame(data_2024)\n",
    "    print(f\"  Reshaped to {len(df_2024_long)} observations\")\n",
    "    \n",
    "    # ===== LOAD 2025 FILE =====\n",
    "    print(\"\\nLoading 2020-2025 data from CTEESpring2025-DataAppendix.xlsx...\")\n",
    "    df_2025 = pd.read_excel(\n",
    "        filepath_2025,\n",
    "        sheet_name='CIP Group Enrollment',\n",
    "        header=2  # Row 2 has the actual column headers\n",
    "    )\n",
    "    print(f\"  Loaded {len(df_2025)} rows\")\n",
    "    \n",
    "    # Filter to Undergraduate 4-year only\n",
    "    df_2025 = df_2025[df_2025['Award Level and Institution Type'] == 'Undergraduate 4-year'].copy()\n",
    "    print(f\"  Filtered to {len(df_2025)} Undergraduate 4-year rows\")\n",
    "    \n",
    "    # Rename columns\n",
    "    df_2025 = df_2025.rename(columns={\n",
    "        'Major Field Family \\n(2-digit CIP)': 'CIP2',\n",
    "        'Major Field Family \\n(2-digit CIP) Title': 'CIP2_title',\n",
    "        'Major Field Group \\n(4-digit CIP)': 'CIP4',\n",
    "        'Major Field Group \\n(4-digit CIP) Title': 'CIP4_title'\n",
    "    })\n",
    "    \n",
    "    # Get enrollment columns (years 2020-2025)\n",
    "    # The enrollment columns alternate: Enrollment, % Change, Enrollment, % Change...\n",
    "    # Columns 5, 6, 8, 10, 12, 14 correspond to years 2020-2025\n",
    "    years_2025 = [2020, 2021, 2022, 2023, 2024, 2025]\n",
    "    enrollment_col_indices = [5, 6, 8, 10, 12, 14]\n",
    "    \n",
    "    # Reshape to long format\n",
    "    data_2025 = []\n",
    "    for idx, row in df_2025.iterrows():\n",
    "        cip4 = row['CIP4']\n",
    "        if pd.isna(cip4) or cip4 == 'Total':\n",
    "            continue\n",
    "        for year, col_idx in zip(years_2025, enrollment_col_indices):\n",
    "            enrollment = row.iloc[col_idx]\n",
    "            if pd.notna(enrollment) and enrollment != '*':\n",
    "                data_2025.append({\n",
    "                    'CIP4': str(cip4)[:4] if pd.notna(cip4) and str(cip4) != 'Total' else None,\n",
    "                    'year': year,\n",
    "                    'enrollment': float(enrollment)\n",
    "                })\n",
    "    \n",
    "    df_2025_long = pd.DataFrame(data_2025)\n",
    "    print(f\"  Reshaped to {len(df_2025_long)} observations\")\n",
    "    \n",
    "    # ===== COMBINE DATASETS =====\n",
    "    print(\"\\nCombining datasets...\")\n",
    "    \n",
    "    # For overlapping years (2020-2024), use 2025 file data (more recent)\n",
    "    df_2024_unique = df_2024_long[df_2024_long['year'] == 2019].copy()\n",
    "    \n",
    "    enrollment = pd.concat([df_2024_unique, df_2025_long], axis=0, ignore_index=True)\n",
    "    enrollment = enrollment.sort_values(['CIP4', 'year']).reset_index(drop=True)\n",
    "    \n",
    "    print(f\"\\n✓ Combined dataset: {len(enrollment)} observations\")\n",
    "    print(f\"  Years: {sorted(enrollment['year'].unique())}\")\n",
    "    print(f\"  Unique 4-digit CIP codes: {enrollment['CIP4'].nunique()}\")\n",
    "    \n",
    "    # Summary stats\n",
    "    print(\"\\nTotal enrollment by year:\")\n",
    "    yearly_enrollment = enrollment.groupby('year')['enrollment'].sum()\n",
    "    for year, total in yearly_enrollment.items():\n",
    "        print(f\"  {year}: {total:,.0f}\")\n",
    "    \n",
    "    return enrollment\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# STEP 7: MERGE AND FINALIZE\n",
    "# =============================================================================\n",
    "\n",
    "def merge_enrollment_exposure(\n",
    "    enrollment: pd.DataFrame,\n",
    "    cip_exposure: pd.DataFrame\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Merge enrollment data with AI exposure scores.\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"MERGING ENROLLMENT WITH AI EXPOSURE\")\n",
    "    print(\"=\"*70)\n",
    "    # Normalize CIP4 codes to match (both as zero-padded 4-char strings)\n",
    "    enrollment['CIP4'] = enrollment['CIP4'].astype(str).str.zfill(4)\n",
    "    cip_exposure['CIP4'] = cip_exposure['CIP4'].astype(str).str.zfill(4)\n",
    "    \n",
    "    \n",
    "    # Merge on 4-digit CIP code\n",
    "    df_final = enrollment.merge(\n",
    "        cip_exposure[['CIP4', 'ai_exposure_score', 'n_obs']],\n",
    "        on='CIP4',\n",
    "        how='left'\n",
    "    )\n",
    "    \n",
    "    # Report merge success\n",
    "    n_matched = df_final['ai_exposure_score'].notna().sum()\n",
    "    pct_matched = 100 * n_matched / len(df_final)\n",
    "    print(f\"\\nMatched {n_matched}/{len(df_final)} enrollment records ({pct_matched:.1f}%)\")\n",
    "    \n",
    "    # Create treatment variables\n",
    "    median_exposure = df_final['ai_exposure_score'].median()\n",
    "    df_final['high_ai_exposure'] = (\n",
    "        df_final['ai_exposure_score'] > median_exposure\n",
    "    ).astype(int)\n",
    "    \n",
    "    # Standardized exposure\n",
    "    df_final['ai_exposure_std'] = (\n",
    "        (df_final['ai_exposure_score'] - df_final['ai_exposure_score'].mean()) /\n",
    "        df_final['ai_exposure_score'].std()\n",
    "    )\n",
    "    \n",
    "    # Terciles (with error handling for insufficient unique values)\n",
    "    try:\n",
    "        df_final['ai_exposure_tercile'] = pd.qcut(\n",
    "            df_final['ai_exposure_score'],\n",
    "            q=3,\n",
    "            labels=['Low', 'Medium', 'High'],\n",
    "            duplicates='drop'\n",
    "        )\n",
    "    except ValueError as e:\n",
    "        # If qcut fails (e.g., too many NaNs or duplicates), use simple cut\n",
    "        print(f\"⚠ Could not create terciles: {e}\")\n",
    "        print(\"  Using quartile-based cut instead\")\n",
    "        df_final['ai_exposure_tercile'] = pd.cut(\n",
    "            df_final['ai_exposure_score'],\n",
    "            bins=3,\n",
    "            labels=['Low', 'Medium', 'High']\n",
    "        )\n",
    "    \n",
    "    # Create log enrollment\n",
    "    df_final['log_enrollment'] = np.log(df_final['enrollment'] + 1)\n",
    "    \n",
    "    print(\"\\n\\nFinal dataset:\")\n",
    "    print(df_final.head(20))\n",
    "    print(f\"\\nShape: {df_final.shape}\")\n",
    "    \n",
    "    return df_final\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# STEP 8: VISUALIZATION\n",
    "# =============================================================================\n",
    "\n",
    "def create_descriptive_plots(df: pd.DataFrame, output_path: str = 'enrollment_trends_4digit.png'):\n",
    "    \"\"\"\n",
    "    Create descriptive visualizations for 4-digit CIP analysis.\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"CREATING VISUALIZATIONS\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "    \n",
    "    # 1. Enrollment trends by AI exposure group\n",
    "    ax1 = axes[0, 0]\n",
    "    trend_data = df.groupby(['year', 'high_ai_exposure'])['enrollment'].sum().reset_index()\n",
    "    for group in [0, 1]:\n",
    "        data = trend_data[trend_data['high_ai_exposure'] == group]\n",
    "        label = 'High AI Exposure' if group else 'Low AI Exposure'\n",
    "        ax1.plot(data['year'], data['enrollment'], marker='o', label=label, linewidth=2)\n",
    "    ax1.set_xlabel('Year', fontsize=12)\n",
    "    ax1.set_ylabel('Total Enrollment', fontsize=12)\n",
    "    ax1.set_title('Enrollment Trends by AI Exposure (4-digit CIP)', fontsize=14, fontweight='bold')\n",
    "    ax1.legend()\n",
    "    ax1.grid(alpha=0.3)\n",
    "    ax1.axvline(2022.5, color='red', linestyle='--', alpha=0.5, label='ChatGPT Launch')\n",
    "    \n",
    "    # 2. Distribution of AI exposure\n",
    "    ax2 = axes[0, 1]\n",
    "    cip_scores = df.groupby('CIP4')['ai_exposure_score'].first()\n",
    "    ax2.hist(cip_scores, bins=50, edgecolor='black', alpha=0.7, color='steelblue')\n",
    "    ax2.axvline(cip_scores.median(), color='red', linestyle='--', linewidth=2, label='Median')\n",
    "    ax2.set_xlabel('AI Exposure Score', fontsize=12)\n",
    "    ax2.set_ylabel('Number of 4-digit CIP Codes', fontsize=12)\n",
    "    ax2.set_title('Distribution of AI Exposure Across Majors', fontsize=14, fontweight='bold')\n",
    "    ax2.legend()\n",
    "    ax2.grid(alpha=0.3)\n",
    "    \n",
    "    # 3. Scatter: enrollment growth vs exposure\n",
    "    ax3 = axes[1, 0]\n",
    "    first_year = df['year'].min()\n",
    "    last_year = df['year'].max()\n",
    "    \n",
    "    growth_data = []\n",
    "    for cip in df['CIP4'].unique():\n",
    "        cip_data = df[df['CIP4'] == cip]\n",
    "        enroll_first = cip_data[cip_data['year'] == first_year]['enrollment'].values\n",
    "        enroll_last = cip_data[cip_data['year'] == last_year]['enrollment'].values\n",
    "        if len(enroll_first) > 0 and len(enroll_last) > 0 and enroll_first[0] > 0:\n",
    "            growth = (enroll_last[0] - enroll_first[0]) / enroll_first[0] * 100\n",
    "            exposure = cip_data['ai_exposure_score'].iloc[0] if len(cip_data) > 0 else None\n",
    "            if exposure is not None and pd.notna(exposure):\n",
    "                growth_data.append({'CIP4': cip, 'growth_rate': growth, 'ai_exposure': exposure})\n",
    "    \n",
    "    growth_df = pd.DataFrame(growth_data)\n",
    "    if len(growth_df) > 0:\n",
    "        ax3.scatter(growth_df['ai_exposure'], growth_df['growth_rate'], alpha=0.6, s=30)\n",
    "        ax3.set_xlabel('AI Exposure Score', fontsize=12)\n",
    "        ax3.set_ylabel(f'Enrollment Growth Rate ({first_year}-{last_year}, %)', fontsize=12)\n",
    "        ax3.set_title('Growth Rate vs AI Exposure', fontsize=14, fontweight='bold')\n",
    "        ax3.axhline(0, color='black', linestyle='--', linewidth=1, alpha=0.5)\n",
    "        ax3.grid(alpha=0.3)\n",
    "        \n",
    "        # Add correlation\n",
    "        corr = growth_df[['ai_exposure', 'growth_rate']].corr().iloc[0, 1]\n",
    "        ax3.text(0.05, 0.95, f'Correlation: {corr:.3f}', \n",
    "                transform=ax3.transAxes, verticalalignment='top',\n",
    "                bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))\n",
    "    \n",
    "    # 4. Enrollment by tercile over time\n",
    "    ax4 = axes[1, 1]\n",
    "    tercile_data = df.groupby(['year', 'ai_exposure_tercile'])['enrollment'].sum().reset_index()\n",
    "    for tercile in ['Low', 'Medium', 'High']:\n",
    "        data = tercile_data[tercile_data['ai_exposure_tercile'] == tercile]\n",
    "        if len(data) > 0:\n",
    "            ax4.plot(data['year'], data['enrollment'], marker='o', label=f'{tercile} Exposure', linewidth=2)\n",
    "    ax4.set_xlabel('Year', fontsize=12)\n",
    "    ax4.set_ylabel('Total Enrollment', fontsize=12)\n",
    "    ax4.set_title('Enrollment by AI Exposure Tercile', fontsize=14, fontweight='bold')\n",
    "    ax4.legend()\n",
    "    ax4.grid(alpha=0.3)\n",
    "    ax4.axvline(2022.5, color='red', linestyle='--', alpha=0.5)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(output_path, dpi=300, bbox_inches='tight')\n",
    "    print(f\"\\n✓ Saved plots to {output_path}\")\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# MAIN EXECUTION\n",
    "# =============================================================================\n",
    "\n",
    "def main():\n",
    "    \"\"\"\n",
    "    Main execution function.\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"\\n\" + \"#\"*70)\n",
    "    print(\"# AI EXPOSURE AND ENROLLMENT ANALYSIS - 4-DIGIT CIP\")\n",
    "    print(\"#\"*70 + \"\\n\")\n",
    "    \n",
    "    # FILE PATHS\n",
    "    FELTEN_PATH = '/Users/jeffreyohl/Dropbox/CollegeMajorData/FeltenEtAl/AIOE_DataAppendix.xlsx'\n",
    "    CROSSWALK_PATH = '/Users/jeffreyohl/Dropbox/CollegeMajorData/Crosswalks/crosswalk_handout.xlsx'\n",
    "    ACS_PATH = '/Users/jeffreyohl/Dropbox/CollegeMajorData/IPUMS/usa_00008.csv'\n",
    "    ENROLLMENT_PATH_2025 = '/Users/jeffreyohl/Dropbox/CollegeMajorData/National Student Clearinghouse Data/CTEESpring2025-DataAppendix.xlsx'\n",
    "    ENROLLMENT_PATH_2024 = '/Users/jeffreyohl/Dropbox/CollegeMajorData/National Student Clearinghouse Data/CTEESpring2024-Appendix.xlsx'\n",
    "    OUTPUT_DIR = '/Users/jeffreyohl/Dropbox/CollegeMajorData/output'\n",
    "    \n",
    "    try:\n",
    "        # Step 1: Load Felten data\n",
    "        felten = load_felten_data(FELTEN_PATH)\n",
    "        \n",
    "        # Step 2: Load FOD to 4-digit CIP crosswalk\n",
    "        fod_to_cip4 = load_fod_cip4_crosswalk(CROSSWALK_PATH)\n",
    "        \n",
    "        # Step 3-5: Process ACS and calculate exposure scores\n",
    "        print(\"\\n\" + \"=\"*70)\n",
    "        print(\"PROCESSING ACS DATA\")\n",
    "        print(\"=\"*70)\n",
    "        acs = load_and_filter_acs(ACS_PATH)\n",
    "        acs_with_exposure = process_acs_with_exposure(acs, felten, fod_to_cip4)\n",
    "        cip_exposure = calculate_cip4_exposure(acs_with_exposure)\n",
    "        \n",
    "        # Save exposure scores\n",
    "        cip_exposure.to_csv(f'{OUTPUT_DIR}/cip4_ai_exposure_scores.csv', index=False)\n",
    "        print(f\"\\n✓ Saved exposure scores to {OUTPUT_DIR}/cip4_ai_exposure_scores.csv\")\n",
    "        \n",
    "        # Step 6: Load and combine enrollment data (2019-2025)\n",
    "        enrollment = load_and_combine_enrollment_data(ENROLLMENT_PATH_2024, ENROLLMENT_PATH_2025)\n",
    "        \n",
    "        # Step 7: Merge enrollment with exposure\n",
    "        df_final = merge_enrollment_exposure(enrollment, cip_exposure)\n",
    "        \n",
    "        # Save final dataset\n",
    "        df_final.to_csv(f'{OUTPUT_DIR}/enrollment_with_ai_exposure_4digit.csv', index=False)\n",
    "        print(f\"\\n✓ Saved final dataset to {OUTPUT_DIR}/enrollment_with_ai_exposure_4digit.csv\")\n",
    "        \n",
    "        # Step 8: Create visualizations\n",
    "        create_descriptive_plots(df_final, f'{OUTPUT_DIR}/enrollment_trends_4digit.png')\n",
    "        \n",
    "        print(\"\\n\" + \"#\"*70)\n",
    "        print(\"# DATA PREPARATION COMPLETE (4-DIGIT CIP)\")\n",
    "        print(\"#\"*70)\n",
    "        print(\"\\nNext steps:\")\n",
    "        print(\"1. Review cip4_ai_exposure_scores.csv to validate exposure scores\")\n",
    "        print(\"2. Check enrollment_with_ai_exposure_4digit.csv for data quality\")\n",
    "        print(\"3. Run econometric_analysis.py for DiD and event study\")\n",
    "        print(\"\\n4-digit CIP analysis provides:\")\n",
    "        print(\"  - Computer Science (1107) vs Information Systems (1104)\")\n",
    "        print(\"  - Business Administration (5202) vs Finance (5208) vs Accounting (5203)\")  \n",
    "        print(\"  - More granular treatment effects and heterogeneity analysis\")\n",
    "        \n",
    "    except FileNotFoundError as e:\n",
    "        print(f\"\\n❌ Error: File not found - {e}\")\n",
    "        print(\"\\nPlease check that all data files exist at the specified paths:\")\n",
    "        print(f\"  - Felten: {FELTEN_PATH}\")\n",
    "        print(f\"  - Crosswalk: {CROSSWALK_PATH}\")\n",
    "        print(f\"  - ACS: {ACS_PATH}\")\n",
    "        print(f\"  - Enrollment 2024: {ENROLLMENT_PATH_2024}\")\n",
    "        print(f\"  - Enrollment 2025: {ENROLLMENT_PATH_2025}\")\n",
    "    except Exception as e:\n",
    "        print(f\"\\n❌ Error occurred: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run main analysis\n",
    "main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
