{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "######################################################################\n",
      "# AI EXPOSURE AND ENROLLMENT ANALYSIS - 4-DIGIT CIP\n",
      "######################################################################\n",
      "\n",
      "======================================================================\n",
      "LOADING FELTEN AIOE DATA\n",
      "======================================================================\n",
      "\n",
      "Loaded 774 occupations\n",
      "AIOE range: -2.67 to 1.53\n",
      "\n",
      "======================================================================\n",
      "LOADING FOD TO 4-DIGIT CIP CROSSWALK\n",
      "======================================================================\n",
      "\n",
      "Created 614 FOD\u2192CIP4 mappings\n",
      "  Average 3.2 CIP4 codes per FOD\n",
      "\n",
      "======================================================================\n",
      "PROCESSING ACS DATA\n",
      "======================================================================\n",
      "\n",
      "======================================================================\n",
      "LOADING ACS PUMS DATA\n",
      "======================================================================\n",
      "\n",
      "Initial sample: 4,770,082 observations\n",
      "Filtered sample: 1,405,906 observations\n",
      "  - Age 22-35\n",
      "  - Valid occupation (OCCSOC) and field of degree (DEGFIELDD)\n",
      "\n",
      "Unique DEGFIELDD codes: 175\n",
      "Unique OCCSOC codes: 530\n",
      "\n",
      "======================================================================\n",
      "MAPPING FOD TO 4-DIGIT CIP AND MERGING AI EXPOSURE\n",
      "======================================================================\n",
      "\n",
      "Mapped 168 ACS observations to 2,638,688 CIP4 mappings\n",
      "  (Average 15706.5 CIP4 codes per person)\n",
      "\n",
      "Matched 1,374,527/2,638,688 observations to AI exposure (52.1%)\n",
      "\n",
      "\u26a0 Imputing 1264161 missing AIOE values with mean (0.6162)\n",
      "\n",
      "Final sample: 2,638,688 observations\n",
      "Unique 4-digit CIP codes: 365\n",
      "\n",
      "======================================================================\n",
      "CALCULATING 4-DIGIT CIP-LEVEL AI EXPOSURE SCORES\n",
      "======================================================================\n",
      "\n",
      "Calculated AI exposure for 365 4-digit CIP codes\n",
      "\n",
      "AI Exposure Score Distribution:\n",
      "count    365.000000\n",
      "mean       0.586657\n",
      "std        0.142604\n",
      "min        0.093170\n",
      "25%        0.550304\n",
      "50%        0.612211\n",
      "75%        0.660773\n",
      "max        1.064023\n",
      "Name: ai_exposure_score, dtype: float64\n",
      "\n",
      "\n",
      "Top 20 most AI-exposed majors (4-digit CIP):\n",
      "     CIP4  ai_exposure_score     n_obs\n",
      "344  5203           1.064023   26092.0\n",
      "349  5208           0.893085   21972.0\n",
      "358  5217           0.893085   21972.0\n",
      "82   1408           0.882391    8613.0\n",
      "347  5206           0.847676    1747.0\n",
      "88   1414           0.803274     984.0\n",
      "275  4506           0.800410   17931.0\n",
      "68   1311           0.798062     207.0\n",
      "228  4004           0.795709     531.0\n",
      "76   1402           0.794777    2587.0\n",
      "313  5102           0.790510    5111.0\n",
      "341  5200           0.780273  162400.0\n",
      "78   1404           0.775323     369.0\n",
      "38   0909           0.773682    5483.0\n",
      "81   1407           0.768679    6260.0\n",
      "266  4405           0.764002    1111.0\n",
      "277  4509           0.761276    3718.0\n",
      "354  5213           0.760643    3936.0\n",
      "91   1420           0.755148     104.0\n",
      "21   0400           0.750975    6144.0\n",
      "\n",
      "\n",
      "Bottom 20 least AI-exposed majors (4-digit CIP):\n",
      "     CIP4  ai_exposure_score    n_obs\n",
      "289  4700           0.093170    307.0\n",
      "290  4701           0.093170    307.0\n",
      "291  4702           0.093170    307.0\n",
      "292  4703           0.093170    307.0\n",
      "293  4704           0.093170    307.0\n",
      "294  4706           0.093170    307.0\n",
      "295  4799           0.093170    307.0\n",
      "232  4100           0.121214    279.0\n",
      "233  4102           0.121214    279.0\n",
      "234  4103           0.121214    279.0\n",
      "235  4199           0.121214    279.0\n",
      "53   1200           0.189050   1007.0\n",
      "54   1203           0.189050   1007.0\n",
      "55   1204           0.189050   1007.0\n",
      "56   1205           0.189050   1007.0\n",
      "57   1299           0.189050   1007.0\n",
      "9    0109           0.281416   3643.0\n",
      "18   0305           0.311669    742.0\n",
      "323  5116           0.314859  39347.0\n",
      "319  5110           0.315186   2526.0\n",
      "\n",
      "\u2713 Saved exposure scores to /Users/jeffreyohl/Dropbox/CollegeMajorData/output/cip4_ai_exposure_scores.csv\n",
      "\n",
      "======================================================================\n",
      "LOADING AND COMBINING ENROLLMENT DATA (2019-2025)\n",
      "======================================================================\n",
      "\n",
      "Loading 2019-2024 data from CTEESpring2024-Appendix.xlsx...\n",
      "  Loaded 488 rows\n",
      "  Found 6 enrollment columns for years 2019-2024\n",
      "  Reshaped to 2001 observations\n",
      "\n",
      "Loading 2020-2025 data from CTEESpring2025-DataAppendix.xlsx...\n",
      "  Loaded 1410 rows\n",
      "  Filtered to 470 Undergraduate 4-year rows\n",
      "  Reshaped to 2097 observations\n",
      "\n",
      "Combining datasets...\n",
      "\n",
      "\u2713 Combined dataset: 2421 observations\n",
      "  Years: [np.int64(2019), np.int64(2020), np.int64(2021), np.int64(2022), np.int64(2023), np.int64(2024), np.int64(2025)]\n",
      "  Unique 4-digit CIP codes: 390\n",
      "\n",
      "Total enrollment by year:\n",
      "  2019: 8,881,017\n",
      "  2020: 8,836,845\n",
      "  2021: 8,690,353\n",
      "  2022: 8,581,948\n",
      "  2023: 8,456,944\n",
      "  2024: 8,669,730\n",
      "  2025: 8,877,394\n",
      "\n",
      "======================================================================\n",
      "MERGING ENROLLMENT WITH AI EXPOSURE\n",
      "======================================================================\n",
      "\n",
      "Matched 1884/2421 enrollment records (77.8%)\n",
      "\n",
      "\n",
      "Final dataset:\n",
      "    CIP4  year    enrollment  ai_exposure_score    n_obs  high_ai_exposure  \\\n",
      "0   0100  2019   9519.068031           0.411245  11057.0                 0   \n",
      "1   0100  2020   9282.396944           0.411245  11057.0                 0   \n",
      "2   0100  2021   9147.125698           0.411245  11057.0                 0   \n",
      "3   0100  2022   8410.844989           0.411245  11057.0                 0   \n",
      "4   0100  2023   8616.469810           0.411245  11057.0                 0   \n",
      "5   0100  2024   8706.931635           0.411245  11057.0                 0   \n",
      "6   0100  2025   8644.549148           0.411245  11057.0                 0   \n",
      "7   0101  2019  18059.790261           0.504175   3024.0                 0   \n",
      "8   0101  2020  17627.500204           0.504175   3024.0                 0   \n",
      "9   0101  2021  16472.834741           0.504175   3024.0                 0   \n",
      "10  0101  2022  16076.321122           0.504175   3024.0                 0   \n",
      "11  0101  2023  14674.973222           0.504175   3024.0                 0   \n",
      "12  0101  2024  17441.527090           0.504175   3024.0                 0   \n",
      "13  0101  2025  17907.299601           0.504175   3024.0                 0   \n",
      "14  0102  2019   1259.195858           0.488248   2584.0                 0   \n",
      "15  0102  2020   1123.517786           0.488248   2584.0                 0   \n",
      "16  0102  2021   1006.194094           0.488248   2584.0                 0   \n",
      "17  0102  2022    936.594522           0.488248   2584.0                 0   \n",
      "18  0102  2023    926.160247           0.488248   2584.0                 0   \n",
      "19  0102  2024    928.274895           0.488248   2584.0                 0   \n",
      "\n",
      "    ai_exposure_std ai_exposure_tercile  log_enrollment  \n",
      "0         -1.260232                 Low        9.161157  \n",
      "1         -1.260232                 Low        9.135983  \n",
      "2         -1.260232                 Low        9.121304  \n",
      "3         -1.260232                 Low        9.037396  \n",
      "4         -1.260232                 Low        9.061547  \n",
      "5         -1.260232                 Low        9.071990  \n",
      "6         -1.260232                 Low        9.064800  \n",
      "7         -0.611101                 Low        9.801499  \n",
      "8         -0.611101                 Low        9.777272  \n",
      "9         -0.611101                 Low        9.709529  \n",
      "10        -0.611101                 Low        9.685165  \n",
      "11        -0.611101                 Low        9.593967  \n",
      "12        -0.611101                 Low        9.766667  \n",
      "13        -0.611101                 Low        9.793020  \n",
      "14        -0.722354                 Low        7.139022  \n",
      "15        -0.722354                 Low        7.025110  \n",
      "16        -0.722354                 Low        6.914924  \n",
      "17        -0.722354                 Low        6.843318  \n",
      "18        -0.722354                 Low        6.832126  \n",
      "19        -0.722354                 Low        6.834405  \n",
      "\n",
      "Shape: (2421, 9)\n",
      "\n",
      "\u2713 Saved final dataset to /Users/jeffreyohl/Dropbox/CollegeMajorData/output/enrollment_with_ai_exposure_4digit.csv\n",
      "\n",
      "======================================================================\n",
      "CREATING VISUALIZATIONS\n",
      "======================================================================\n",
      "\n",
      "\u2713 Saved plots to /Users/jeffreyohl/Dropbox/CollegeMajorData/output/enrollment_trends_4digit.png\n",
      "\n",
      "######################################################################\n",
      "# DATA PREPARATION COMPLETE (4-DIGIT CIP)\n",
      "######################################################################\n",
      "\n",
      "Next steps:\n",
      "1. Review cip4_ai_exposure_scores.csv to validate exposure scores\n",
      "2. Check enrollment_with_ai_exposure_4digit.csv for data quality\n",
      "3. Run econometric_analysis.py for DiD and event study\n",
      "\n",
      "4-digit CIP analysis provides:\n",
      "  - Computer Science (1107) vs Information Systems (1104)\n",
      "  - Business Administration (5202) vs Finance (5208) vs Accounting (5203)\n",
      "  - More granular treatment effects and heterogeneity analysis\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "AI Exposure and College Enrollment Analysis - 4-DIGIT CIP VERSION\n",
    "==================================================================\n",
    "Updated for:\n",
    "- 4-digit CIP codes (436 programs vs 49 at 2-digit level)\n",
    "- 2019-2025 enrollment data (combined from both files)\n",
    "- More granular analysis (e.g., Computer Science vs Information Systems)\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from typing import Dict\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# =============================================================================\n",
    "# STEP 1: LOAD FELTEN AIOE DATA\n",
    "# =============================================================================\n",
    "\n",
    "def load_felten_data(filepath: str) -> pd.DataFrame:\n",
    "    \"\"\"Load Felten et al. (2021) AIOE scores.\"\"\"\n",
    "    print(\"=\"*70)\n",
    "    print(\"LOADING FELTEN AIOE DATA\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    felten = pd.read_excel(filepath, sheet_name='Appendix A')\n",
    "    felten['soc_clean'] = felten['SOC Code'].str.replace('-', '').str.replace('.', '')\n",
    "    \n",
    "    print(f\"\\nLoaded {len(felten)} occupations\")\n",
    "    print(f\"AIOE range: {felten['AIOE'].min():.2f} to {felten['AIOE'].max():.2f}\")\n",
    "    \n",
    "    return felten\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# STEP 2: LOAD FOD TO 4-DIGIT CIP CROSSWALK\n",
    "# =============================================================================\n",
    "\n",
    "def load_fod_cip4_crosswalk(filepath: str) -> Dict[int, str]:\n",
    "    \"\"\"\n",
    "    Load FOD to 4-digit CIP mapping from crosswalk file.\n",
    "    \n",
    "    The crosswalk has detailed 6-digit CIP codes (like 11.0701).\n",
    "    We extract 4-digit CIP:\n",
    "    - Family (2 digits): 11 = Computer Science\n",
    "    - Group (next 2 digits): 07 = Computer Science \n",
    "    - Combined: 1107 = Computer Science (4-digit)\n",
    "    \n",
    "    Examples:\n",
    "    - 11.0000 \u2192 1100 (Computer Science, General)\n",
    "    - 11.0701 \u2192 1107 (Computer Science)\n",
    "    - 52.0201 \u2192 5202 (Business Administration)\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    Dict mapping FOD code (int) to 4-digit CIP string (e.g., '1107')\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"LOADING FOD TO 4-DIGIT CIP CROSSWALK\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    # Read from \"CIP code by HHES code\" sheet\n",
    "    df = pd.read_excel(filepath, sheet_name='CIP code by HHES code', skiprows=1)\n",
    "    \n",
    "    # Extract FOD and CIP columns\n",
    "    crosswalk = df[['HHES Code', 'CIP \\nCode']].copy()\n",
    "    crosswalk.columns = ['FOD', 'CIP']\n",
    "    crosswalk = crosswalk.dropna(subset=['FOD', 'CIP'])\n",
    "    \n",
    "    # Convert FOD to integer\n",
    "    crosswalk['FOD'] = crosswalk['FOD'].astype(int)\n",
    "    \n",
    "    # Extract 4-digit CIP from 6-digit CIP code\n",
    "    # CIP format: XX.XXXX where first 2 are family, next 2 are group\n",
    "    # E.g., 11.0701 \u2192 1107\n",
    "    def extract_cip4(cip_6digit):\n",
    "        try:\n",
    "            cip_float = float(cip_6digit)\n",
    "            # Get integer part (family, 2 digits)\n",
    "            family = int(cip_float)  # e.g., 11\n",
    "            # Get first 2 decimal digits (group)\n",
    "            decimal_part = cip_float - family  # e.g., 0.0701\n",
    "            # Extract first 2 decimal digits\n",
    "            group = int(round(decimal_part * 10000)) // 100  # e.g., 07\n",
    "            # Combine to 4-digit code\n",
    "            cip4 = f\"{family:02d}{group:02d}\"  # e.g., \"1107\"\n",
    "            return cip4\n",
    "        except:\n",
    "            return None\n",
    "    \n",
    "    crosswalk['CIP4'] = crosswalk['CIP'].apply(extract_cip4)\n",
    "    crosswalk = crosswalk.dropna(subset=['CIP4'])\n",
    "    \n",
    "    # For each FOD, use the modal (most common) 4-digit CIP\n",
    "    # (some FOD codes map to multiple detailed CIPs within same 4-digit group)\n",
    "    # Create many-to-many mapping (each FOD can map to multiple CIP4s)\n",
    "    # This preserves all valid FOD\u2192CIP4 mappings instead of just the modal one\n",
    "    fod_to_cip4_df = crosswalk[['FOD', 'CIP4']].drop_duplicates()\n",
    "    print(f\"\\nCreated {len(fod_to_cip4_df)} FOD\u2192CIP4 mappings\")\n",
    "    print(f\"  Average {len(fod_to_cip4_df) / crosswalk['FOD'].nunique():.1f} CIP4 codes per FOD\")\n",
    "    \n",
    "    # Return as dataframe instead of dict to preserve many-to-many relationship\n",
    "    return fod_to_cip4_df\n",
    "    \n",
    "    print(f\"\\nMapped {len(fod_to_cip4)} FOD codes to 4-digit CIP codes\")\n",
    "    \n",
    "    # Show sample mappings\n",
    "    print(\"\\nSample mappings:\")\n",
    "    for fod in sorted(fod_to_cip4.keys())[:20]:\n",
    "        print(f\"  FOD {fod} \u2192 CIP4 {fod_to_cip4[fod]}\")\n",
    "    \n",
    "    # Check Computer Science specifically (FOD 2102)\n",
    "    if 2102 in fod_to_cip4:\n",
    "        print(f\"\\n\u2713 Computer Science: FOD 2102 \u2192 CIP4 {fod_to_cip4[2102]}\")\n",
    "    \n",
    "    return fod_to_cip4\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# STEP 2B: ADD EMPIRICAL ENROLLMENT WEIGHTS TO FOD\u2192CIP4 MAPPING\n",
    "# =============================================================================\n",
    "\n",
    "def add_empirical_weights_to_crosswalk(\n",
    "    fod_to_cip4: pd.DataFrame,\n",
    "    enrollment: pd.DataFrame,\n",
    "    base_year: int = 2019\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Add empirical enrollment weights to FOD\u2192CIP4 mapping.\n",
    "    \n",
    "    For each FOD that maps to multiple CIP4s, calculate weights based on\n",
    "    actual 2019 enrollment: weight_i = enrollment_i / sum(enrollment for all CIP4s that FOD maps to)\n",
    "    \n",
    "    This creates a Bayesian update: P(CIP4 | FOD) \u221d enrollment(CIP4)\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    fod_to_cip4 : DataFrame with columns ['FOD', 'CIP4']\n",
    "    enrollment : DataFrame with columns ['CIP4', 'year', 'enrollment']\n",
    "    base_year : Year to use for calculating weights (default 2019)\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    DataFrame with columns ['FOD', 'CIP4', 'empirical_weight']\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"ADDING EMPIRICAL ENROLLMENT WEIGHTS TO FOD\u2192CIP4 MAPPING\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    # Get base year enrollment\n",
    "    enroll_base = enrollment[enrollment['year'] == base_year][['CIP4', 'enrollment']].copy()\n",
    "    print(f\"\\nUsing {base_year} enrollment as basis for weights\")\n",
    "    print(f\"  {len(enroll_base)} CIP4 codes have enrollment data\")\n",
    "    \n",
    "    # Merge enrollment into crosswalk\n",
    "    crosswalk_with_enroll = fod_to_cip4.merge(\n",
    "        enroll_base,\n",
    "        on='CIP4',\n",
    "        how='left'\n",
    "    )\n",
    "    \n",
    "    # For CIP4s with no enrollment data, use a small value (1.0) as placeholder\n",
    "    crosswalk_with_enroll['enrollment'] = crosswalk_with_enroll['enrollment'].fillna(1.0)\n",
    "    \n",
    "    # For each FOD, calculate weights as proportion of total enrollment\n",
    "    # weight_i = enrollment_i / sum_j(enrollment_j) for all j that FOD maps to\n",
    "    fod_totals = crosswalk_with_enroll.groupby('FOD')['enrollment'].transform('sum')\n",
    "    crosswalk_with_enroll['empirical_weight'] = crosswalk_with_enroll['enrollment'] / fod_totals\n",
    "    \n",
    "    # Clean up\n",
    "    crosswalk_weighted = crosswalk_with_enroll[['FOD', 'CIP4', 'empirical_weight']].copy()\n",
    "    \n",
    "    # Report\n",
    "    print(f\"\\nCalculated empirical weights for {len(crosswalk_weighted)} FOD\u2192CIP4 mappings\")\n",
    "    \n",
    "    # Show examples\n",
    "    print(\"\\nSample weighted mappings:\")\n",
    "    sample_fods = crosswalk_weighted['FOD'].unique()[:3]\n",
    "    for fod in sample_fods:\n",
    "        fod_mappings = crosswalk_weighted[crosswalk_weighted['FOD'] == fod]\n",
    "        print(f\"\\n  FOD {fod} maps to {len(fod_mappings)} CIP4 codes:\")\n",
    "        for _, row in fod_mappings.iterrows():\n",
    "            print(f\"    CIP4 {row['CIP4']}: weight = {row['empirical_weight']:.3f}\")\n",
    "    \n",
    "    # Sanity check: weights should sum to 1.0 for each FOD\n",
    "    weight_sums = crosswalk_weighted.groupby('FOD')['empirical_weight'].sum()\n",
    "    if not np.allclose(weight_sums, 1.0):\n",
    "        print(f\"\\n\u26a0 WARNING: Some FOD weights don't sum to 1.0!\")\n",
    "        print(f\"  Min: {weight_sums.min():.6f}, Max: {weight_sums.max():.6f}\")\n",
    "    else:\n",
    "        print(f\"\\n\u2713 All FOD weights sum to 1.0\")\n",
    "    \n",
    "    return crosswalk_weighted\n",
    "\n",
    "\n",
    "# STEP 3: LOAD AND PROCESS ACS PUMS DATA\n",
    "# =============================================================================\n",
    "\n",
    "def load_and_filter_acs(\n",
    "    filepath: str,\n",
    "    age_min: int = 22,\n",
    "    age_max: int = 35\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Load and filter IPUMS ACS PUMS data.\n",
    "    \n",
    "    Your ACS columns: DEGFIELDD, OCCSOC, PERWT, AGE, EDUC, YEAR\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"LOADING ACS PUMS DATA\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    acs = pd.read_csv(filepath)\n",
    "    \n",
    "    print(f\"\\nInitial sample: {len(acs):,} observations\")\n",
    "    \n",
    "    # Filter\n",
    "    acs_filtered = acs[\n",
    "        (acs['AGE'] >= age_min) & \n",
    "        (acs['AGE'] <= age_max) &\n",
    "        (acs['OCCSOC'].notna()) &\n",
    "        (acs['DEGFIELDD'].notna())\n",
    "    ].copy()\n",
    "    \n",
    "    print(f\"Filtered sample: {len(acs_filtered):,} observations\")\n",
    "    print(f\"  - Age {age_min}-{age_max}\")\n",
    "    print(f\"  - Valid occupation (OCCSOC) and field of degree (DEGFIELDD)\")\n",
    "    \n",
    "    # Clean SOC codes\n",
    "    acs_filtered['soc_clean'] = acs_filtered['OCCSOC'].astype(str).str.replace('-', '').str.replace('.', '')\n",
    "    \n",
    "    print(f\"\\nUnique DEGFIELDD codes: {acs_filtered['DEGFIELDD'].nunique()}\")\n",
    "    print(f\"Unique OCCSOC codes: {acs_filtered['OCCSOC'].nunique()}\")\n",
    "    \n",
    "    return acs_filtered\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# STEP 4: MAP FOD TO 4-DIGIT CIP AND MERGE WITH EXPOSURE\n",
    "# =============================================================================\n",
    "\n",
    "def process_acs_with_exposure(\n",
    "    acs: pd.DataFrame,\n",
    "    felten: pd.DataFrame,\n",
    "    fod_to_cip4: pd.DataFrame\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Map ACS FOD codes to 4-digit CIP using many-to-many relationship.\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"MAPPING FOD TO 4-DIGIT CIP AND MERGING AI EXPOSURE\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    # Map FOD to CIP4\n",
    "    # Map FOD to CIP4 using many-to-many relationship\n",
    "    # Each ACS observation can contribute to multiple CIP4 codes\n",
    "    acs_with_cip = acs.merge(\n",
    "        fod_to_cip4,\n",
    "        left_on='DEGFIELDD',\n",
    "        right_on='FOD',\n",
    "        how='inner'\n",
    "    )\n",
    "    \n",
    "    # Report mapping success\n",
    "    n_original = len(acs)\n",
    "    n_after_mapping = len(acs_with_cip)\n",
    "    n_unique_people = acs_with_cip['DEGFIELDD'].nunique() if 'DEGFIELDD' in acs_with_cip.columns else len(acs_with_cip)\n",
    "    \n",
    "    # Use empirical weights from crosswalk (already calculated based on 2019 enrollment)\n",
    "    # Each ACS person contributes weight_split = PERWT * empirical_weight to each CIP4\n",
    "    acs_with_cip['weight_split'] = acs_with_cip['PERWT'] * acs_with_cip['empirical_weight']\n",
    "    \n",
    "    avg_cips = len(acs_with_cip) / len(acs)\n",
    "    print(f\"  Each ACS person contributes to avg {avg_cips:.1f} CIP4 codes (weighted by 2019 enrollment)\")\n",
    "    \n",
    "    \n",
    "    print(f\"\\nMapped {n_unique_people:,} ACS observations to {len(acs_with_cip):,} CIP4 mappings\")\n",
    "    print(f\"  (Average {n_after_mapping/n_unique_people if n_unique_people > 0 else 0:.1f} CIP4 codes per person)\")\n",
    "    \n",
    "    # Check unmapped FODs\n",
    "    if len(acs_with_cip) < len(acs):\n",
    "        unmapped = acs[~acs['DEGFIELDD'].isin(fod_to_cip4['FOD'])]\n",
    "        unmapped_fods = unmapped['DEGFIELDD'].value_counts().head(10)\n",
    "        print(\"\\nTop 10 unmapped FOD codes:\")\n",
    "        print(unmapped_fods)\n",
    "    \n",
    "    \n",
    "    # Filter to successfully mapped\n",
    "    \n",
    "    # Merge with Felten AIOE scores on SOC code\n",
    "    acs_with_exposure = acs_with_cip.merge(\n",
    "        felten[['soc_clean', 'AIOE']],\n",
    "        on='soc_clean',\n",
    "        how='left'\n",
    "    )\n",
    "    \n",
    "    # Report merge success\n",
    "    n_matched = acs_with_exposure['AIOE'].notna().sum()\n",
    "    pct_matched = 100 * n_matched / len(acs_with_exposure)\n",
    "    print(f\"\\nMatched {n_matched:,}/{len(acs_with_exposure):,} observations to AI exposure ({pct_matched:.1f}%)\")\n",
    "    \n",
    "    \n",
    "    # Drop observations with missing AIOE (do NOT impute with mean)\n",
    "    n_missing = acs_with_exposure['AIOE'].isna().sum()\n",
    "    if n_missing > 0:\n",
    "        print(f\"\\n\u26a0 Dropping {n_missing:,} observations with missing AIOE scores\")\n",
    "        acs_with_exposure = acs_with_exposure[acs_with_exposure['AIOE'].notna()].copy()\n",
    "    \n",
    "    print(f\"\\nFinal sample: {len(acs_with_exposure):,} observations\")\n",
    "    print(f\"Unique 4-digit CIP codes: {acs_with_exposure['CIP4'].nunique()}\")\n",
    "    \n",
    "    return acs_with_exposure\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# STEP 5: CALCULATE 4-DIGIT CIP-LEVEL AI EXPOSURE\n",
    "# =============================================================================\n",
    "\n",
    "def calculate_cip4_exposure(\n",
    "    acs: pd.DataFrame,\n",
    "    weight_var: str = 'weight_split'\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Calculate weighted average AI exposure by 4-digit CIP code.\n",
    "    \n",
    "    For each CIP4: AI_exposure = \u03a3 [P(occupation|CIP4) \u00d7 AIOE(occupation)]\n",
    "    where P(occupation|CIP4) is weighted by split weights (PERWT \u00d7 empirical_weight).\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"CALCULATING 4-DIGIT CIP-LEVEL AI EXPOSURE SCORES\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    # Calculate weighted average by CIP4\n",
    "    cip_exposure = acs.groupby('CIP4').apply(\n",
    "        lambda x: pd.Series({\n",
    "            'ai_exposure_score': np.average(x['AIOE'], weights=x[weight_var]),\n",
    "            'n_obs': len(x),\n",
    "            'n_weighted': x[weight_var].sum(),\n",
    "            'min_exposure': x['AIOE'].min(),\n",
    "            'max_exposure': x['AIOE'].max(),\n",
    "            'std_exposure': np.sqrt(np.average((x['AIOE'] - np.average(x['AIOE'], weights=x[weight_var]))**2, \n",
    "                                                weights=x[weight_var]))\n",
    "        })\n",
    "    ).reset_index()\n",
    "    \n",
    "    print(f\"\\nCalculated AI exposure for {len(cip_exposure)} 4-digit CIP codes\")\n",
    "    print(\"\\nAI Exposure Score Distribution:\")\n",
    "    print(cip_exposure['ai_exposure_score'].describe())\n",
    "    \n",
    "    # Show top and bottom CIPs\n",
    "    print(\"\\n\\nTop 20 most AI-exposed majors (4-digit CIP):\")\n",
    "    top20 = cip_exposure.nlargest(20, 'ai_exposure_score')[['CIP4', 'ai_exposure_score', 'n_obs']]\n",
    "    print(top20)\n",
    "    \n",
    "    print(\"\\n\\nBottom 20 least AI-exposed majors (4-digit CIP):\")\n",
    "    bottom20 = cip_exposure.nsmallest(20, 'ai_exposure_score')[['CIP4', 'ai_exposure_score', 'n_obs']]\n",
    "    print(bottom20)\n",
    "    \n",
    "    return cip_exposure\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# STEP 6: LOAD AND COMBINE ENROLLMENT DATA (2019-2025)\n",
    "# =============================================================================\n",
    "\n",
    "def load_and_combine_enrollment_data(\n",
    "    filepath_2024: str, \n",
    "    filepath_2025: str\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Load and combine enrollment data from two sources with proper header handling.\n",
    "    \n",
    "    2024 file: Major Field (4-year, Undergrad) sheet, years 2019-2024\n",
    "    2025 file: CIP Group Enrollment sheet, years 2020-2025 (filter to Undergraduate 4-year)\n",
    "    \n",
    "    Returns combined dataset with 4-digit CIP codes (2019-2025).\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"LOADING AND COMBINING ENROLLMENT DATA (2019-2025)\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    # ===== LOAD 2024 FILE =====\n",
    "    print(\"\\nLoading 2019-2024 data from CTEESpring2024-Appendix.xlsx...\")\n",
    "    df_2024 = pd.read_excel(\n",
    "        filepath_2024, \n",
    "        sheet_name='Major Field (4-year, Undergrad)',\n",
    "        header=2  # Row 2 has the actual column headers\n",
    "    )\n",
    "    print(f\"  Loaded {len(df_2024)} rows\")\n",
    "    \n",
    "    # Rename columns for clarity\n",
    "    df_2024 = df_2024.rename(columns={\n",
    "        'Major Field Family (2-digit CIP)': 'CIP2',\n",
    "        'Major Field Family (2-digit) Title': 'CIP2_title',\n",
    "        'Major Field Group (4-digit CIP)': 'CIP4',\n",
    "        'Major Field Group (4-digit) Title': 'CIP4_title'\n",
    "    })\n",
    "    \n",
    "    # Get enrollment columns (years 2019-2024)\n",
    "    years_2024 = [2019, 2020, 2021, 2022, 2023, 2024]\n",
    "    enrollment_cols = [col for col in df_2024.columns if 'Enrollment' in str(col) and '% Change' not in str(col)]\n",
    "    print(f\"  Found {len(enrollment_cols)} enrollment columns for years 2019-2024\")\n",
    "    \n",
    "    # Reshape to long format\n",
    "    data_2024 = []\n",
    "    for idx, row in df_2024.iterrows():\n",
    "        cip4 = row['CIP4']\n",
    "        if pd.isna(cip4) or cip4 == 'Total':\n",
    "            continue\n",
    "        for year, col in zip(years_2024, enrollment_cols):\n",
    "            enrollment = row[col]\n",
    "            if pd.notna(enrollment) and enrollment != '*':\n",
    "                data_2024.append({\n",
    "                    'CIP4': str(cip4)[:4] if pd.notna(cip4) and str(cip4) != 'Total' else None,\n",
    "                    'year': year,\n",
    "                    'enrollment': float(enrollment)\n",
    "                })\n",
    "    \n",
    "    df_2024_long = pd.DataFrame(data_2024)\n",
    "    print(f\"  Reshaped to {len(df_2024_long)} observations\")\n",
    "    \n",
    "    # ===== LOAD 2025 FILE =====\n",
    "    print(\"\\nLoading 2020-2025 data from CTEESpring2025-DataAppendix.xlsx...\")\n",
    "    df_2025 = pd.read_excel(\n",
    "        filepath_2025,\n",
    "        sheet_name='CIP Group Enrollment',\n",
    "        header=2  # Row 2 has the actual column headers\n",
    "    )\n",
    "    print(f\"  Loaded {len(df_2025)} rows\")\n",
    "    \n",
    "    # Filter to Undergraduate 4-year only\n",
    "    df_2025 = df_2025[df_2025['Award Level and Institution Type'] == 'Undergraduate 4-year'].copy()\n",
    "    print(f\"  Filtered to {len(df_2025)} Undergraduate 4-year rows\")\n",
    "    \n",
    "    # Rename columns\n",
    "    df_2025 = df_2025.rename(columns={\n",
    "        'Major Field Family \\n(2-digit CIP)': 'CIP2',\n",
    "        'Major Field Family \\n(2-digit CIP) Title': 'CIP2_title',\n",
    "        'Major Field Group \\n(4-digit CIP)': 'CIP4',\n",
    "        'Major Field Group \\n(4-digit CIP) Title': 'CIP4_title'\n",
    "    })\n",
    "    \n",
    "    # Get enrollment columns (years 2020-2025)\n",
    "    # The enrollment columns alternate: Enrollment, % Change, Enrollment, % Change...\n",
    "    # Columns 5, 6, 8, 10, 12, 14 correspond to years 2020-2025\n",
    "    years_2025 = [2020, 2021, 2022, 2023, 2024, 2025]\n",
    "    enrollment_col_indices = [5, 6, 8, 10, 12, 14]\n",
    "    \n",
    "    # Reshape to long format\n",
    "    data_2025 = []\n",
    "    for idx, row in df_2025.iterrows():\n",
    "        cip4 = row['CIP4']\n",
    "        if pd.isna(cip4) or cip4 == 'Total':\n",
    "            continue\n",
    "        for year, col_idx in zip(years_2025, enrollment_col_indices):\n",
    "            enrollment = row.iloc[col_idx]\n",
    "            if pd.notna(enrollment) and enrollment != '*':\n",
    "                data_2025.append({\n",
    "                    'CIP4': str(cip4)[:4] if pd.notna(cip4) and str(cip4) != 'Total' else None,\n",
    "                    'year': year,\n",
    "                    'enrollment': float(enrollment)\n",
    "                })\n",
    "    \n",
    "    df_2025_long = pd.DataFrame(data_2025)\n",
    "    print(f\"  Reshaped to {len(df_2025_long)} observations\")\n",
    "    \n",
    "    # ===== COMBINE DATASETS =====\n",
    "    print(\"\\nCombining datasets...\")\n",
    "    \n",
    "    # For overlapping years (2020-2024), use 2025 file data (more recent)\n",
    "    df_2024_unique = df_2024_long[df_2024_long['year'] == 2019].copy()\n",
    "    \n",
    "    enrollment = pd.concat([df_2024_unique, df_2025_long], axis=0, ignore_index=True)\n",
    "    enrollment = enrollment.sort_values(['CIP4', 'year']).reset_index(drop=True)\n",
    "    \n",
    "    print(f\"\\n\u2713 Combined dataset: {len(enrollment)} observations\")\n",
    "    print(f\"  Years: {sorted(enrollment['year'].unique())}\")\n",
    "    print(f\"  Unique 4-digit CIP codes: {enrollment['CIP4'].nunique()}\")\n",
    "    \n",
    "    # Summary stats\n",
    "    print(\"\\nTotal enrollment by year:\")\n",
    "    yearly_enrollment = enrollment.groupby('year')['enrollment'].sum()\n",
    "    for year, total in yearly_enrollment.items():\n",
    "        print(f\"  {year}: {total:,.0f}\")\n",
    "    \n",
    "    return enrollment\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# STEP 7: MERGE AND FINALIZE\n",
    "# =============================================================================\n",
    "\n",
    "def merge_enrollment_exposure(\n",
    "    enrollment: pd.DataFrame,\n",
    "    cip_exposure: pd.DataFrame\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Merge enrollment data with AI exposure scores.\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"MERGING ENROLLMENT WITH AI EXPOSURE\")\n",
    "    print(\"=\"*70)\n",
    "    # Normalize CIP4 codes to match (both as zero-padded 4-char strings)\n",
    "    enrollment['CIP4'] = enrollment['CIP4'].astype(str).str.zfill(4)\n",
    "    cip_exposure['CIP4'] = cip_exposure['CIP4'].astype(str).str.zfill(4)\n",
    "    \n",
    "    \n",
    "    # Merge on 4-digit CIP code\n",
    "    df_final = enrollment.merge(\n",
    "        cip_exposure[['CIP4', 'ai_exposure_score', 'n_obs']],\n",
    "        on='CIP4',\n",
    "        how='left'\n",
    "    )\n",
    "    \n",
    "    # Report merge success\n",
    "    n_matched = df_final['ai_exposure_score'].notna().sum()\n",
    "    pct_matched = 100 * n_matched / len(df_final)\n",
    "    print(f\"\\nMatched {n_matched}/{len(df_final)} enrollment records ({pct_matched:.1f}%)\")\n",
    "    \n",
    "    # Create treatment variables\n",
    "    median_exposure = df_final['ai_exposure_score'].median()\n",
    "    df_final['high_ai_exposure'] = (\n",
    "        df_final['ai_exposure_score'] > median_exposure\n",
    "    ).astype(int)\n",
    "    \n",
    "    # Standardized exposure\n",
    "    df_final['ai_exposure_std'] = (\n",
    "        (df_final['ai_exposure_score'] - df_final['ai_exposure_score'].mean()) /\n",
    "        df_final['ai_exposure_score'].std()\n",
    "    )\n",
    "    \n",
    "    # Terciles (with error handling for insufficient unique values)\n",
    "    try:\n",
    "        df_final['ai_exposure_tercile'] = pd.qcut(\n",
    "            df_final['ai_exposure_score'],\n",
    "            q=3,\n",
    "            labels=['Low', 'Medium', 'High'],\n",
    "            duplicates='drop'\n",
    "        )\n",
    "    except ValueError as e:\n",
    "        # If qcut fails (e.g., too many NaNs or duplicates), use simple cut\n",
    "        print(f\"\u26a0 Could not create terciles: {e}\")\n",
    "        print(\"  Using quartile-based cut instead\")\n",
    "        df_final['ai_exposure_tercile'] = pd.cut(\n",
    "            df_final['ai_exposure_score'],\n",
    "            bins=3,\n",
    "            labels=['Low', 'Medium', 'High']\n",
    "        )\n",
    "    \n",
    "    # Create log enrollment\n",
    "    df_final['log_enrollment'] = np.log(df_final['enrollment'] + 1)\n",
    "    \n",
    "    print(\"\\n\\nFinal dataset:\")\n",
    "    print(df_final.head(20))\n",
    "    print(f\"\\nShape: {df_final.shape}\")\n",
    "    \n",
    "    return df_final\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# STEP 8: VISUALIZATION\n",
    "# =============================================================================\n",
    "\n",
    "def create_descriptive_plots(df: pd.DataFrame, output_path: str = 'enrollment_trends_4digit.png'):\n",
    "    \"\"\"\n",
    "    Create descriptive visualizations for 4-digit CIP analysis.\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"CREATING VISUALIZATIONS\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "    \n",
    "    # 1. Enrollment trends by AI exposure group\n",
    "    ax1 = axes[0, 0]\n",
    "    trend_data = df.groupby(['year', 'high_ai_exposure'])['enrollment'].sum().reset_index()\n",
    "    # Normalize to 2019 (show as % of 2019 enrollment)\n",
    "    trend_2019 = trend_data[trend_data['year'] == 2019].set_index('high_ai_exposure')['enrollment']\n",
    "    trend_data['enrollment_pct_2019'] = trend_data.apply(\n",
    "        lambda row: (row['enrollment'] / trend_2019[row['high_ai_exposure']]) * 100\n",
    "            if row['high_ai_exposure'] in trend_2019.index else 100,\n",
    "        axis=1\n",
    "    )\n",
    "    \n",
    "    for group in [0, 1]:\n",
    "        data = trend_data[trend_data['high_ai_exposure'] == group]\n",
    "        label = 'High AI Exposure' if group else 'Low AI Exposure'\n",
    "        ax1.plot(data['year'], data['enrollment_pct_2019'], marker='o', label=label, linewidth=2)\n",
    "    ax1.set_xlabel('Year', fontsize=12)\n",
    "    ax1.set_ylabel('Enrollment (% of 2019)', fontsize=12)\n",
    "    ax1.set_title('Enrollment Trends by AI Exposure (4-digit CIP)', fontsize=14, fontweight='bold')\n",
    "    ax1.legend()\n",
    "    ax1.grid(alpha=0.3)\n",
    "    ax1.axvline(2022.5, color='red', linestyle='--', alpha=0.5, label='ChatGPT Launch')\n",
    "    \n",
    "    # 2. Distribution of AI exposure\n",
    "    ax2 = axes[0, 1]\n",
    "    cip_scores = df.groupby('CIP4')['ai_exposure_score'].first()\n",
    "    ax2.hist(cip_scores, bins=50, edgecolor='black', alpha=0.7, color='steelblue')\n",
    "    ax2.axvline(cip_scores.median(), color='red', linestyle='--', linewidth=2, label='Median')\n",
    "    ax2.set_xlabel('AI Exposure Score', fontsize=12)\n",
    "    ax2.set_ylabel('Number of 4-digit CIP Codes', fontsize=12)\n",
    "    ax2.set_title('Distribution of AI Exposure Across Majors', fontsize=14, fontweight='bold')\n",
    "    ax2.legend()\n",
    "    ax2.grid(alpha=0.3)\n",
    "    \n",
    "    # 3. Scatter: enrollment growth vs exposure\n",
    "    ax3 = axes[1, 0]\n",
    "    first_year = df['year'].min()\n",
    "    last_year = df['year'].max()\n",
    "    \n",
    "    growth_data = []\n",
    "    for cip in df['CIP4'].unique():\n",
    "        cip_data = df[df['CIP4'] == cip]\n",
    "        enroll_first = cip_data[cip_data['year'] == first_year]['enrollment'].values\n",
    "        enroll_last = cip_data[cip_data['year'] == last_year]['enrollment'].values\n",
    "        if len(enroll_first) > 0 and len(enroll_last) > 0 and enroll_first[0] > 0:\n",
    "            growth = (enroll_last[0] - enroll_first[0]) / enroll_first[0] * 100\n",
    "            exposure = cip_data['ai_exposure_score'].iloc[0] if len(cip_data) > 0 else None\n",
    "            if exposure is not None and pd.notna(exposure):\n",
    "                growth_data.append({'CIP4': cip, 'growth_rate': growth, 'ai_exposure': exposure})\n",
    "    \n",
    "    growth_df = pd.DataFrame(growth_data)\n",
    "    if len(growth_df) > 0:\n",
    "        ax3.scatter(growth_df['ai_exposure'], growth_df['growth_rate'], alpha=0.6, s=30)\n",
    "        ax3.set_xlabel('AI Exposure Score', fontsize=12)\n",
    "        ax3.set_ylabel(f'Enrollment Growth Rate ({first_year}-{last_year}, %)', fontsize=12)\n",
    "        ax3.set_title('Growth Rate vs AI Exposure', fontsize=14, fontweight='bold')\n",
    "        ax3.axhline(0, color='black', linestyle='--', linewidth=1, alpha=0.5)\n",
    "        ax3.grid(alpha=0.3)\n",
    "        \n",
    "        # Add correlation\n",
    "        corr = growth_df[['ai_exposure', 'growth_rate']].corr().iloc[0, 1]\n",
    "        ax3.text(0.05, 0.95, f'Correlation: {corr:.3f}', \n",
    "                transform=ax3.transAxes, verticalalignment='top',\n",
    "                bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))\n",
    "    \n",
    "    # 4. Enrollment by tercile over time\n",
    "    ax4 = axes[1, 1]\n",
    "    tercile_data = df.groupby(['year', 'ai_exposure_tercile'])['enrollment'].sum().reset_index()\n",
    "    # Normalize to 2019\n",
    "    tercile_2019 = tercile_data[tercile_data['year'] == 2019].set_index('ai_exposure_tercile')['enrollment']\n",
    "    tercile_data['enrollment_pct_2019'] = tercile_data.apply(\n",
    "        lambda row: (row['enrollment'] / tercile_2019[row['ai_exposure_tercile']]) * 100\n",
    "            if row['ai_exposure_tercile'] in tercile_2019.index else 100,\n",
    "        axis=1\n",
    "    )\n",
    "    \n",
    "    for tercile in ['Low', 'Medium', 'High']:\n",
    "        data = tercile_data[tercile_data['ai_exposure_tercile'] == tercile]\n",
    "        if len(data) > 0:\n",
    "            ax4.plot(data['year'], data['enrollment_pct_2019'], marker='o', label=f'{tercile} Exposure', linewidth=2)\n",
    "    ax4.set_xlabel('Year', fontsize=12)\n",
    "    ax4.set_ylabel('Enrollment (% of 2019)', fontsize=12)\n",
    "    ax4.set_title('Enrollment by AI Exposure Tercile', fontsize=14, fontweight='bold')\n",
    "    ax4.legend()\n",
    "    ax4.grid(alpha=0.3)\n",
    "    ax4.axvline(2022.5, color='red', linestyle='--', alpha=0.5)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(output_path, dpi=300, bbox_inches='tight')\n",
    "    print(f\"\\n\u2713 Saved plots to {output_path}\")\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# MAIN EXECUTION\n",
    "# =============================================================================\n",
    "\n",
    "def main():\n",
    "    \"\"\"\n",
    "    Main execution function.\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"\\n\" + \"#\"*70)\n",
    "    print(\"# AI EXPOSURE AND ENROLLMENT ANALYSIS - 4-DIGIT CIP\")\n",
    "    print(\"#\"*70 + \"\\n\")\n",
    "    \n",
    "    # FILE PATHS\n",
    "    FELTEN_PATH = '/Users/jeffreyohl/Dropbox/CollegeMajorData/FeltenEtAl/AIOE_DataAppendix.xlsx'\n",
    "    CROSSWALK_PATH = '/Users/jeffreyohl/Dropbox/CollegeMajorData/Crosswalks/crosswalk_handout.xlsx'\n",
    "    ACS_PATH = '/Users/jeffreyohl/Dropbox/CollegeMajorData/IPUMS/usa_00008.csv'\n",
    "    ENROLLMENT_PATH_2025 = '/Users/jeffreyohl/Dropbox/CollegeMajorData/National Student Clearinghouse Data/CTEESpring2025-DataAppendix.xlsx'\n",
    "    ENROLLMENT_PATH_2024 = '/Users/jeffreyohl/Dropbox/CollegeMajorData/National Student Clearinghouse Data/CTEESpring2024-Appendix.xlsx'\n",
    "    OUTPUT_DIR = '/Users/jeffreyohl/Dropbox/CollegeMajorData/output'\n",
    "    \n",
    "    try:\n",
    "        # Step 1: Load Felten data\n",
    "        felten = load_felten_data(FELTEN_PATH)\n",
    "        \n",
    "        # Step 2: Load FOD to 4-digit CIP crosswalk\n",
    "        fod_to_cip4 = load_fod_cip4_crosswalk(CROSSWALK_PATH)\n",
    "        \n",
    "        # Step 3: Load and combine enrollment data (2019-2025) - MOVED UP!\n",
    "        enrollment = load_and_combine_enrollment_data(ENROLLMENT_PATH_2024, ENROLLMENT_PATH_2025)\n",
    "        \n",
    "        # Step 4: Add empirical enrollment weights to crosswalk\n",
    "        fod_to_cip4_weighted = add_empirical_weights_to_crosswalk(\n",
    "            fod_to_cip4, enrollment, base_year=2019\n",
    "        )\n",
    "        \n",
    "        # Step 5-6: Process ACS and calculate exposure scores\n",
    "        print(\"\\n\" + \"=\"*70)\n",
    "        print(\"PROCESSING ACS DATA\")\n",
    "        print(\"=\"*70)\n",
    "        acs = load_and_filter_acs(ACS_PATH)\n",
    "        acs_with_exposure = process_acs_with_exposure(acs, felten, fod_to_cip4_weighted)\n",
    "        cip_exposure = calculate_cip4_exposure(acs_with_exposure)\n",
    "        \n",
    "        # Save exposure scores\n",
    "        cip_exposure.to_csv(f'{OUTPUT_DIR}/cip4_ai_exposure_scores.csv', index=False)\n",
    "        print(f\"\\n\u2713 Saved exposure scores to {OUTPUT_DIR}/cip4_ai_exposure_scores.csv\")\n",
    "        \n",
    "        # Step 7: Merge enrollment with exposure\n",
    "        df_final = merge_enrollment_exposure(enrollment, cip_exposure)\n",
    "        \n",
    "        # Save final dataset\n",
    "        df_final.to_csv(f'{OUTPUT_DIR}/enrollment_with_ai_exposure_4digit.csv', index=False)\n",
    "        print(f\"\\n\u2713 Saved final dataset to {OUTPUT_DIR}/enrollment_with_ai_exposure_4digit.csv\")\n",
    "        \n",
    "        # Step 8: Create visualizations\n",
    "        create_descriptive_plots(df_final, f'{OUTPUT_DIR}/enrollment_trends_4digit.png')\n",
    "        \n",
    "        # Step 9: Diagnostic reporting - what's missing?\n",
    "        print(\"\\n\" + \"#\"*70)\n",
    "        print(\"# DIAGNOSTIC REPORT: COVERAGE ANALYSIS\")\n",
    "        print(\"#\"*70)\n",
    "        \n",
    "        # (i) ACS FOD codes not in crosswalk\n",
    "        acs_fods = set(acs['DEGFIELDD'].dropna().unique())\n",
    "        crosswalk_fods = set(fod_to_cip4['FOD'].unique())\n",
    "        missing_fods = acs_fods - crosswalk_fods\n",
    "        \n",
    "        print(f\"\\n(i) ACS FOD codes NOT in crosswalk mapping:\")\n",
    "        print(f\"    Total: {len(missing_fods)} FOD codes\")\n",
    "        if len(missing_fods) > 0:\n",
    "            print(f\"    FODs: {sorted(list(missing_fods))[:20]}\")\n",
    "            # How many ACS observations do these represent?\n",
    "            missing_fod_count = acs[acs['DEGFIELDD'].isin(missing_fods)]['PERWT'].sum()\n",
    "            total_count = acs['PERWT'].sum()\n",
    "            print(f\"    Represents {missing_fod_count:,.0f} / {total_count:,.0f} ACS observations ({missing_fod_count/total_count*100:.1f}%)\")\n",
    "        \n",
    "        # (ii) CIP codes with enrollment but no FOD mapping\n",
    "        enrollment_cips = set(enrollment['CIP4'].unique())\n",
    "        crosswalk_cips = set(fod_to_cip4['CIP4'].unique())\n",
    "        unmapped_cips = enrollment_cips - crosswalk_cips\n",
    "        \n",
    "        print(f\"\\n(ii) CIP4 codes with enrollment but NOT mapped from any FOD:\")\n",
    "        print(f\"     Total: {len(unmapped_cips)} CIP4 codes\")\n",
    "        if len(unmapped_cips) > 0:\n",
    "            # Get enrollment counts for these\n",
    "            unmapped_enroll = enrollment[enrollment['CIP4'].isin(unmapped_cips)]\n",
    "            unmapped_2019 = unmapped_enroll[unmapped_enroll['year'] == 2019]['enrollment'].sum()\n",
    "            total_2019 = enrollment[enrollment['year'] == 2019]['enrollment'].sum()\n",
    "            print(f\"     CIP4s: {sorted(list(unmapped_cips))[:30]}\")\n",
    "            print(f\"     2019 enrollment: {unmapped_2019:,.0f} / {total_2019:,.0f} ({unmapped_2019/total_2019*100:.1f}%)\")\n",
    "            print(f\"\\n     Top 10 unmapped CIP4s by 2019 enrollment:\")\n",
    "            top_unmapped = unmapped_enroll[unmapped_enroll['year'] == 2019].nlargest(10, 'enrollment')[['CIP4', 'enrollment']]\n",
    "            for _, row in top_unmapped.iterrows():\n",
    "                print(f\"       CIP4 {row['CIP4']}: {row['enrollment']:,.0f} students\")\n",
    "        \n",
    "        print(\"\\n\" + \"#\"*70)\n",
    "        print(\"# DATA PREPARATION COMPLETE (4-DIGIT CIP)\")\n",
    "        print(\"#\"*70)\n",
    "        print(\"\\nNext steps:\")\n",
    "        print(\"1. Review cip4_ai_exposure_scores.csv to validate exposure scores\")\n",
    "        print(\"2. Check enrollment_with_ai_exposure_4digit.csv for data quality\")\n",
    "        print(\"3. Code missing FOD\u2192CIP4 mappings to improve coverage\")\n",
    "        print(\"4. Run econometric_analysis.py for DiD and event study\")\n",
    "        print(\"\\n4-digit CIP analysis provides:\")\n",
    "        print(\"  - Computer Science (1107) vs Information Systems (1104)\")\n",
    "        print(\"  - Business Administration (5202) vs Finance (5208) vs Accounting (5203)\")  \n",
    "        print(\"  - More granular treatment effects and heterogeneity analysis\")\n",
    "        \n",
    "    except FileNotFoundError as e:\n",
    "        print(f\"\\n\u274c Error: File not found - {e}\")\n",
    "        print(\"\\nPlease check that all data files exist at the specified paths:\")\n",
    "        print(f\"  - Felten: {FELTEN_PATH}\")\n",
    "        print(f\"  - Crosswalk: {CROSSWALK_PATH}\")\n",
    "        print(f\"  - ACS: {ACS_PATH}\")\n",
    "        print(f\"  - Enrollment 2024: {ENROLLMENT_PATH_2024}\")\n",
    "        print(f\"  - Enrollment 2025: {ENROLLMENT_PATH_2025}\")\n",
    "    except Exception as e:\n",
    "        print(f\"\\n\u274c Error occurred: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "######################################################################\n",
      "# AI EXPOSURE AND ENROLLMENT ANALYSIS - 4-DIGIT CIP\n",
      "######################################################################\n",
      "\n",
      "======================================================================\n",
      "LOADING FELTEN AIOE DATA\n",
      "======================================================================\n",
      "\n",
      "Loaded 774 occupations\n",
      "AIOE range: -2.67 to 1.53\n",
      "\n",
      "======================================================================\n",
      "LOADING FOD TO 4-DIGIT CIP CROSSWALK\n",
      "======================================================================\n",
      "\n",
      "Created 614 FOD\u2192CIP4 mappings\n",
      "  Average 3.2 CIP4 codes per FOD\n",
      "\n",
      "======================================================================\n",
      "PROCESSING ACS DATA\n",
      "======================================================================\n",
      "\n",
      "======================================================================\n",
      "LOADING ACS PUMS DATA\n",
      "======================================================================\n",
      "\n",
      "Initial sample: 4,770,082 observations\n",
      "Filtered sample: 1,405,906 observations\n",
      "  - Age 22-35\n",
      "  - Valid occupation (OCCSOC) and field of degree (DEGFIELDD)\n",
      "\n",
      "Unique DEGFIELDD codes: 175\n",
      "Unique OCCSOC codes: 530\n",
      "\n",
      "======================================================================\n",
      "MAPPING FOD TO 4-DIGIT CIP AND MERGING AI EXPOSURE\n",
      "======================================================================\n",
      "\n",
      "Mapped 168 ACS observations to 2,638,688 CIP4 mappings\n",
      "  (Average 15706.5 CIP4 codes per person)\n",
      "\n",
      "Matched 1,374,527/2,638,688 observations to AI exposure (52.1%)\n",
      "\n",
      "\u26a0 Imputing 1264161 missing AIOE values with mean (0.6162)\n",
      "\n",
      "Final sample: 2,638,688 observations\n",
      "Unique 4-digit CIP codes: 365\n",
      "\n",
      "======================================================================\n",
      "CALCULATING 4-DIGIT CIP-LEVEL AI EXPOSURE SCORES\n",
      "======================================================================\n",
      "\n",
      "Calculated AI exposure for 365 4-digit CIP codes\n",
      "\n",
      "AI Exposure Score Distribution:\n",
      "count    365.000000\n",
      "mean       0.586657\n",
      "std        0.142604\n",
      "min        0.093170\n",
      "25%        0.550304\n",
      "50%        0.612211\n",
      "75%        0.660773\n",
      "max        1.064023\n",
      "Name: ai_exposure_score, dtype: float64\n",
      "\n",
      "\n",
      "Top 20 most AI-exposed majors (4-digit CIP):\n",
      "     CIP4  ai_exposure_score     n_obs\n",
      "344  5203           1.064023   26092.0\n",
      "349  5208           0.893085   21972.0\n",
      "358  5217           0.893085   21972.0\n",
      "82   1408           0.882391    8613.0\n",
      "347  5206           0.847676    1747.0\n",
      "88   1414           0.803274     984.0\n",
      "275  4506           0.800410   17931.0\n",
      "68   1311           0.798062     207.0\n",
      "228  4004           0.795709     531.0\n",
      "76   1402           0.794777    2587.0\n",
      "313  5102           0.790510    5111.0\n",
      "341  5200           0.780273  162400.0\n",
      "78   1404           0.775323     369.0\n",
      "38   0909           0.773682    5483.0\n",
      "81   1407           0.768679    6260.0\n",
      "266  4405           0.764002    1111.0\n",
      "277  4509           0.761276    3718.0\n",
      "354  5213           0.760643    3936.0\n",
      "91   1420           0.755148     104.0\n",
      "21   0400           0.750975    6144.0\n",
      "\n",
      "\n",
      "Bottom 20 least AI-exposed majors (4-digit CIP):\n",
      "     CIP4  ai_exposure_score    n_obs\n",
      "289  4700           0.093170    307.0\n",
      "290  4701           0.093170    307.0\n",
      "291  4702           0.093170    307.0\n",
      "292  4703           0.093170    307.0\n",
      "293  4704           0.093170    307.0\n",
      "294  4706           0.093170    307.0\n",
      "295  4799           0.093170    307.0\n",
      "232  4100           0.121214    279.0\n",
      "233  4102           0.121214    279.0\n",
      "234  4103           0.121214    279.0\n",
      "235  4199           0.121214    279.0\n",
      "53   1200           0.189050   1007.0\n",
      "54   1203           0.189050   1007.0\n",
      "55   1204           0.189050   1007.0\n",
      "56   1205           0.189050   1007.0\n",
      "57   1299           0.189050   1007.0\n",
      "9    0109           0.281416   3643.0\n",
      "18   0305           0.311669    742.0\n",
      "323  5116           0.314859  39347.0\n",
      "319  5110           0.315186   2526.0\n",
      "\n",
      "\u2713 Saved exposure scores to /Users/jeffreyohl/Dropbox/CollegeMajorData/output/cip4_ai_exposure_scores.csv\n",
      "\n",
      "======================================================================\n",
      "LOADING AND COMBINING ENROLLMENT DATA (2019-2025)\n",
      "======================================================================\n",
      "\n",
      "Loading 2019-2024 data from CTEESpring2024-Appendix.xlsx...\n",
      "  Loaded 488 rows\n",
      "  Found 6 enrollment columns for years 2019-2024\n",
      "  Reshaped to 2001 observations\n",
      "\n",
      "Loading 2020-2025 data from CTEESpring2025-DataAppendix.xlsx...\n",
      "  Loaded 1410 rows\n",
      "  Filtered to 470 Undergraduate 4-year rows\n",
      "  Reshaped to 2097 observations\n",
      "\n",
      "Combining datasets...\n",
      "\n",
      "\u2713 Combined dataset: 2421 observations\n",
      "  Years: [np.int64(2019), np.int64(2020), np.int64(2021), np.int64(2022), np.int64(2023), np.int64(2024), np.int64(2025)]\n",
      "  Unique 4-digit CIP codes: 390\n",
      "\n",
      "Total enrollment by year:\n",
      "  2019: 8,881,017\n",
      "  2020: 8,836,845\n",
      "  2021: 8,690,353\n",
      "  2022: 8,581,948\n",
      "  2023: 8,456,944\n",
      "  2024: 8,669,730\n",
      "  2025: 8,877,394\n",
      "\n",
      "======================================================================\n",
      "MERGING ENROLLMENT WITH AI EXPOSURE\n",
      "======================================================================\n",
      "\n",
      "Matched 1884/2421 enrollment records (77.8%)\n",
      "\n",
      "\n",
      "Final dataset:\n",
      "    CIP4  year    enrollment  ai_exposure_score    n_obs  high_ai_exposure  \\\n",
      "0   0100  2019   9519.068031           0.411245  11057.0                 0   \n",
      "1   0100  2020   9282.396944           0.411245  11057.0                 0   \n",
      "2   0100  2021   9147.125698           0.411245  11057.0                 0   \n",
      "3   0100  2022   8410.844989           0.411245  11057.0                 0   \n",
      "4   0100  2023   8616.469810           0.411245  11057.0                 0   \n",
      "5   0100  2024   8706.931635           0.411245  11057.0                 0   \n",
      "6   0100  2025   8644.549148           0.411245  11057.0                 0   \n",
      "7   0101  2019  18059.790261           0.504175   3024.0                 0   \n",
      "8   0101  2020  17627.500204           0.504175   3024.0                 0   \n",
      "9   0101  2021  16472.834741           0.504175   3024.0                 0   \n",
      "10  0101  2022  16076.321122           0.504175   3024.0                 0   \n",
      "11  0101  2023  14674.973222           0.504175   3024.0                 0   \n",
      "12  0101  2024  17441.527090           0.504175   3024.0                 0   \n",
      "13  0101  2025  17907.299601           0.504175   3024.0                 0   \n",
      "14  0102  2019   1259.195858           0.488248   2584.0                 0   \n",
      "15  0102  2020   1123.517786           0.488248   2584.0                 0   \n",
      "16  0102  2021   1006.194094           0.488248   2584.0                 0   \n",
      "17  0102  2022    936.594522           0.488248   2584.0                 0   \n",
      "18  0102  2023    926.160247           0.488248   2584.0                 0   \n",
      "19  0102  2024    928.274895           0.488248   2584.0                 0   \n",
      "\n",
      "    ai_exposure_std ai_exposure_tercile  log_enrollment  \n",
      "0         -1.260232                 Low        9.161157  \n",
      "1         -1.260232                 Low        9.135983  \n",
      "2         -1.260232                 Low        9.121304  \n",
      "3         -1.260232                 Low        9.037396  \n",
      "4         -1.260232                 Low        9.061547  \n",
      "5         -1.260232                 Low        9.071990  \n",
      "6         -1.260232                 Low        9.064800  \n",
      "7         -0.611101                 Low        9.801499  \n",
      "8         -0.611101                 Low        9.777272  \n",
      "9         -0.611101                 Low        9.709529  \n",
      "10        -0.611101                 Low        9.685165  \n",
      "11        -0.611101                 Low        9.593967  \n",
      "12        -0.611101                 Low        9.766667  \n",
      "13        -0.611101                 Low        9.793020  \n",
      "14        -0.722354                 Low        7.139022  \n",
      "15        -0.722354                 Low        7.025110  \n",
      "16        -0.722354                 Low        6.914924  \n",
      "17        -0.722354                 Low        6.843318  \n",
      "18        -0.722354                 Low        6.832126  \n",
      "19        -0.722354                 Low        6.834405  \n",
      "\n",
      "Shape: (2421, 9)\n",
      "\n",
      "\u2713 Saved final dataset to /Users/jeffreyohl/Dropbox/CollegeMajorData/output/enrollment_with_ai_exposure_4digit.csv\n",
      "\n",
      "======================================================================\n",
      "CREATING VISUALIZATIONS\n",
      "======================================================================\n",
      "\n",
      "\u2713 Saved plots to /Users/jeffreyohl/Dropbox/CollegeMajorData/output/enrollment_trends_4digit.png\n",
      "\n",
      "######################################################################\n",
      "# DATA PREPARATION COMPLETE (4-DIGIT CIP)\n",
      "######################################################################\n",
      "\n",
      "Next steps:\n",
      "1. Review cip4_ai_exposure_scores.csv to validate exposure scores\n",
      "2. Check enrollment_with_ai_exposure_4digit.csv for data quality\n",
      "3. Run econometric_analysis.py for DiD and event study\n",
      "\n",
      "4-digit CIP analysis provides:\n",
      "  - Computer Science (1107) vs Information Systems (1104)\n",
      "  - Business Administration (5202) vs Finance (5208) vs Accounting (5203)\n",
      "  - More granular treatment effects and heterogeneity analysis\n"
     ]
    }
   ],
   "source": [
    "# Run main analysis\n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}