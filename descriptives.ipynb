{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 6 manual FOD→CIP4 mappings\n",
      "\n",
      "######################################################################\n",
      "# AI EXPOSURE AND ENROLLMENT ANALYSIS - 4-DIGIT CIP\n",
      "######################################################################\n",
      "\n",
      "======================================================================\n",
      "LOADING FELTEN AIOE DATA\n",
      "======================================================================\n",
      "\n",
      "Loaded 774 occupations\n",
      "AIOE range: -1.85 to 1.93\n",
      "\n",
      "======================================================================\n",
      "LOADING FOD TO 4-DIGIT CIP CROSSWALK\n",
      "======================================================================\n",
      "\n",
      "Loaded 614 FOD→CIP4 mappings from crosswalk file\n",
      "  191 unique FODs\n",
      "  398 unique CIP4 codes\n",
      "  Average 3.2 CIP4 codes per FOD\n",
      "\n",
      "✓ Added 6 manual mappings\n",
      "  FOD 6107 → CIP4 5138 (Registered Nursing/Nursing Administration/Nursing Research and Clinical Nursing)\n",
      "  FOD 3611 → CIP4 2615 (Neurobiology and Neurosciences)\n",
      "  FOD 5202 → CIP4 4228 (Clinical, Counseling and Applied Psychology)\n",
      "  FOD 5203 → CIP4 4228 (Clinical, Counseling and Applied Psychology)\n",
      "  FOD 5203 → CIP4 4228 (Clinical, Counseling and Applied Psychology)\n",
      "  FOD 5098 → CIP4 4099 (Physical Sciences, other)\n",
      "\n",
      "Sample mappings:\n",
      "  FOD 1100 → CIP4 ['0100']\n",
      "  FOD 1101 → CIP4 ['0100', '0101', '0102', '0103', '0104', '0105', '0106', '0107', '0199']\n",
      "  FOD 1102 → CIP4 ['0100', '0101']\n",
      "  FOD 1103 → CIP4 ['0100', '0109']\n",
      "  FOD 1104 → CIP4 ['0100', '0110']\n",
      "  FOD 1105 → CIP4 ['0100', '0111']\n",
      "  FOD 1106 → CIP4 ['0100', '0112']\n",
      "  FOD 1199 → CIP4 ['0100', '0108']\n",
      "  FOD 1301 → CIP4 ['0300', '0301']\n",
      "  FOD 1302 → CIP4 ['0300', '0305']\n",
      "\n",
      "======================================================================\n",
      "LOADING AND COMBINING ENROLLMENT DATA (2019-2025)\n",
      "======================================================================\n",
      "\n",
      "Loading 2019-2024 data from CTEESpring2024-Appendix.xlsx...\n",
      "  Loaded 488 rows\n",
      "  Found 6 enrollment columns for years 2019-2024\n",
      "  Reshaped to 2001 observations\n",
      "\n",
      "Loading 2020-2025 data from CTEESpring2025-DataAppendix.xlsx...\n",
      "  Loaded 1410 rows\n",
      "  Filtered to 470 Undergraduate 4-year rows\n",
      "  Reshaped to 2097 observations\n",
      "\n",
      "Combining datasets...\n",
      "\n",
      "✓ Combined dataset: 2421 observations\n",
      "  Years: [np.int64(2019), np.int64(2020), np.int64(2021), np.int64(2022), np.int64(2023), np.int64(2024), np.int64(2025)]\n",
      "  Unique 4-digit CIP codes: 390\n",
      "\n",
      "Total enrollment by year:\n",
      "  2019: 8,881,017\n",
      "  2020: 8,836,845\n",
      "  2021: 8,690,353\n",
      "  2022: 8,581,948\n",
      "  2023: 8,456,944\n",
      "  2024: 8,669,730\n",
      "  2025: 8,877,394\n",
      "\n",
      "======================================================================\n",
      "ADDING EMPIRICAL ENROLLMENT WEIGHTS TO FOD→CIP4 MAPPING\n",
      "======================================================================\n",
      "\n",
      "Using 2019 enrollment as basis for weights\n",
      "  324 CIP4 codes have enrollment data\n",
      "\n",
      "Calculated empirical weights for 620 FOD→CIP4 mappings\n",
      "\n",
      "Sample weighted mappings:\n",
      "\n",
      "  FOD 1100 maps to 1 CIP4 codes:\n",
      "    CIP4 0100: weight = 1.000\n",
      "\n",
      "  FOD 1101 maps to 9 CIP4 codes:\n",
      "    CIP4 0100: weight = 0.261\n",
      "    CIP4 0101: weight = 0.496\n",
      "    CIP4 0102: weight = 0.035\n",
      "    CIP4 0103: weight = 0.074\n",
      "    CIP4 0104: weight = 0.008\n",
      "    CIP4 0105: weight = 0.041\n",
      "    CIP4 0106: weight = 0.051\n",
      "    CIP4 0107: weight = 0.006\n",
      "    CIP4 0199: weight = 0.028\n",
      "\n",
      "  FOD 1102 maps to 2 CIP4 codes:\n",
      "    CIP4 0100: weight = 0.345\n",
      "    CIP4 0101: weight = 0.655\n",
      "\n",
      "✓ All FOD weights sum to 1.0\n",
      "\n",
      "======================================================================\n",
      "PROCESSING ACS DATA\n",
      "======================================================================\n",
      "\n",
      "======================================================================\n",
      "LOADING ACS PUMS DATA\n",
      "======================================================================\n",
      "\n",
      "Initial sample: 4,770,082 observations\n",
      "Filtered sample: 908,298 observations\n",
      "  - Age 22-35\n",
      "  - Valid occupation (OCCSOC) and field of degree (DEGFIELDD)\n",
      "\n",
      "Unique DEGFIELDD codes: 174\n",
      "Unique OCCSOC codes: 530\n",
      "\n",
      "======================================================================\n",
      "MAPPING FOD TO 4-DIGIT CIP AND MERGING AI EXPOSURE\n",
      "======================================================================\n",
      "  Each ACS person contributes to avg 3.0 CIP4 codes (weighted by 2019 enrollment)\n",
      "\n",
      "Mapped 170 ACS observations to 2,688,732 CIP4 mappings\n",
      "  (Average 15816.1 CIP4 codes per person)\n",
      "\n",
      "Matched 1,412,675/2,688,732 observations to AI exposure (52.5%)\n",
      "\n",
      "⚠ Dropping 1,276,057 observations with missing AIOE scores\n",
      "\n",
      "Final sample: 1,412,675 observations\n",
      "Unique 4-digit CIP codes: 369\n",
      "\n",
      "======================================================================\n",
      "CALCULATING 4-DIGIT CIP-LEVEL AI EXPOSURE SCORES\n",
      "======================================================================\n",
      "\n",
      "Calculated AI exposure for 369 4-digit CIP codes\n",
      "\n",
      "AI Exposure Score Distribution:\n",
      "count    369.000000\n",
      "mean       0.578997\n",
      "std        0.228450\n",
      "min       -0.292599\n",
      "25%        0.441772\n",
      "50%        0.637870\n",
      "75%        0.711421\n",
      "max        1.072428\n",
      "Name: ai_exposure_score, dtype: float64\n",
      "\n",
      "\n",
      "Top 20 most AI-exposed majors (4-digit CIP):\n",
      "CIP4                                                  CIP4_title  ai_exposure_score  n_obs\n",
      "1311 Counselor Education/School Counseling and Guidance Services           1.072428    136\n",
      "5203                                                  Accounting           1.033059  20511\n",
      "5102                            Communication Disorders, General           1.009464   3759\n",
      "5208                                            Finance, General           0.997712  14181\n",
      "5217                                                   Insurance           0.997712  14181\n",
      "5206                               Business/Managerial Economics           0.948364   1084\n",
      "4206                                       Counseling Psychology           0.938485    388\n",
      "4506                                          Economics, General           0.934409   9894\n",
      "5213                                 Management Science, General           0.922417   1858\n",
      "4405                                      Public Policy Analysis           0.921830    573\n",
      "4509                         International Relations and Affairs           0.917250   1878\n",
      "1300                                        Elementary Education           0.904944  12434\n",
      "4004               Atmospheric Sciences and Meteorology, General           0.904130    287\n",
      "0909                       Organizational Communication, General           0.902333   3453\n",
      "2705                                         Statistics, General           0.889246    557\n",
      "2799                           Mathematics and Statistics, Other           0.889246    557\n",
      "4512                                       Urban Studies/Affairs           0.886720    240\n",
      "4505                           Demography and Population Studies           0.886720    240\n",
      "2703                                         Applied Mathematics           0.872028    451\n",
      "3008                            Mathematics and Computer Science           0.870933     39\n",
      "\n",
      "\n",
      "Bottom 20 least AI-exposed majors (4-digit CIP):\n",
      "CIP4                                                                                 CIP4_title  ai_exposure_score  n_obs\n",
      "4700                                           Electrical and Mechanic Repairs and Technologies          -0.292599    170\n",
      "4704                                                                       Gunsmithing/Gunsmith          -0.292599    170\n",
      "4706                                        Autobody/Collision and Repair Technology/Technician          -0.292599    170\n",
      "4799                                          Mechanic and Repair Technology/Technicians, Other          -0.292599    170\n",
      "4701                          Electrical/Electronics Equipment Installation and Repair, General          -0.292599    170\n",
      "4702 Heating, Air Conditioning, Ventilation and Refrigeration Maintenance Technology/Technician          -0.292599    170\n",
      "4703                                          Heavy Equipment Maintenance Technology/Technician          -0.292599    170\n",
      "0305                                                                          Forestry, General          -0.062477    292\n",
      "4100                                              Nuclear and Industrial Radiology Technologies           0.046239    229\n",
      "4102                                                Industrial/Radiologic Technology/Technician           0.046239    229\n",
      "4199                                                    Science Technologies/Technicians, Other           0.046239    229\n",
      "4103                                                             Chemical Technology/Technician           0.046239    229\n",
      "1200                                                    Cosmetology Services and Culinary Arts            0.070021    672\n",
      "1204                                                         Cosmetology/Cosmetologist, General           0.070021    672\n",
      "1299                                                      Personal and Culinary Services, Other           0.070021    672\n",
      "1203                                              Funeral Service and Mortuary Science, General           0.070021    672\n",
      "1205                                                 Cooking and Related Culinary Arts, General           0.070021    672\n",
      "5110                                                           Blood Bank Technology Specialist           0.118086   1463\n",
      "0111                                                                             Plant Sciences           0.156051    711\n",
      "0109                                                                   Animal Sciences, General           0.160466   2374\n",
      "\n",
      "✓ Saved exposure scores to /Users/jeffreyohl/Dropbox/CollegeMajorData/output/cip4_ai_exposure_scores.csv\n",
      "\n",
      "======================================================================\n",
      "MERGING ENROLLMENT WITH AI EXPOSURE\n",
      "======================================================================\n",
      "\n",
      "Matched 1912/2421 enrollment records (79.0%)\n",
      "\n",
      "\n",
      "Final dataset:\n",
      "    CIP4                             CIP4_title  year    enrollment  \\\n",
      "0   0100                  Agriculture, General.  2019   9519.068031   \n",
      "1   0100                   Agriculture, General  2020   9282.396944   \n",
      "2   0100                   Agriculture, General  2021   9147.125698   \n",
      "3   0100                   Agriculture, General  2022   8410.844989   \n",
      "4   0100                   Agriculture, General  2023   8616.469810   \n",
      "5   0100                   Agriculture, General  2024   8706.931635   \n",
      "6   0100                   Agriculture, General  2025   8644.549148   \n",
      "7   0101  Agricultural Business and Management.  2019  18059.790261   \n",
      "8   0101   Agricultural Business and Management  2020  17627.500204   \n",
      "9   0101   Agricultural Business and Management  2021  16472.834741   \n",
      "10  0101   Agricultural Business and Management  2022  16076.321122   \n",
      "11  0101   Agricultural Business and Management  2023  14674.973222   \n",
      "12  0101   Agricultural Business and Management  2024  17441.527090   \n",
      "13  0101   Agricultural Business and Management  2025  17907.299601   \n",
      "14  0102            Agricultural Mechanization.  2019   1259.195858   \n",
      "15  0102             Agricultural Mechanization  2020   1123.517786   \n",
      "16  0102             Agricultural Mechanization  2021   1006.194094   \n",
      "17  0102             Agricultural Mechanization  2022    936.594522   \n",
      "18  0102             Agricultural Mechanization  2023    926.160247   \n",
      "19  0102             Agricultural Mechanization  2024    928.274895   \n",
      "\n",
      "    ai_exposure_score   n_obs  high_ai_exposure  ai_exposure_std  \\\n",
      "0            0.317631  6423.0                 0        -1.146972   \n",
      "1            0.317631  6423.0                 0        -1.146972   \n",
      "2            0.317631  6423.0                 0        -1.146972   \n",
      "3            0.317631  6423.0                 0        -1.146972   \n",
      "4            0.317631  6423.0                 0        -1.146972   \n",
      "5            0.317631  6423.0                 0        -1.146972   \n",
      "6            0.317631  6423.0                 0        -1.146972   \n",
      "7            0.444040  1809.0                 0        -0.592312   \n",
      "8            0.444040  1809.0                 0        -0.592312   \n",
      "9            0.444040  1809.0                 0        -0.592312   \n",
      "10           0.444040  1809.0                 0        -0.592312   \n",
      "11           0.444040  1809.0                 0        -0.592312   \n",
      "12           0.444040  1809.0                 0        -0.592312   \n",
      "13           0.444040  1809.0                 0        -0.592312   \n",
      "14           0.415259  1527.0                 0        -0.718598   \n",
      "15           0.415259  1527.0                 0        -0.718598   \n",
      "16           0.415259  1527.0                 0        -0.718598   \n",
      "17           0.415259  1527.0                 0        -0.718598   \n",
      "18           0.415259  1527.0                 0        -0.718598   \n",
      "19           0.415259  1527.0                 0        -0.718598   \n",
      "\n",
      "   ai_exposure_tercile  log_enrollment  \n",
      "0                  Low        9.161157  \n",
      "1                  Low        9.135983  \n",
      "2                  Low        9.121304  \n",
      "3                  Low        9.037396  \n",
      "4                  Low        9.061547  \n",
      "5                  Low        9.071990  \n",
      "6                  Low        9.064800  \n",
      "7                  Low        9.801499  \n",
      "8                  Low        9.777272  \n",
      "9                  Low        9.709529  \n",
      "10                 Low        9.685165  \n",
      "11                 Low        9.593967  \n",
      "12                 Low        9.766667  \n",
      "13                 Low        9.793020  \n",
      "14                 Low        7.139022  \n",
      "15                 Low        7.025110  \n",
      "16                 Low        6.914924  \n",
      "17                 Low        6.843318  \n",
      "18                 Low        6.832126  \n",
      "19                 Low        6.834405  \n",
      "\n",
      "Shape: (2421, 10)\n",
      "Columns: ['CIP4', 'CIP4_title', 'year', 'enrollment', 'ai_exposure_score', 'n_obs', 'high_ai_exposure', 'ai_exposure_std', 'ai_exposure_tercile', 'log_enrollment']\n",
      "\n",
      "✓ Saved final dataset to /Users/jeffreyohl/Dropbox/CollegeMajorData/output/enrollment_with_ai_exposure_4digit.csv\n",
      "\n",
      "======================================================================\n",
      "CREATING VISUALIZATIONS\n",
      "======================================================================\n",
      "\n",
      "✓ Saved plots to /Users/jeffreyohl/Dropbox/CollegeMajorData/output/enrollment_trends_4digit.png\n",
      "\n",
      "======================================================================\n",
      "CREATING TERCILE DEEP-DIVE PLOTS (TOP 5)\n",
      "======================================================================\n",
      "\n",
      "Low Tercile:\n",
      "  Top 5 CIP4s: ['5138', '2601', '4301', '3105', '1313']\n",
      "  Coverage: 63.6% of Low tercile enrollment\n",
      "  2019 enrollment in top 5: 1,430,781 / 2,248,813\n",
      "\n",
      "Medium Tercile:\n",
      "  Top 5 CIP4s: ['2401', '1312', '1101', '1419', '1107']\n",
      "  Coverage: 51.2% of Medium tercile enrollment\n",
      "  2019 enrollment in top 5: 1,445,037 / 2,820,046\n",
      "\n",
      "High Tercile:\n",
      "  Top 5 CIP4s: ['5202', '4201', '5203', '0901', '5201']\n",
      "  Coverage: 45.5% of High tercile enrollment\n",
      "  2019 enrollment in top 5: 1,590,963 / 3,494,893\n",
      "\n",
      "✓ Saved tercile deep-dive plots to /Users/jeffreyohl/Dropbox/CollegeMajorData/output/enrollment_tercile_deepdive.png\n",
      "\n",
      "######################################################################\n",
      "# DIAGNOSTIC REPORT: COVERAGE ANALYSIS\n",
      "######################################################################\n",
      "\n",
      "(i) ACS FOD codes NOT in crosswalk mapping:\n",
      "    Total: 4 FOD codes\n",
      "    FODs: [np.int64(1107), np.int64(4000), np.int64(4009), np.int64(5008)]\n",
      "    Represents 69,285 / 20,881,650 ACS observations (0.3%)\n",
      "\n",
      "(ii) CIP4 codes with enrollment but NOT mapped from any FOD:\n",
      "     Total: 80 CIP4 codes\n",
      "     CIP4s: ['0113', '0180', '0181', '0182', '0183', '0410', '0999', '1099', '1440', '1441', '1442', '1443', '1445', '1447', '1448', '1517', '1617', '1910', '2313', '2314', '2614', '2706', '2805', '2899', '2902', '2903', '2904', '2906', '2999', '3026']\n",
      "     2019 enrollment: 142,465 / 8,881,017 (1.6%)\n",
      "\n",
      "     Top 10 unmapped CIP4s by 2019 enrollment:\n",
      "       CIP4 4227 (Research and Experimental Psychology.): 31,141 students\n",
      "       CIP4 2313 (Rhetoric and Composition/Writing Studies.): 25,694 students\n",
      "       CIP4 4304 (Security Science and Technology.): 14,765 students\n",
      "       CIP4 4303 (Homeland Security.): 11,083 students\n",
      "       CIP4 5010 (Arts, Entertainment, and Media Management.): 10,990 students\n",
      "       CIP4 5139 (Practical Nursing, Vocational Nursing and Nursing Assistants.): 6,062 students\n",
      "       CIP4 3027 (Human Biology.): 4,720 students\n",
      "       CIP4 0999 (Communication, Journalism, and Related Programs, Other.): 4,147 students\n",
      "       CIP4 3701 (Personal Awareness and Self-Improvement.): 3,722 students\n",
      "       CIP4 0183 (Veterinary/Animal Health Technologies/Technicians.): 3,581 students\n",
      "\n",
      "(iii) Top 20 unmapped ACS FOD codes by weighted person-count:\n",
      "\n",
      "     FOD       Weighted Count % of Total\n",
      "     -------- --------------- ----------\n",
      "     4000              50,462      0.24%\n",
      "     5008              17,737      0.08%\n",
      "     4009                 611      0.00%\n",
      "     1107                 475      0.00%\n",
      "\n",
      "######################################################################\n",
      "# DATA PREPARATION COMPLETE (4-DIGIT CIP)\n",
      "######################################################################\n",
      "\n",
      "Next steps:\n",
      "1. Review cip4_ai_exposure_scores.csv to validate exposure scores\n",
      "2. Check enrollment_with_ai_exposure_4digit.csv for data quality\n",
      "3. Review diagnostic report and add more manual mappings if needed\n",
      "4. Run econometric_analysis.py for DiD and event study\n",
      "\n",
      "4-digit CIP analysis provides:\n",
      "  - Computer Science (1107) vs Information Systems (1104)\n",
      "  - Business Administration (5202) vs Finance (5208) vs Accounting (5203)\n",
      "  - More granular treatment effects and heterogeneity analysis\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "AI Exposure and College Enrollment Analysis - 4-DIGIT CIP VERSION\n",
    "==================================================================\n",
    "Updated for:\n",
    "- 4-digit CIP codes (436 programs vs 49 at 2-digit level)\n",
    "- 2019-2025 enrollment data (combined from both files)\n",
    "- More granular analysis (e.g., Computer Science vs Information Systems)\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from typing import Dict\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# =============================================================================\n",
    "# CONFIGURATION: MANUAL FOD → CIP4 MAPPINGS\n",
    "# =============================================================================\n",
    "# These are mappings not present in the crosswalk file or that need correction.\n",
    "# Each entry: dict with FOD, CIP4, CIP4_title, notes\n",
    "# To add more: just append to this list!\n",
    "\n",
    "MANUAL_MAPPINGS = [\n",
    "    {\n",
    "        'FOD': 6107,\n",
    "        'CIP4': '5138',\n",
    "        'CIP4_title': 'Registered Nursing/Nursing Administration/Nursing Research and Clinical Nursing',\n",
    "        'notes': 'Added Nov 6 2025 - FOD 6107 missing mapping to CIP 5138 (490K students)'\n",
    "    },\n",
    "    {\n",
    "        'FOD': 3611,\n",
    "        'CIP4': '2615',\n",
    "        'CIP4_title': 'Neurobiology and Neurosciences',\n",
    "        'notes': 'Added Nov 6 2025 - FOD 3611 not in original crosswalk'\n",
    "    },\n",
    "    {\n",
    "        'FOD': 5202,\n",
    "        'CIP4': '4228',\n",
    "        'CIP4_title': 'Clinical, Counseling and Applied Psychology',\n",
    "        'notes': 'Added Nov 6 2025 - FOD 5202 (Clinical Psychology) maps to CIP 4228'\n",
    "    },\n",
    "    {\n",
    "        'FOD': 5203,\n",
    "        'CIP4': '4228',\n",
    "        'CIP4_title': 'Clinical, Counseling and Applied Psychology',\n",
    "        'notes': 'Added Nov 6 2025 - FOD 5203 (Counseling Psychology) maps to CIP 4228'\n",
    "    },\n",
    "\n",
    "      {\n",
    "        'FOD': 5203,\n",
    "        'CIP4': '4228',\n",
    "        'CIP4_title': 'Clinical, Counseling and Applied Psychology',\n",
    "        'notes': 'Added Nov 6 2025 - FOD 5203 (Counseling Psychology) maps to CIP 4228'\n",
    "    },\n",
    "     {\n",
    "        'FOD': 5098,\n",
    "        'CIP4': '4099',\n",
    "        'CIP4_title': 'Physical Sciences, other',\n",
    "        'notes': 'Added Nov 6 2025 - FOD 5098 (Multi-disciplinary or General Science) maps to CIP 4099'\n",
    "    },\n",
    "    \n",
    "]\n",
    "\n",
    "print(f\"Loaded {len(MANUAL_MAPPINGS)} manual FOD→CIP4 mappings\")\n",
    "\n",
    "# =============================================================================\n",
    "# STEP 1: LOAD FELTEN AIOE DATA\n",
    "# =============================================================================\n",
    "\n",
    "def load_felten_data(filepath: str) -> pd.DataFrame:\n",
    "    \"\"\"Load Felten et al. (2021) AIOE scores.\"\"\"\n",
    "    print(\"=\"*70)\n",
    "    print(\"LOADING FELTEN AIOE DATA\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    felten = pd.read_excel(filepath, sheet_name='LM AIOE')\n",
    "    felten['soc_clean'] = felten['SOC Code'].str.replace('-', '').str.replace('.', '')\n",
    "    felten['AIOE'] = felten['Language Modeling AIOE'] \n",
    "    print(f\"\\nLoaded {len(felten)} occupations\")\n",
    "    print(f\"AIOE range: {felten['AIOE'].min():.2f} to {felten['AIOE'].max():.2f}\")\n",
    "    \n",
    "    return felten\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# STEP 2: LOAD FOD TO 4-DIGIT CIP CROSSWALK\n",
    "# =============================================================================\n",
    "\n",
    "def load_fod_cip4_crosswalk(filepath: str, manual_mappings: list = None) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Load FOD to 4-digit CIP mapping from crosswalk file.\n",
    "    \n",
    "    The crosswalk has detailed 6-digit CIP codes (like 11.0701).\n",
    "    We extract 4-digit CIP:\n",
    "    - Family (2 digits): 11 = Computer Science\n",
    "    - Group (next 2 digits): 07 = Computer Science \n",
    "    - Combined: 1107 = Computer Science (4-digit)\n",
    "    \n",
    "    Examples:\n",
    "    - 11.0000 → 1100 (Computer Science, General)\n",
    "    - 11.0701 → 1107 (Computer Science)\n",
    "    - 52.0201 → 5202 (Business Administration)\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    filepath : str\n",
    "        Path to crosswalk Excel file\n",
    "    manual_mappings : list of dict\n",
    "        Additional manual mappings to append. Each dict should have keys:\n",
    "        'FOD', 'CIP4', 'CIP4_title', 'notes'\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    DataFrame with columns ['FOD', 'CIP4', 'CIP4_title']\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"LOADING FOD TO 4-DIGIT CIP CROSSWALK\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    # Read from \"CIP code by HHES code\" sheet\n",
    "    df = pd.read_excel(filepath, sheet_name='CIP code by HHES code', skiprows=1)\n",
    "    \n",
    "    # Extract FOD and CIP columns\n",
    "    crosswalk = df[['HHES Code', 'CIP \\nCode', 'CIP Title']].copy()\n",
    "    crosswalk.columns = ['FOD', 'CIP', 'CIP_title']\n",
    "    crosswalk = crosswalk.dropna(subset=['FOD', 'CIP'])\n",
    "    \n",
    "    # Convert FOD to integer\n",
    "    crosswalk['FOD'] = crosswalk['FOD'].astype(int)\n",
    "    \n",
    "    # Extract 4-digit CIP from 6-digit CIP code\n",
    "    # CIP format: XX.XXXX where first 2 are family, next 2 are group\n",
    "    # E.g., 11.0701 → 1107\n",
    "    def extract_cip4(cip_6digit):\n",
    "        try:\n",
    "            cip_float = float(cip_6digit)\n",
    "            # Get integer part (family, 2 digits)\n",
    "            family = int(cip_float)  # e.g., 11\n",
    "            # Get first 2 decimal digits (group)\n",
    "            decimal_part = cip_float - family  # e.g., 0.0701\n",
    "            # Extract first 2 decimal digits\n",
    "            group = int(round(decimal_part * 10000)) // 100  # e.g., 07\n",
    "            # Combine to 4-digit code\n",
    "            cip4 = f\"{family:02d}{group:02d}\"  # e.g., \"1107\"\n",
    "            return cip4\n",
    "        except:\n",
    "            return None\n",
    "    \n",
    "    crosswalk['CIP4'] = crosswalk['CIP'].apply(extract_cip4)\n",
    "    crosswalk = crosswalk.dropna(subset=['CIP4'])\n",
    "    \n",
    "    # Create many-to-many mapping (each FOD can map to multiple CIP4s)\n",
    "    # Keep CIP4_title for the most general title per CIP4\n",
    "    fod_to_cip4_df = crosswalk.groupby(['FOD', 'CIP4']).agg({\n",
    "        'CIP_title': 'first'  # Take first title (they're usually the same for same CIP4)\n",
    "    }).reset_index()\n",
    "    fod_to_cip4_df.columns = ['FOD', 'CIP4', 'CIP4_title']\n",
    "    \n",
    "    print(f\"\\nLoaded {len(fod_to_cip4_df)} FOD→CIP4 mappings from crosswalk file\")\n",
    "    print(f\"  {fod_to_cip4_df['FOD'].nunique()} unique FODs\")\n",
    "    print(f\"  {fod_to_cip4_df['CIP4'].nunique()} unique CIP4 codes\")\n",
    "    print(f\"  Average {len(fod_to_cip4_df) / fod_to_cip4_df['FOD'].nunique():.1f} CIP4 codes per FOD\")\n",
    "    \n",
    "    # Append manual mappings if provided\n",
    "    if manual_mappings:\n",
    "        manual_df = pd.DataFrame(manual_mappings)[['FOD', 'CIP4', 'CIP4_title']]\n",
    "        fod_to_cip4_df = pd.concat([fod_to_cip4_df, manual_df], ignore_index=True)\n",
    "        print(f\"\\n✓ Added {len(manual_mappings)} manual mappings\")\n",
    "        for mapping in manual_mappings:\n",
    "            print(f\"  FOD {mapping['FOD']} → CIP4 {mapping['CIP4']} ({mapping['CIP4_title']})\")\n",
    "    \n",
    "    # Show sample mappings\n",
    "    print(\"\\nSample mappings:\")\n",
    "    sample_fods = sorted(fod_to_cip4_df['FOD'].unique())[:10]\n",
    "    for fod in sample_fods:\n",
    "        cips = fod_to_cip4_df[fod_to_cip4_df['FOD'] == fod]['CIP4'].tolist()\n",
    "        print(f\"  FOD {fod} → CIP4 {cips}\")\n",
    "    \n",
    "    return fod_to_cip4_df\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# STEP 2B: ADD EMPIRICAL ENROLLMENT WEIGHTS TO FOD→CIP4 MAPPING\n",
    "# =============================================================================\n",
    "\n",
    "def add_empirical_weights_to_crosswalk(\n",
    "    fod_to_cip4: pd.DataFrame,\n",
    "    enrollment: pd.DataFrame,\n",
    "    base_year: int = 2019\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Add empirical enrollment weights to FOD→CIP4 mapping.\n",
    "    \n",
    "    For each FOD that maps to multiple CIP4s, calculate weights based on\n",
    "    actual 2019 enrollment: weight_i = enrollment_i / sum(enrollment for all CIP4s that FOD maps to)\n",
    "    \n",
    "    This creates a Bayesian update: P(CIP4 | FOD) ∝ enrollment(CIP4)\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    fod_to_cip4 : DataFrame with columns ['FOD', 'CIP4', 'CIP4_title']\n",
    "    enrollment : DataFrame with columns ['CIP4', 'year', 'enrollment']\n",
    "    base_year : Year to use for calculating weights (default 2019)\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    DataFrame with columns ['FOD', 'CIP4', 'CIP4_title', 'empirical_weight']\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"ADDING EMPIRICAL ENROLLMENT WEIGHTS TO FOD→CIP4 MAPPING\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    # Get base year enrollment\n",
    "    enroll_base = enrollment[enrollment['year'] == base_year][['CIP4', 'enrollment', 'CIP4_title']].copy()\n",
    "    print(f\"\\nUsing {base_year} enrollment as basis for weights\")\n",
    "    print(f\"  {len(enroll_base)} CIP4 codes have enrollment data\")\n",
    "    \n",
    "    # Merge enrollment into crosswalk\n",
    "    crosswalk_with_enroll = fod_to_cip4.merge(\n",
    "        enroll_base[['CIP4', 'enrollment']],\n",
    "        on='CIP4',\n",
    "        how='left'\n",
    "    )\n",
    "    \n",
    "    # For CIP4s with no enrollment data, use a small value (1.0) as placeholder\n",
    "    crosswalk_with_enroll['enrollment'] = crosswalk_with_enroll['enrollment'].fillna(1.0)\n",
    "    \n",
    "    # For each FOD, calculate weights as proportion of total enrollment\n",
    "    # weight_i = enrollment_i / sum_j(enrollment_j) for all j that FOD maps to\n",
    "    fod_totals = crosswalk_with_enroll.groupby('FOD')['enrollment'].transform('sum')\n",
    "    crosswalk_with_enroll['empirical_weight'] = crosswalk_with_enroll['enrollment'] / fod_totals\n",
    "    \n",
    "    # Clean up\n",
    "    crosswalk_weighted = crosswalk_with_enroll[['FOD', 'CIP4', 'CIP4_title', 'empirical_weight']].copy()\n",
    "    \n",
    "    # Report\n",
    "    print(f\"\\nCalculated empirical weights for {len(crosswalk_weighted)} FOD→CIP4 mappings\")\n",
    "    \n",
    "    # Show examples\n",
    "    print(\"\\nSample weighted mappings:\")\n",
    "    sample_fods = crosswalk_weighted['FOD'].unique()[:3]\n",
    "    for fod in sample_fods:\n",
    "        fod_mappings = crosswalk_weighted[crosswalk_weighted['FOD'] == fod]\n",
    "        print(f\"\\n  FOD {fod} maps to {len(fod_mappings)} CIP4 codes:\")\n",
    "        for _, row in fod_mappings.iterrows():\n",
    "            print(f\"    CIP4 {row['CIP4']}: weight = {row['empirical_weight']:.3f}\")\n",
    "    \n",
    "    # Sanity check: weights should sum to 1.0 for each FOD\n",
    "    weight_sums = crosswalk_weighted.groupby('FOD')['empirical_weight'].sum()\n",
    "    if not np.allclose(weight_sums, 1.0):\n",
    "        print(f\"\\n⚠ WARNING: Some FOD weights don't sum to 1.0!\")\n",
    "        print(f\"  Min: {weight_sums.min():.6f}, Max: {weight_sums.max():.6f}\")\n",
    "    else:\n",
    "        print(f\"\\n✓ All FOD weights sum to 1.0\")\n",
    "    \n",
    "    return crosswalk_weighted\n",
    "\n",
    "\n",
    "# STEP 3: LOAD AND PROCESS ACS PUMS DATA\n",
    "# =============================================================================\n",
    "\n",
    "def load_and_filter_acs(\n",
    "    filepath: str,\n",
    "    age_min: int = 22,\n",
    "    age_max: int = 35\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Load and filter IPUMS ACS PUMS data.\n",
    "    \n",
    "    Your ACS columns: DEGFIELDD, OCCSOC, PERWT, AGE, EDUC, YEAR\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"LOADING ACS PUMS DATA\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    acs = pd.read_csv(filepath)\n",
    "    \n",
    "    print(f\"\\nInitial sample: {len(acs):,} observations\")\n",
    "    \n",
    "    # Filter out missing, invalid, and zero FODs\n",
    "    acs_filtered = acs[\n",
    "        (acs['AGE'] >= age_min) & \n",
    "        (acs['AGE'] <= age_max) &\n",
    "        (acs['OCCSOC'].notna()) &\n",
    "        (acs['DEGFIELDD'].notna()) &\n",
    "        (acs['DEGFIELDD'] != 0)  # Exclude FOD = 0 (invalid/no field of degree)\n",
    "    ].copy()\n",
    "    \n",
    "    print(f\"Filtered sample: {len(acs_filtered):,} observations\")\n",
    "    print(f\"  - Age {age_min}-{age_max}\")\n",
    "    print(f\"  - Valid occupation (OCCSOC) and field of degree (DEGFIELDD)\")\n",
    "    \n",
    "    # Clean SOC codes\n",
    "    acs_filtered['soc_clean'] = acs_filtered['OCCSOC'].astype(str).str.replace('-', '').str.replace('.', '')\n",
    "    \n",
    "    print(f\"\\nUnique DEGFIELDD codes: {acs_filtered['DEGFIELDD'].nunique()}\")\n",
    "    print(f\"Unique OCCSOC codes: {acs_filtered['OCCSOC'].nunique()}\")\n",
    "    \n",
    "    return acs_filtered\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# STEP 4: MAP FOD TO 4-DIGIT CIP AND MERGE WITH EXPOSURE\n",
    "# =============================================================================\n",
    "\n",
    "def process_acs_with_exposure(\n",
    "    acs: pd.DataFrame,\n",
    "    felten: pd.DataFrame,\n",
    "    fod_to_cip4: pd.DataFrame\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Map ACS FOD codes to 4-digit CIP using many-to-many relationship.\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"MAPPING FOD TO 4-DIGIT CIP AND MERGING AI EXPOSURE\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    # Map FOD to CIP4\n",
    "    # Map FOD to CIP4 using many-to-many relationship\n",
    "    # Each ACS observation can contribute to multiple CIP4 codes\n",
    "    acs_with_cip = acs.merge(\n",
    "        fod_to_cip4,\n",
    "        left_on='DEGFIELDD',\n",
    "        right_on='FOD',\n",
    "        how='inner'\n",
    "    )\n",
    "    \n",
    "    # Report mapping success\n",
    "    n_original = len(acs)\n",
    "    n_after_mapping = len(acs_with_cip)\n",
    "    n_unique_people = acs_with_cip['DEGFIELDD'].nunique() if 'DEGFIELDD' in acs_with_cip.columns else len(acs_with_cip)\n",
    "    \n",
    "    # Use empirical weights from crosswalk (already calculated based on 2019 enrollment)\n",
    "    # Each ACS person contributes weight_split = PERWT * empirical_weight to each CIP4\n",
    "    acs_with_cip['weight_split'] = acs_with_cip['PERWT'] * acs_with_cip['empirical_weight']\n",
    "    \n",
    "    avg_cips = len(acs_with_cip) / len(acs)\n",
    "    print(f\"  Each ACS person contributes to avg {avg_cips:.1f} CIP4 codes (weighted by 2019 enrollment)\")\n",
    "    \n",
    "    \n",
    "    print(f\"\\nMapped {n_unique_people:,} ACS observations to {len(acs_with_cip):,} CIP4 mappings\")\n",
    "    print(f\"  (Average {n_after_mapping/n_unique_people if n_unique_people > 0 else 0:.1f} CIP4 codes per person)\")\n",
    "    \n",
    "    # Check unmapped FODs\n",
    "    if len(acs_with_cip) < len(acs):\n",
    "        unmapped = acs[~acs['DEGFIELDD'].isin(fod_to_cip4['FOD'])]\n",
    "        unmapped_fods = unmapped['DEGFIELDD'].value_counts().head(10)\n",
    "        print(\"\\nTop 10 unmapped FOD codes:\")\n",
    "        print(unmapped_fods)\n",
    "    \n",
    "    \n",
    "    # Filter to successfully mapped\n",
    "    \n",
    "    # Merge with Felten AIOE scores on SOC code\n",
    "    acs_with_exposure = acs_with_cip.merge(\n",
    "        felten[['soc_clean', 'AIOE']],\n",
    "        on='soc_clean',\n",
    "        how='left'\n",
    "    )\n",
    "    \n",
    "    # Report merge success\n",
    "    n_matched = acs_with_exposure['AIOE'].notna().sum()\n",
    "    pct_matched = 100 * n_matched / len(acs_with_exposure)\n",
    "    print(f\"\\nMatched {n_matched:,}/{len(acs_with_exposure):,} observations to AI exposure ({pct_matched:.1f}%)\")\n",
    "    \n",
    "    \n",
    "    # Drop observations with missing AIOE (do NOT impute with mean)\n",
    "    n_missing = acs_with_exposure['AIOE'].isna().sum()\n",
    "    if n_missing > 0:\n",
    "        print(f\"\\n⚠ Dropping {n_missing:,} observations with missing AIOE scores\")\n",
    "        acs_with_exposure = acs_with_exposure[acs_with_exposure['AIOE'].notna()].copy()\n",
    "    \n",
    "    print(f\"\\nFinal sample: {len(acs_with_exposure):,} observations\")\n",
    "    print(f\"Unique 4-digit CIP codes: {acs_with_exposure['CIP4'].nunique()}\")\n",
    "    \n",
    "    return acs_with_exposure\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# STEP 5: CALCULATE 4-DIGIT CIP-LEVEL AI EXPOSURE\n",
    "# =============================================================================\n",
    "\n",
    "def calculate_cip4_exposure(\n",
    "    acs: pd.DataFrame,\n",
    "    weight_var: str = 'weight_split'\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Calculate weighted average AI exposure by 4-digit CIP code.\n",
    "    \n",
    "    For each CIP4: AI_exposure = Σ [P(occupation|CIP4) × AIOE(occupation)]\n",
    "    where P(occupation|CIP4) is weighted by split weights (PERWT × empirical_weight).\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"CALCULATING 4-DIGIT CIP-LEVEL AI EXPOSURE SCORES\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    # Calculate weighted average by CIP4\n",
    "    cip_exposure = acs.groupby('CIP4').apply(\n",
    "        lambda x: pd.Series({\n",
    "            'ai_exposure_score': np.average(x['AIOE'], weights=x[weight_var]),\n",
    "            'n_obs': len(x),\n",
    "            'n_weighted': x[weight_var].sum(),\n",
    "            'min_exposure': x['AIOE'].min(),\n",
    "            'max_exposure': x['AIOE'].max(),\n",
    "            'std_exposure': np.sqrt(np.average((x['AIOE'] - np.average(x['AIOE'], weights=x[weight_var]))**2, \n",
    "                                                weights=x[weight_var])),\n",
    "            'CIP4_title': x['CIP4_title'].iloc[0] if 'CIP4_title' in x.columns else ''\n",
    "        })\n",
    "    ).reset_index()\n",
    "    \n",
    "    print(f\"\\nCalculated AI exposure for {len(cip_exposure)} 4-digit CIP codes\")\n",
    "    print(\"\\nAI Exposure Score Distribution:\")\n",
    "    print(cip_exposure['ai_exposure_score'].describe())\n",
    "    \n",
    "    # Show top and bottom CIPs\n",
    "    print(\"\\n\\nTop 20 most AI-exposed majors (4-digit CIP):\")\n",
    "    top20 = cip_exposure.nlargest(20, 'ai_exposure_score')[['CIP4', 'CIP4_title', 'ai_exposure_score', 'n_obs']]\n",
    "    print(top20.to_string(index=False))\n",
    "    \n",
    "    print(\"\\n\\nBottom 20 least AI-exposed majors (4-digit CIP):\")\n",
    "    bottom20 = cip_exposure.nsmallest(20, 'ai_exposure_score')[['CIP4', 'CIP4_title', 'ai_exposure_score', 'n_obs']]\n",
    "    print(bottom20.to_string(index=False))\n",
    "    \n",
    "    return cip_exposure\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# STEP 6: LOAD AND COMBINE ENROLLMENT DATA (2019-2025)\n",
    "# =============================================================================\n",
    "\n",
    "def load_and_combine_enrollment_data(\n",
    "    filepath_2024: str, \n",
    "    filepath_2025: str\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Load and combine enrollment data from two sources with proper header handling.\n",
    "    \n",
    "    2024 file: Major Field (4-year, Undergrad) sheet, years 2019-2024\n",
    "    2025 file: CIP Group Enrollment sheet, years 2020-2025 (filter to Undergraduate 4-year)\n",
    "    \n",
    "    Returns combined dataset with 4-digit CIP codes (2019-2025), including CIP4_title.\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"LOADING AND COMBINING ENROLLMENT DATA (2019-2025)\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    # ===== LOAD 2024 FILE =====\n",
    "    print(\"\\nLoading 2019-2024 data from CTEESpring2024-Appendix.xlsx...\")\n",
    "    df_2024 = pd.read_excel(\n",
    "        filepath_2024, \n",
    "        sheet_name='Major Field (4-year, Undergrad)',\n",
    "        header=2  # Row 2 has the actual column headers\n",
    "    )\n",
    "    print(f\"  Loaded {len(df_2024)} rows\")\n",
    "    \n",
    "    # Rename columns for clarity\n",
    "    df_2024 = df_2024.rename(columns={\n",
    "        'Major Field Family (2-digit CIP)': 'CIP2',\n",
    "        'Major Field Family (2-digit) Title': 'CIP2_title',\n",
    "        'Major Field Group (4-digit CIP)': 'CIP4',\n",
    "        'Major Field Group (4-digit) Title': 'CIP4_title'\n",
    "    })\n",
    "    \n",
    "    # Get enrollment columns (years 2019-2024)\n",
    "    years_2024 = [2019, 2020, 2021, 2022, 2023, 2024]\n",
    "    enrollment_cols = [col for col in df_2024.columns if 'Enrollment' in str(col) and '% Change' not in str(col)]\n",
    "    print(f\"  Found {len(enrollment_cols)} enrollment columns for years 2019-2024\")\n",
    "    \n",
    "    # Reshape to long format\n",
    "    data_2024 = []\n",
    "    for idx, row in df_2024.iterrows():\n",
    "        cip4 = row['CIP4']\n",
    "        cip4_title = row['CIP4_title']\n",
    "        if pd.isna(cip4) or cip4 == 'Total':\n",
    "            continue\n",
    "        for year, col in zip(years_2024, enrollment_cols):\n",
    "            enrollment = row[col]\n",
    "            if pd.notna(enrollment) and enrollment != '*':\n",
    "                data_2024.append({\n",
    "                    'CIP4': str(cip4)[:4] if pd.notna(cip4) and str(cip4) != 'Total' else None,\n",
    "                    'CIP4_title': cip4_title,\n",
    "                    'year': year,\n",
    "                    'enrollment': float(enrollment)\n",
    "                })\n",
    "    \n",
    "    df_2024_long = pd.DataFrame(data_2024)\n",
    "    print(f\"  Reshaped to {len(df_2024_long)} observations\")\n",
    "    \n",
    "    # ===== LOAD 2025 FILE =====\n",
    "    print(\"\\nLoading 2020-2025 data from CTEESpring2025-DataAppendix.xlsx...\")\n",
    "    df_2025 = pd.read_excel(\n",
    "        filepath_2025,\n",
    "        sheet_name='CIP Group Enrollment',\n",
    "        header=2  # Row 2 has the actual column headers\n",
    "    )\n",
    "    print(f\"  Loaded {len(df_2025)} rows\")\n",
    "    \n",
    "    # Filter to Undergraduate 4-year only\n",
    "    df_2025 = df_2025[df_2025['Award Level and Institution Type'] == 'Undergraduate 4-year'].copy()\n",
    "    print(f\"  Filtered to {len(df_2025)} Undergraduate 4-year rows\")\n",
    "    \n",
    "    # Rename columns\n",
    "    df_2025 = df_2025.rename(columns={\n",
    "        'Major Field Family \\n(2-digit CIP)': 'CIP2',\n",
    "        'Major Field Family \\n(2-digit CIP) Title': 'CIP2_title',\n",
    "        'Major Field Group \\n(4-digit CIP)': 'CIP4',\n",
    "        'Major Field Group \\n(4-digit CIP) Title': 'CIP4_title'\n",
    "    })\n",
    "    \n",
    "    # Get enrollment columns (years 2020-2025)\n",
    "    # The enrollment columns alternate: Enrollment, % Change, Enrollment, % Change...\n",
    "    # Columns 5, 6, 8, 10, 12, 14 correspond to years 2020-2025\n",
    "    years_2025 = [2020, 2021, 2022, 2023, 2024, 2025]\n",
    "    enrollment_col_indices = [5, 6, 8, 10, 12, 14]\n",
    "    \n",
    "    # Reshape to long format\n",
    "    data_2025 = []\n",
    "    for idx, row in df_2025.iterrows():\n",
    "        cip4 = row['CIP4']\n",
    "        cip4_title = row['CIP4_title']\n",
    "        if pd.isna(cip4) or cip4 == 'Total':\n",
    "            continue\n",
    "        for year, col_idx in zip(years_2025, enrollment_col_indices):\n",
    "            enrollment = row.iloc[col_idx]\n",
    "            if pd.notna(enrollment) and enrollment != '*':\n",
    "                data_2025.append({\n",
    "                    'CIP4': str(cip4)[:4] if pd.notna(cip4) and str(cip4) != 'Total' else None,\n",
    "                    'CIP4_title': cip4_title,\n",
    "                    'year': year,\n",
    "                    'enrollment': float(enrollment)\n",
    "                })\n",
    "    \n",
    "    df_2025_long = pd.DataFrame(data_2025)\n",
    "    print(f\"  Reshaped to {len(df_2025_long)} observations\")\n",
    "    \n",
    "    # ===== COMBINE DATASETS =====\n",
    "    print(\"\\nCombining datasets...\")\n",
    "    \n",
    "    # For overlapping years (2020-2024), use 2025 file data (more recent)\n",
    "    df_2024_unique = df_2024_long[df_2024_long['year'] == 2019].copy()\n",
    "    \n",
    "    enrollment = pd.concat([df_2024_unique, df_2025_long], axis=0, ignore_index=True)\n",
    "    enrollment = enrollment.sort_values(['CIP4', 'year']).reset_index(drop=True)\n",
    "    \n",
    "    print(f\"\\n✓ Combined dataset: {len(enrollment)} observations\")\n",
    "    print(f\"  Years: {sorted(enrollment['year'].unique())}\")\n",
    "    print(f\"  Unique 4-digit CIP codes: {enrollment['CIP4'].nunique()}\")\n",
    "    \n",
    "    # Summary stats\n",
    "    print(\"\\nTotal enrollment by year:\")\n",
    "    yearly_enrollment = enrollment.groupby('year')['enrollment'].sum()\n",
    "    for year, total in yearly_enrollment.items():\n",
    "        print(f\"  {year}: {total:,.0f}\")\n",
    "    \n",
    "    return enrollment\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# STEP 7: MERGE AND FINALIZE\n",
    "# =============================================================================\n",
    "\n",
    "def merge_enrollment_exposure(\n",
    "    enrollment: pd.DataFrame,\n",
    "    cip_exposure: pd.DataFrame\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Merge enrollment data with AI exposure scores.\n",
    "    Preserves CIP4_title from enrollment data (more complete).\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"MERGING ENROLLMENT WITH AI EXPOSURE\")\n",
    "    print(\"=\"*70)\n",
    "    # Normalize CIP4 codes to match (both as zero-padded 4-char strings)\n",
    "    enrollment['CIP4'] = enrollment['CIP4'].astype(str).str.zfill(4)\n",
    "    cip_exposure['CIP4'] = cip_exposure['CIP4'].astype(str).str.zfill(4)\n",
    "    \n",
    "    \n",
    "    # Merge on 4-digit CIP code\n",
    "    # Keep CIP4_title from enrollment (left) as it's more complete\n",
    "    df_final = enrollment.merge(\n",
    "        cip_exposure[['CIP4', 'ai_exposure_score', 'n_obs']],\n",
    "        on='CIP4',\n",
    "        how='left'\n",
    "    )\n",
    "    \n",
    "    # Report merge success\n",
    "    n_matched = df_final['ai_exposure_score'].notna().sum()\n",
    "    pct_matched = 100 * n_matched / len(df_final)\n",
    "    print(f\"\\nMatched {n_matched}/{len(df_final)} enrollment records ({pct_matched:.1f}%)\")\n",
    "    \n",
    "    # Create treatment variables\n",
    "    median_exposure = df_final['ai_exposure_score'].median()\n",
    "    df_final['high_ai_exposure'] = (\n",
    "        df_final['ai_exposure_score'] > median_exposure\n",
    "    ).astype(int)\n",
    "    \n",
    "    # Standardized exposure\n",
    "    df_final['ai_exposure_std'] = (\n",
    "        (df_final['ai_exposure_score'] - df_final['ai_exposure_score'].mean()) /\n",
    "        df_final['ai_exposure_score'].std()\n",
    "    )\n",
    "    \n",
    "    # Terciles (with error handling for insufficient unique values)\n",
    "    try:\n",
    "        df_final['ai_exposure_tercile'] = pd.qcut(\n",
    "            df_final['ai_exposure_score'],\n",
    "            q=3,\n",
    "            labels=['Low', 'Medium', 'High'],\n",
    "            duplicates='drop'\n",
    "        )\n",
    "    except ValueError as e:\n",
    "        # If qcut fails (e.g., too many NaNs or duplicates), use simple cut\n",
    "        print(f\"⚠ Could not create terciles: {e}\")\n",
    "        print(\"  Using quartile-based cut instead\")\n",
    "        df_final['ai_exposure_tercile'] = pd.cut(\n",
    "            df_final['ai_exposure_score'],\n",
    "            bins=3,\n",
    "            labels=['Low', 'Medium', 'High']\n",
    "        )\n",
    "    \n",
    "    # Create log enrollment\n",
    "    df_final['log_enrollment'] = np.log(df_final['enrollment'] + 1)\n",
    "    \n",
    "    print(\"\\n\\nFinal dataset:\")\n",
    "    print(df_final.head(20))\n",
    "    print(f\"\\nShape: {df_final.shape}\")\n",
    "    print(f\"Columns: {list(df_final.columns)}\")\n",
    "    \n",
    "    return df_final\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# STEP 8: VISUALIZATION\n",
    "# =============================================================================\n",
    "\n",
    "def create_descriptive_plots(df: pd.DataFrame, output_path: str = 'enrollment_trends_4digit.png'):\n",
    "    \"\"\"\n",
    "    Create descriptive visualizations for 4-digit CIP analysis.\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"CREATING VISUALIZATIONS\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "    \n",
    "    # 1. Enrollment trends by AI exposure group\n",
    "    ax1 = axes[0, 0]\n",
    "    trend_data = df.groupby(['year', 'high_ai_exposure'])['enrollment'].sum().reset_index()\n",
    "    # Normalize to 2019 (show as % of 2019 enrollment)\n",
    "    trend_2019 = trend_data[trend_data['year'] == 2019].set_index('high_ai_exposure')['enrollment']\n",
    "    trend_data['enrollment_pct_2019'] = trend_data.apply(\n",
    "        lambda row: (row['enrollment'] / trend_2019[row['high_ai_exposure']]) * 100\n",
    "            if row['high_ai_exposure'] in trend_2019.index else 100,\n",
    "        axis=1\n",
    "    )\n",
    "    \n",
    "    for group in [0, 1]:\n",
    "        data = trend_data[trend_data['high_ai_exposure'] == group]\n",
    "        label = 'High AI Exposure' if group else 'Low AI Exposure'\n",
    "        ax1.plot(data['year'], data['enrollment_pct_2019'], marker='o', label=label, linewidth=2)\n",
    "    ax1.set_xlabel('Year', fontsize=12)\n",
    "    ax1.set_ylabel('Enrollment (% of 2019)', fontsize=12)\n",
    "    ax1.set_title('Enrollment Trends by AI Exposure (4-digit CIP)', fontsize=14, fontweight='bold')\n",
    "    ax1.legend()\n",
    "    ax1.grid(alpha=0.3)\n",
    "    ax1.axvline(2022.5, color='red', linestyle='--', alpha=0.5, label='ChatGPT Launch')\n",
    "    \n",
    "    # 2. Distribution of AI exposure\n",
    "    ax2 = axes[0, 1]\n",
    "    cip_scores = df.groupby('CIP4')['ai_exposure_score'].first()\n",
    "    ax2.hist(cip_scores, bins=50, edgecolor='black', alpha=0.7, color='steelblue')\n",
    "    ax2.axvline(cip_scores.median(), color='red', linestyle='--', linewidth=2, label='Median')\n",
    "    ax2.set_xlabel('AI Exposure Score', fontsize=12)\n",
    "    ax2.set_ylabel('Number of 4-digit CIP Codes', fontsize=12)\n",
    "    ax2.set_title('Distribution of AI Exposure Across Majors', fontsize=14, fontweight='bold')\n",
    "    ax2.legend()\n",
    "    ax2.grid(alpha=0.3)\n",
    "    \n",
    "    # 3. Scatter: enrollment growth vs exposure\n",
    "    ax3 = axes[1, 0]\n",
    "    first_year = df['year'].min()\n",
    "    last_year = df['year'].max()\n",
    "    \n",
    "    growth_data = []\n",
    "    for cip in df['CIP4'].unique():\n",
    "        cip_data = df[df['CIP4'] == cip]\n",
    "        enroll_first = cip_data[cip_data['year'] == first_year]['enrollment'].values\n",
    "        enroll_last = cip_data[cip_data['year'] == last_year]['enrollment'].values\n",
    "        if len(enroll_first) > 0 and len(enroll_last) > 0 and enroll_first[0] > 0:\n",
    "            growth = (enroll_last[0] - enroll_first[0]) / enroll_first[0] * 100\n",
    "            exposure = cip_data['ai_exposure_score'].iloc[0] if len(cip_data) > 0 else None\n",
    "            if exposure is not None and pd.notna(exposure):\n",
    "                growth_data.append({'CIP4': cip, 'growth_rate': growth, 'ai_exposure': exposure})\n",
    "    \n",
    "    growth_df = pd.DataFrame(growth_data)\n",
    "    if len(growth_df) > 0:\n",
    "        ax3.scatter(growth_df['ai_exposure'], growth_df['growth_rate'], alpha=0.6, s=30)\n",
    "        ax3.set_xlabel('AI Exposure Score', fontsize=12)\n",
    "        ax3.set_ylabel(f'Enrollment Growth Rate ({first_year}-{last_year}, %)', fontsize=12)\n",
    "        ax3.set_title('Growth Rate vs AI Exposure', fontsize=14, fontweight='bold')\n",
    "        ax3.axhline(0, color='black', linestyle='--', linewidth=1, alpha=0.5)\n",
    "        ax3.grid(alpha=0.3)\n",
    "        \n",
    "        # Add correlation\n",
    "        corr = growth_df[['ai_exposure', 'growth_rate']].corr().iloc[0, 1]\n",
    "        ax3.text(0.05, 0.95, f'Correlation: {corr:.3f}', \n",
    "                transform=ax3.transAxes, verticalalignment='top',\n",
    "                bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))\n",
    "    \n",
    "    # 4. Enrollment by tercile over time\n",
    "    ax4 = axes[1, 1]\n",
    "    tercile_data = df.groupby(['year', 'ai_exposure_tercile'])['enrollment'].sum().reset_index()\n",
    "    # Normalize to 2019\n",
    "    tercile_2019 = tercile_data[tercile_data['year'] == 2019].set_index('ai_exposure_tercile')['enrollment']\n",
    "    tercile_data['enrollment_pct_2019'] = tercile_data.apply(\n",
    "        lambda row: (row['enrollment'] / tercile_2019[row['ai_exposure_tercile']]) * 100\n",
    "            if row['ai_exposure_tercile'] in tercile_2019.index else 100,\n",
    "        axis=1\n",
    "    )\n",
    "    \n",
    "    for tercile in ['Low', 'Medium', 'High']:\n",
    "        data = tercile_data[tercile_data['ai_exposure_tercile'] == tercile]\n",
    "        if len(data) > 0:\n",
    "            ax4.plot(data['year'], data['enrollment_pct_2019'], marker='o', label=f'{tercile} Exposure', linewidth=2)\n",
    "    ax4.set_xlabel('Year', fontsize=12)\n",
    "    ax4.set_ylabel('Enrollment (% of 2019)', fontsize=12)\n",
    "    ax4.set_title('Enrollment by AI Exposure Tercile', fontsize=14, fontweight='bold')\n",
    "    ax4.legend()\n",
    "    ax4.grid(alpha=0.3)\n",
    "    ax4.axvline(2022.5, color='red', linestyle='--', alpha=0.5)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(output_path, dpi=300, bbox_inches='tight')\n",
    "    print(f\"\\n✓ Saved plots to {output_path}\")\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# STEP 8B: TERCILE DEEP-DIVE VISUALIZATION\n",
    "# =============================================================================\n",
    "\n",
    "def create_tercile_deepdive_plots(df: pd.DataFrame, output_path: str = 'enrollment_tercile_deepdive.png'):\n",
    "    \"\"\"\n",
    "    Create detailed enrollment trend plots for top 5 majors within each AI exposure tercile.\n",
    "    \n",
    "    For each tercile (Low/Medium/High), shows:\n",
    "    - Top 5 CIP4 codes by 2019 enrollment\n",
    "    - Enrollment trends 2019-2025 (normalized to 2019 = 100%)\n",
    "    - CIP4 labels with titles\n",
    "    - 2025: Actual enrollment number labeled\n",
    "    - 2023: AI exposure score labeled\n",
    "    - % coverage: what fraction of tercile enrollment these top 5 represent\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"CREATING TERCILE DEEP-DIVE PLOTS (TOP 5)\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    # Filter to rows with valid tercile assignment\n",
    "    df_valid = df[df['ai_exposure_tercile'].notna()].copy()\n",
    "    \n",
    "    # Create figure with 3 subplots (1 row x 3 cols)\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(20, 6))\n",
    "    \n",
    "    # Color palette for 5 lines\n",
    "    colors = plt.cm.tab10(np.linspace(0, 1, 5))\n",
    "    \n",
    "    for idx, tercile in enumerate(['Low', 'Medium', 'High']):\n",
    "        ax = axes[idx]\n",
    "        \n",
    "        # Get data for this tercile\n",
    "        tercile_data = df_valid[df_valid['ai_exposure_tercile'] == tercile].copy()\n",
    "        \n",
    "        if len(tercile_data) == 0:\n",
    "            print(f\"⚠ No data for {tercile} tercile, skipping...\")\n",
    "            continue\n",
    "        \n",
    "        # Get 2019 baseline\n",
    "        tercile_2019 = tercile_data[tercile_data['year'] == 2019].copy()\n",
    "        \n",
    "        # Get top 5 CIP4 by 2019 enrollment\n",
    "        top5_cip4s = tercile_2019.nlargest(5, 'enrollment')['CIP4'].values\n",
    "        \n",
    "        # Calculate coverage\n",
    "        top5_enrollment = tercile_2019[tercile_2019['CIP4'].isin(top5_cip4s)]['enrollment'].sum()\n",
    "        total_enrollment = tercile_2019['enrollment'].sum()\n",
    "        coverage_pct = (top5_enrollment / total_enrollment * 100) if total_enrollment > 0 else 0\n",
    "        \n",
    "        print(f\"\\n{tercile} Tercile:\")\n",
    "        print(f\"  Top 5 CIP4s: {list(top5_cip4s)}\")\n",
    "        print(f\"  Coverage: {coverage_pct:.1f}% of {tercile} tercile enrollment\")\n",
    "        print(f\"  2019 enrollment in top 5: {top5_enrollment:,.0f} / {total_enrollment:,.0f}\")\n",
    "        \n",
    "        # For each of the top 5 CIP4s, plot enrollment trend\n",
    "        for i, cip4 in enumerate(top5_cip4s):\n",
    "            cip_data = tercile_data[tercile_data['CIP4'] == cip4].copy()\n",
    "            \n",
    "            if len(cip_data) == 0:\n",
    "                continue\n",
    "            \n",
    "            # Get 2019 baseline for this CIP4\n",
    "            baseline_2019 = cip_data[cip_data['year'] == 2019]['enrollment'].values\n",
    "            if len(baseline_2019) == 0 or baseline_2019[0] == 0:\n",
    "                continue\n",
    "            baseline_2019 = baseline_2019[0]\n",
    "            \n",
    "            # Normalize to 2019 = 100%\n",
    "            cip_data['enrollment_pct'] = (cip_data['enrollment'] / baseline_2019) * 100\n",
    "            \n",
    "            # Get CIP4 title (truncate if too long)\n",
    "            cip4_title = cip_data['CIP4_title'].iloc[0] if len(cip_data) > 0 else ''\n",
    "            if len(cip4_title) > 30:\n",
    "                cip4_title = cip4_title[:27] + '...'\n",
    "            \n",
    "            # Get AI exposure score\n",
    "            ai_exposure = cip_data['ai_exposure_score'].iloc[0] if len(cip_data) > 0 else None\n",
    "            \n",
    "            # Plot\n",
    "            label = f\"{cip4}: {cip4_title}\"\n",
    "            ax.plot(cip_data['year'], cip_data['enrollment_pct'], \n",
    "                   marker='o', label=label, linewidth=2.5, color=colors[i], alpha=0.8, markersize=6)\n",
    "            \n",
    "            # Add label for 2025 (actual enrollment)\n",
    "            data_2025 = cip_data[cip_data['year'] == 2025]\n",
    "            if len(data_2025) > 0:\n",
    "                enrollment_2025 = data_2025['enrollment'].values[0]\n",
    "                enrollment_pct_2025 = data_2025['enrollment_pct'].values[0]\n",
    "                \n",
    "                # Smart vertical offset to avoid overlap\n",
    "                offset = (i - 2) * 8  # Spread labels vertically (-16, -8, 0, 8, 16)\n",
    "                \n",
    "                ax.annotate(f'{enrollment_2025:,.0f}',\n",
    "                           xy=(2025, enrollment_pct_2025),\n",
    "                           xytext=(8, offset),\n",
    "                           textcoords='offset points',\n",
    "                           fontsize=8,\n",
    "                           color=colors[i],\n",
    "                           fontweight='bold',\n",
    "                           bbox=dict(boxstyle='round,pad=0.3', facecolor='white', edgecolor=colors[i], alpha=0.8))\n",
    "            \n",
    "            # Add label for 2023 (AI exposure score)\n",
    "            data_2023 = cip_data[cip_data['year'] == 2023]\n",
    "            if len(data_2023) > 0 and ai_exposure is not None:\n",
    "                enrollment_pct_2023 = data_2023['enrollment_pct'].values[0]\n",
    "                \n",
    "                # Smart vertical offset to avoid overlap\n",
    "                offset_y = (i - 2) * 6  # Spread labels vertically\n",
    "                \n",
    "                ax.annotate(f'AI: {ai_exposure:.3f}',\n",
    "                           xy=(2023, enrollment_pct_2023),\n",
    "                           xytext=(-35, offset_y),\n",
    "                           textcoords='offset points',\n",
    "                           fontsize=7,\n",
    "                           color=colors[i],\n",
    "                           style='italic',\n",
    "                           bbox=dict(boxstyle='round,pad=0.2', facecolor='lightyellow', edgecolor=colors[i], alpha=0.7))\n",
    "        \n",
    "        # Styling\n",
    "        ax.set_xlabel('Year', fontsize=12)\n",
    "        ax.set_ylabel('Enrollment (% of 2019)', fontsize=12)\n",
    "        ax.set_title(f'{tercile} AI Exposure - Top 5 Majors', fontsize=14, fontweight='bold')\n",
    "        ax.grid(alpha=0.3)\n",
    "        ax.axvline(2022.5, color='red', linestyle='--', alpha=0.5, linewidth=1.5, label='ChatGPT Launch')\n",
    "        ax.axhline(100, color='gray', linestyle=':', alpha=0.5, linewidth=1)\n",
    "        \n",
    "        # Add coverage annotation\n",
    "        annotation_text = f\"Top 5: {coverage_pct:.1f}% of tercile\\nN = {top5_enrollment:,.0f} (2019)\"\n",
    "        ax.text(0.02, 0.98, annotation_text, \n",
    "               transform=ax.transAxes, \n",
    "               verticalalignment='top',\n",
    "               fontsize=9,\n",
    "               bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.8))\n",
    "        \n",
    "        # Legend - smaller font, outside plot\n",
    "        ax.legend(loc='upper left', bbox_to_anchor=(0, -0.12), \n",
    "                 ncol=1, fontsize=9, framealpha=0.9)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(output_path, dpi=300, bbox_inches='tight')\n",
    "    print(f\"\\n✓ Saved tercile deep-dive plots to {output_path}\")\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# # STEP 9: DIAGNOSTIC REPORTING\n",
    "# =============================================================================\n",
    "\n",
    "def generate_diagnostic_report(\n",
    "    acs: pd.DataFrame,\n",
    "    fod_to_cip4: pd.DataFrame,\n",
    "    enrollment: pd.DataFrame\n",
    "):\n",
    "    \"\"\"\n",
    "    Generate diagnostic report showing coverage gaps:\n",
    "    (i) ACS FOD codes not in crosswalk\n",
    "    (ii) CIP4 codes with enrollment but no FOD mapping\n",
    "    (iii) Top unmapped ACS FODs by weighted person-count\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"#\"*70)\n",
    "    print(\"# DIAGNOSTIC REPORT: COVERAGE ANALYSIS\")\n",
    "    print(\"#\"*70)\n",
    "    \n",
    "    # (i) ACS FOD codes not in crosswalk\n",
    "    acs_fods = set(acs['DEGFIELDD'].dropna().unique())\n",
    "    crosswalk_fods = set(fod_to_cip4['FOD'].unique())\n",
    "    missing_fods = acs_fods - crosswalk_fods\n",
    "    \n",
    "    print(f\"\\n(i) ACS FOD codes NOT in crosswalk mapping:\")\n",
    "    print(f\"    Total: {len(missing_fods)} FOD codes\")\n",
    "    if len(missing_fods) > 0:\n",
    "        print(f\"    FODs: {sorted(list(missing_fods))[:20]}\")\n",
    "        # How many ACS observations do these represent?\n",
    "        missing_fod_count = acs[acs['DEGFIELDD'].isin(missing_fods)]['PERWT'].sum()\n",
    "        total_count = acs['PERWT'].sum()\n",
    "        print(f\"    Represents {missing_fod_count:,.0f} / {total_count:,.0f} ACS observations ({missing_fod_count/total_count*100:.1f}%)\")\n",
    "    \n",
    "    # (ii) CIP codes with enrollment but no FOD mapping\n",
    "    enrollment_cips = set(enrollment['CIP4'].unique())\n",
    "    crosswalk_cips = set(fod_to_cip4['CIP4'].unique())\n",
    "    unmapped_cips = enrollment_cips - crosswalk_cips\n",
    "    \n",
    "    print(f\"\\n(ii) CIP4 codes with enrollment but NOT mapped from any FOD:\")\n",
    "    print(f\"     Total: {len(unmapped_cips)} CIP4 codes\")\n",
    "    if len(unmapped_cips) > 0:\n",
    "        # Get enrollment counts for these\n",
    "        unmapped_enroll = enrollment[enrollment['CIP4'].isin(unmapped_cips)]\n",
    "        unmapped_2019 = unmapped_enroll[unmapped_enroll['year'] == 2019]['enrollment'].sum()\n",
    "        total_2019 = enrollment[enrollment['year'] == 2019]['enrollment'].sum()\n",
    "        print(f\"     CIP4s: {sorted(list(unmapped_cips))[:30]}\")\n",
    "        print(f\"     2019 enrollment: {unmapped_2019:,.0f} / {total_2019:,.0f} ({unmapped_2019/total_2019*100:.1f}%)\")\n",
    "        print(f\"\\n     Top 10 unmapped CIP4s by 2019 enrollment:\")\n",
    "        top_unmapped = unmapped_enroll[unmapped_enroll['year'] == 2019].nlargest(10, 'enrollment')[['CIP4', 'CIP4_title', 'enrollment']]\n",
    "        for _, row in top_unmapped.iterrows():\n",
    "            print(f\"       CIP4 {row['CIP4']} ({row['CIP4_title']}): {row['enrollment']:,.0f} students\")\n",
    "    \n",
    "    # (iii) NEW: Top unmapped ACS FODs by weighted person-count\n",
    "    print(f\"\\n(iii) Top 20 unmapped ACS FOD codes by weighted person-count:\")\n",
    "    if len(missing_fods) > 0:\n",
    "        unmapped_acs = acs[acs['DEGFIELDD'].isin(missing_fods)]\n",
    "        top_unmapped_fods = unmapped_acs.groupby('DEGFIELDD')['PERWT'].sum().sort_values(ascending=False).head(20)\n",
    "        print(f\"\\n     {'FOD':<8} {'Weighted Count':>15} {'% of Total':>10}\")\n",
    "        print(f\"     {'-'*8} {'-'*15} {'-'*10}\")\n",
    "        for fod, count in top_unmapped_fods.items():\n",
    "            pct = count / total_count * 100\n",
    "            print(f\"     {int(fod):<8} {count:>15,.0f} {pct:>9.2f}%\")\n",
    "    else:\n",
    "        print(\"     All ACS FODs are mapped!\")\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# MAIN EXECUTION\n",
    "# =============================================================================\n",
    "\n",
    "def main():\n",
    "    \"\"\"\n",
    "    Main execution function.\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"\\n\" + \"#\"*70)\n",
    "    print(\"# AI EXPOSURE AND ENROLLMENT ANALYSIS - 4-DIGIT CIP\")\n",
    "    print(\"#\"*70 + \"\\n\")\n",
    "    \n",
    "    # FILE PATHS\n",
    "    FELTEN_PATH = '/Users/jeffreyohl/Dropbox/CollegeMajorData/FeltenEtAl/2023_Language Modeling AIOE and AIIE.xlsx'\n",
    "    CROSSWALK_PATH = '/Users/jeffreyohl/Dropbox/CollegeMajorData/Crosswalks/crosswalk_handout.xlsx'\n",
    "    ACS_PATH = '/Users/jeffreyohl/Dropbox/CollegeMajorData/IPUMS/usa_00008.csv'\n",
    "    ENROLLMENT_PATH_2025 = '/Users/jeffreyohl/Dropbox/CollegeMajorData/National Student Clearinghouse Data/CTEESpring2025-DataAppendix.xlsx'\n",
    "    ENROLLMENT_PATH_2024 = '/Users/jeffreyohl/Dropbox/CollegeMajorData/National Student Clearinghouse Data/CTEESpring2024-Appendix.xlsx'\n",
    "    OUTPUT_DIR = '/Users/jeffreyohl/Dropbox/CollegeMajorData/output'\n",
    "    \n",
    "    try:\n",
    "        # Step 1: Load Felten data\n",
    "        felten = load_felten_data(FELTEN_PATH)\n",
    "        \n",
    "        # Step 2: Load FOD to 4-digit CIP crosswalk (with manual mappings)\n",
    "        fod_to_cip4 = load_fod_cip4_crosswalk(CROSSWALK_PATH, manual_mappings=MANUAL_MAPPINGS)\n",
    "        \n",
    "        # Step 3: Load and combine enrollment data (2019-2025) - MOVED UP!\n",
    "        enrollment = load_and_combine_enrollment_data(ENROLLMENT_PATH_2024, ENROLLMENT_PATH_2025)\n",
    "        \n",
    "        # Step 4: Add empirical enrollment weights to crosswalk\n",
    "        fod_to_cip4_weighted = add_empirical_weights_to_crosswalk(\n",
    "            fod_to_cip4, enrollment, base_year=2019\n",
    "        )\n",
    "        \n",
    "        # Step 5-6: Process ACS and calculate exposure scores\n",
    "        print(\"\\n\" + \"=\"*70)\n",
    "        print(\"PROCESSING ACS DATA\")\n",
    "        print(\"=\"*70)\n",
    "        acs = load_and_filter_acs(ACS_PATH)\n",
    "        acs_with_exposure = process_acs_with_exposure(acs, felten, fod_to_cip4_weighted)\n",
    "        cip_exposure = calculate_cip4_exposure(acs_with_exposure)\n",
    "        \n",
    "        # Save exposure scores\n",
    "        cip_exposure.to_csv(f'{OUTPUT_DIR}/cip4_ai_exposure_scores.csv', index=False)\n",
    "        print(f\"\\n✓ Saved exposure scores to {OUTPUT_DIR}/cip4_ai_exposure_scores.csv\")\n",
    "        \n",
    "        # Step 7: Merge enrollment with exposure\n",
    "        df_final = merge_enrollment_exposure(enrollment, cip_exposure)\n",
    "        \n",
    "        # Save final dataset\n",
    "        df_final.to_csv(f'{OUTPUT_DIR}/enrollment_with_ai_exposure_4digit.csv', index=False)\n",
    "        print(f\"\\n✓ Saved final dataset to {OUTPUT_DIR}/enrollment_with_ai_exposure_4digit.csv\")\n",
    "        \n",
    "        # Step 8: Create visualizations\n",
    "        create_descriptive_plots(df_final, f'{OUTPUT_DIR}/enrollment_trends_4digit.png')\n",
    "        \n",
    "        # Step 8B: Create tercile deep-dive plots\n",
    "        create_tercile_deepdive_plots(df_final, f'{OUTPUT_DIR}/enrollment_tercile_deepdive.png')\n",
    "        \n",
    "        # Step 9: Diagnostic reporting - what's missing?\n",
    "        generate_diagnostic_report(acs, fod_to_cip4_weighted, enrollment)\n",
    "        \n",
    "        print(\"\\n\" + \"#\"*70)\n",
    "        print(\"# DATA PREPARATION COMPLETE (4-DIGIT CIP)\")\n",
    "        print(\"#\"*70)\n",
    "        print(\"\\nNext steps:\")\n",
    "        print(\"1. Review cip4_ai_exposure_scores.csv to validate exposure scores\")\n",
    "        print(\"2. Check enrollment_with_ai_exposure_4digit.csv for data quality\")\n",
    "        print(\"3. Review diagnostic report and add more manual mappings if needed\")\n",
    "        print(\"4. Run econometric_analysis.py for DiD and event study\")\n",
    "        print(\"\\n4-digit CIP analysis provides:\")\n",
    "        print(\"  - Computer Science (1107) vs Information Systems (1104)\")\n",
    "        print(\"  - Business Administration (5202) vs Finance (5208) vs Accounting (5203)\")  \n",
    "        print(\"  - More granular treatment effects and heterogeneity analysis\")\n",
    "        \n",
    "    except FileNotFoundError as e:\n",
    "        print(f\"\\n❌ Error: File not found - {e}\")\n",
    "        print(\"\\nPlease check that all data files exist at the specified paths:\")\n",
    "        print(f\"  - Felten: {FELTEN_PATH}\")\n",
    "        print(f\"  - Crosswalk: {CROSSWALK_PATH}\")\n",
    "        print(f\"  - ACS: {ACS_PATH}\")\n",
    "        print(f\"  - Enrollment 2024: {ENROLLMENT_PATH_2024}\")\n",
    "        print(f\"  - Enrollment 2025: {ENROLLMENT_PATH_2025}\")\n",
    "    except Exception as e:\n",
    "        print(f\"\\n❌ Error occurred: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
